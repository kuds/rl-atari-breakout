{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7/o5TglW3MUTu3lmNWYXd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuds/rl-atari-breakout/blob/main/%5BAtari%20Breakout%5D%20Model-Based%20Reinforcement%20Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Model-Based Reinforcement Learning to play Atari's Breakout\n",
        "\n",
        "## References/Repositories\n",
        "- [Model-Based Reinforcement Learning for Atari - Simplified Repo](https://github.com/dhruvramani/model-based-atari/tree/master)\n",
        "- [Model-Based Reinforcement Learning for Atari - Paper](https://arxiv.org/abs/1903.00374)\n",
        "- [Tensor2Tensor - RL Code](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/rl)"
      ],
      "metadata": {
        "id": "x5SgWAjNeWV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9ExFfgAuHui",
        "outputId": "cb73d09e-ab83-4006-94b1-050c379876f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "30ciUtqduAiJ"
      },
      "outputs": [],
      "source": [
        "import gymnasium\n",
        "import platform\n",
        "import torch\n",
        "import numpy\n",
        "from importlib.metadata import version\n",
        "from datetime import datetime\n",
        "import google.colab.drive\n",
        "\n",
        "# Load the CartPole-v1 environment\n",
        "env = gymnasium.make(\"CartPole-v1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Python Version: {platform.python_version()}\")\n",
        "print(f\"Torch Version: {version('torch')}\")\n",
        "print(f\"Is Cuda Available: {torch.cuda.is_available()}\")\n",
        "print(f\"Cuda Version: {torch.version.cuda}\")\n",
        "print(f\"Gymnasium Version: {version('gymnasium')}\")\n",
        "print(f\"Numpy Version: {version('numpy')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-RRgny-u1zx",
        "outputId": "b02c28dd-0d29-47bb-9039-5bdaeabbf5a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Version: 3.10.12\n",
            "Torch Version: 2.5.0+cu121\n",
            "Is Cuda Available: False\n",
            "Cuda Version: 12.1\n",
            "Gymnasium Version: 1.0.0\n",
            "Numpy Version: 1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_data(env, num_episodes=1000):\n",
        "    data = []\n",
        "    for _ in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        while not (terminated or truncated):\n",
        "            action = env.action_space.sample()\n",
        "            next_state, reward, terminated, truncated, info = env.step(action)\n",
        "            data.append((state, action, reward, next_state))\n",
        "            if(terminated or truncated):\n",
        "              print(next_state)\n",
        "            state = next_state\n",
        "    return data\n",
        "\n",
        "# Collect data\n",
        "\n",
        "data = collect_data(env)\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYPDC21YuHMR",
        "outputId": "ce3bf12f-8b37-4841-ba1a-b2ad8d02be54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.09985067  1.1573845  -0.22733371 -2.1230328 ]\n",
            "[-0.14263262 -0.937871    0.22696428  1.7066796 ]\n",
            "[-0.07151423 -0.9587023   0.22259556  1.9680437 ]\n",
            "[-0.18474822 -0.81536525  0.23248145  1.5020494 ]\n",
            "[ 0.16199492  0.38389528 -0.22363782 -0.8589244 ]\n",
            "[-0.06390031 -0.03285903  0.21369837  0.53873193]\n",
            "[-0.20088229 -0.60771954  0.22065611  1.156212  ]\n",
            "[-0.22312042 -1.7290013   0.2535453   2.663306  ]\n",
            "[-0.0717577  -1.165038    0.23382524  2.0948775 ]\n",
            "[ 0.09235707  0.5676411  -0.22014874 -1.4649719 ]\n",
            "[ 0.1689128   0.6503425  -0.23379983 -1.3019111 ]\n",
            "[-0.10049108 -0.5654767   0.22380552  1.2447968 ]\n",
            "[-0.03197342 -0.45850286  0.21602406  1.3897356 ]\n",
            "[ 0.19051856  1.5527407  -0.22743213 -2.4447765 ]\n",
            "[-0.20329696 -0.5940527   0.22163054  1.1417512 ]\n",
            "[-0.0968428  -0.8284884   0.21895196  1.567352  ]\n",
            "[-0.1085595  -0.41229263  0.21909222  0.95741194]\n",
            "[-0.18645835 -1.5370182   0.24279214  2.331681  ]\n",
            "[-0.00744801 -0.24765879  0.21804842  1.0654683 ]\n",
            "[-0.20567559 -0.6362208   0.22102894  1.0211744 ]\n",
            "[-0.00959014 -0.39573997  0.22669466  1.4930495 ]\n",
            "[-0.1508549  -0.05704175  0.21530423  0.53002614]\n",
            "[-0.13122909  0.12116052  0.21174622  0.36295336]\n",
            "[-0.18374392 -1.3815064   0.21667719  2.230712  ]\n",
            "[-0.08701694 -0.41879338  0.21366553  1.1828328 ]\n",
            "[ 0.13502036  0.59008527 -0.21581084 -1.2936177 ]\n",
            "[-0.13523479 -0.797007    0.22282292  1.4432395 ]\n",
            "[-0.03986269 -0.9894797   0.21311986  2.1205287 ]\n",
            "[0.34887472 0.51290953 0.22020172 0.4953961 ]\n",
            "[-0.9542242  -1.6748664   0.22083265  1.3482883 ]\n",
            "[ 0.11311249  1.1878241  -0.21708985 -2.0888028 ]\n",
            "[-0.10200123 -0.617038    0.21583177  1.180386  ]\n",
            "[-0.09984338 -0.6313527   0.21926978  1.4139987 ]\n",
            "[-0.13031489 -1.5175492   0.2135736   2.5208766 ]\n",
            "[ 0.12840462  1.5784979  -0.23896189 -2.5490177 ]\n",
            "[ 0.1487214   1.2048059  -0.23332039 -2.026568  ]\n",
            "[ 0.13302583  0.9604786  -0.22503412 -1.7536806 ]\n",
            "[-0.08721876 -0.6508964   0.2182452   1.4667836 ]\n",
            "[ 0.17541417  1.1724722  -0.24844977 -2.0686252 ]\n",
            "[-0.0140662  0.3935135 -0.2121651 -1.3688105]\n",
            "[-0.1071208  -1.4020921   0.23022275  2.4484618 ]\n",
            "[ 0.1748776   0.7504122  -0.22565459 -1.2610903 ]\n",
            "[-0.12710766 -0.44458002  0.23212376  1.1378311 ]\n",
            "[-0.29060742 -1.5816231   0.2554738   2.1263726 ]\n",
            "[-0.21798578 -0.82877374  0.24103415  1.4910554 ]\n",
            "[-0.12280504 -1.3732485   0.21815057  2.2563393 ]\n",
            "[-0.01848895 -1.5465084   0.23778825  2.758001  ]\n",
            "[ 0.16597015  1.2214845  -0.241013   -2.0129266 ]\n",
            "[-0.13796791  0.13177334  0.21390736  0.21228458]\n",
            "[ 0.21122815  1.1389036  -0.22696136 -1.9036385 ]\n",
            "[-0.19590245 -1.010984    0.22575475  1.6535037 ]\n",
            "[ 0.06571517  0.17302461 -0.21136916 -0.80094486]\n",
            "[ 0.21904346  0.571888   -0.21032535 -1.0529929 ]\n",
            "[ 0.15981363  0.42292923 -0.21119304 -0.9525941 ]\n",
            "[ 0.27915478  0.03380891 -0.21912238 -0.49814522]\n",
            "[ 0.16436926  0.770924   -0.21398768 -1.3249985 ]\n",
            "[ 0.1968219   0.7564722  -0.20976247 -1.2766198 ]\n",
            "[-0.17405394 -0.24111232  0.22008562  0.6403429 ]\n",
            "[ 0.386499    1.7347529  -0.21820709 -2.0341144 ]\n",
            "[-0.14114842 -1.511148    0.22133352  2.3342834 ]\n",
            "[ 0.13202429  0.8356597  -0.22629695 -1.5209916 ]\n",
            "[-0.12929758 -1.1841451   0.25202358  2.0829215 ]\n",
            "[-0.11219253 -0.8224637   0.22068642  1.5655389 ]\n",
            "[ 0.10914023  1.0086695  -0.23868181 -1.8267097 ]\n",
            "[-0.11880711 -0.4433861   0.21359915  1.126933  ]\n",
            "[-0.16924126 -0.5677619   0.22874632  1.1474643 ]\n",
            "[-0.13472427 -0.5725788   0.22327927  1.275283  ]\n",
            "[ 0.07008735  0.06380044 -0.2183897  -0.5006687 ]\n",
            "[-0.1555231  -0.20688161 -0.21520863 -0.55316836]\n",
            "[ 0.05030167  0.1708521  -0.23063155 -0.8902387 ]\n",
            "[ 0.15994729  1.3921019  -0.24723117 -2.2748742 ]\n",
            "[-0.17416753 -1.2200085   0.22321399  2.0139005 ]\n",
            "[-0.14491902 -1.0496744   0.2381886   2.0915036 ]\n",
            "[-0.15362887 -0.39342496  0.22456388  1.0379252 ]\n",
            "[-0.03592532 -1.2159711   0.2136156   2.1677787 ]\n",
            "[ 0.1716648   1.0221981  -0.23115835 -1.78718   ]\n",
            "[-0.16655007 -0.6306182   0.21523339  1.0606505 ]\n",
            "[ 0.1246217   0.46023175 -0.2194309  -1.1005237 ]\n",
            "[-0.07031924 -0.44199026  0.22080235  1.311042  ]\n",
            "[ 0.09499748  0.5923555  -0.22927077 -1.5153546 ]\n",
            "[-0.36398515 -1.1654016   0.21001312  1.5021336 ]\n",
            "[-0.10836004 -0.41498128  0.22713487  1.3285067 ]\n",
            "[-0.1377637  -1.5210106   0.24906515  2.6155474 ]\n",
            "[-0.14134443 -0.9745646   0.21149647  1.7359525 ]\n",
            "[-0.07346207 -0.991778    0.2128312   1.9386238 ]\n",
            "[ 0.16511087  0.2458416  -0.22572681 -0.8580362 ]\n",
            "[ 0.2518229   1.5078863  -0.22270454 -2.1853209 ]\n",
            "[-0.1699534  -1.3280067   0.23737335  2.3754041 ]\n",
            "[-0.13797258 -0.81671655  0.22015241  1.7328682 ]\n",
            "[ 0.0988183   0.25218493 -0.21433152 -0.7102823 ]\n",
            "[ 0.0197459   0.5688885  -0.23823349 -1.3863618 ]\n",
            "[-0.13650966 -0.5722769   0.21235898  1.3885287 ]\n",
            "[ 0.16630968  0.25547805 -0.22616263 -0.855933  ]\n",
            "[-0.16945001 -1.7764776   0.23135841  2.8172991 ]\n",
            "[0.06969926 0.19256996 0.21294361 0.7831476 ]\n",
            "[-0.18087399 -1.028863    0.2340871   1.7671835 ]\n",
            "[-0.20352632 -0.44711113  0.23064351  0.8499681 ]\n",
            "[-0.06186594 -0.5710281   0.22181305  1.4452952 ]\n",
            "[ 0.13637933  0.796017   -0.23003711 -1.4679792 ]\n",
            "[-0.12915611 -0.7824105   0.21869849  1.4732373 ]\n",
            "[-0.08142053 -1.0021628   0.21935141  1.7660943 ]\n",
            "[ 0.07618254  1.0135992  -0.21361522 -1.8337754 ]\n",
            "[ 0.13949239  0.7828182  -0.21457392 -1.407962  ]\n",
            "[-0.03958815 -0.95160776  0.23965389  1.9496158 ]\n",
            "[-0.1614238  -0.5991608   0.22398777  1.4391487 ]\n",
            "[ 0.18697627  1.1682223  -0.25409335 -2.0478597 ]\n",
            "[-0.11012772 -0.17323494  0.21818778  0.9044041 ]\n",
            "[-0.28875634 -1.1370906   0.22103117  1.4475133 ]\n",
            "[-0.17081872 -0.9708578   0.21898536  1.8043108 ]\n",
            "[-0.26153353 -1.0037711   0.23421636  1.434414  ]\n",
            "[-0.13603139 -0.8045944   0.24398229  1.5379882 ]\n",
            "[ 0.1075531   0.6245427  -0.21523783 -1.1930426 ]\n",
            "[ 0.21196926  1.3520769  -0.22626793 -2.1445518 ]\n",
            "[ 0.00532241 -0.32911217 -0.21471858 -0.6013221 ]\n",
            "[ 0.3211689   2.2859797  -0.22657812 -2.924098  ]\n",
            "[ 0.17522685  1.5860993  -0.23081507 -2.5765316 ]\n",
            "[-0.21777062 -0.60289115  0.22519705  1.0779954 ]\n",
            "[ 0.14906421  0.820664   -0.21930785 -1.5500922 ]\n",
            "[ 0.04313829  0.03068976 -0.21655299 -0.9102568 ]\n",
            "[-0.08983633 -0.44028276  0.22158161  0.9718362 ]\n",
            "[ 0.06011926  0.43592536 -0.21178654 -1.0212896 ]\n",
            "[ 0.18927053  1.9232501  -0.23376788 -2.9911823 ]\n",
            "[-0.1570163 -0.8126279  0.2186163  1.4876559]\n",
            "[ 0.1545203   0.63453335 -0.2180549  -1.2633125 ]\n",
            "[-0.1757297  -0.77467424  0.21549395  1.5345229 ]\n",
            "[-0.05004274 -0.39384255  0.21033713  1.0549113 ]\n",
            "[ 0.12907751  0.84373575 -0.21032889 -1.4773972 ]\n",
            "[ 0.15897459  1.7638048  -0.21287523 -2.7852914 ]\n",
            "[ 0.13819368  0.24369696 -0.22810146 -0.746546  ]\n",
            "[ 0.327253    1.3791585  -0.22473055 -1.7144756 ]\n",
            "[-0.11438061 -1.1772631   0.21044542  2.0011072 ]\n",
            "[-0.07004785 -0.01474334  0.2121246   0.60901403]\n",
            "[-0.00434441 -0.22153917  0.20972595  0.9070921 ]\n",
            "[ 0.16025513  1.1680455  -0.25345647 -2.0760384 ]\n",
            "[ 0.1465514   0.0187689  -0.2217134  -0.53827477]\n",
            "[-0.1242548  -0.42800498  0.21139914  0.9559982 ]\n",
            "[-0.03669675 -0.42012265  0.21653214  1.1133639 ]\n",
            "[ 0.09422633  0.9709843  -0.23673421 -1.9518925 ]\n",
            "[ 0.15862443  1.1807958  -0.20992891 -1.9331163 ]\n",
            "[-0.15395585 -0.6262922   0.22005513  1.2396451 ]\n",
            "[-0.13640381 -0.7955263   0.22061393  1.4771258 ]\n",
            "[-0.11365171 -0.05594415  0.2162517   0.7349894 ]\n",
            "[ 0.15347688  0.9922027  -0.21355894 -1.6404155 ]\n",
            "[-0.15502444 -1.0065533   0.21607187  1.6960264 ]\n",
            "[ 0.18281618  1.3573235  -0.23018934 -2.1885762 ]\n",
            "[ 0.1496464   1.1446748  -0.21683568 -1.996539  ]\n",
            "[ 0.17522098  0.95187026 -0.22837017 -1.6122831 ]\n",
            "[-0.15720674 -1.3498434   0.2456785   2.3785267 ]\n",
            "[ 0.17828831  0.9843679  -0.22045583 -1.6883    ]\n",
            "[ 0.18891174  0.44498694 -0.21786119 -1.1223292 ]\n",
            "[-0.09053596 -0.46523663  0.21630634  1.3109564 ]\n",
            "[ 0.12284194  0.4328808  -0.21949263 -1.03367   ]\n",
            "[-0.02413573  0.19213985 -0.21933758 -1.2431942 ]\n",
            "[ 0.02988329 -0.20803559 -0.21968737 -0.47076437]\n",
            "[-0.05605673  0.14862262  0.21129441  0.45841056]\n",
            "[ 0.13294269  0.02879591 -0.2190871  -0.6612326 ]\n",
            "[ 0.14231205  0.8479975  -0.23646154 -1.8184873 ]\n",
            "[ 0.15358505  0.94874644 -0.21423078 -1.682697  ]\n",
            "[-0.33677232 -1.2148619   0.21713747  1.6728424 ]\n",
            "[ 0.07657961  0.59532875 -0.21032725 -1.1963699 ]\n",
            "[-0.12007822 -0.43169135  0.22691612  1.154051  ]\n",
            "[ 0.09444778 -0.5738486   0.21872514  1.6933472 ]\n",
            "[ 0.2049713   1.3837972  -0.21813598 -2.1790848 ]\n",
            "[-0.12476252 -0.23820351  0.21269079  0.7112269 ]\n",
            "[ 0.38431963  1.5138098  -0.23010384 -1.9381874 ]\n",
            "[ 0.12628779  0.5983869  -0.21449451 -1.3137668 ]\n",
            "[ 0.08486826  0.65210426 -0.21915768 -1.6288124 ]\n",
            "[ 0.03088355  0.5774679  -0.22376399 -1.4831597 ]\n",
            "[ 0.07958578  0.648974   -0.2221323  -1.2714391 ]\n",
            "[ 0.08039051  0.06268795 -0.22650588 -0.73019713]\n",
            "[-0.22731675 -0.7690196   0.2278993   1.2288983 ]\n",
            "[ 0.16997863  0.8317689  -0.22219804 -1.381377  ]\n",
            "[-0.09744565 -1.3385073   0.2434258   2.2813547 ]\n",
            "[-0.19457927  0.5845875  -0.23174712 -1.9727294 ]\n",
            "[-0.20012683 -1.0278465   0.24514383  1.7486837 ]\n",
            "[-0.142838   -0.6173822   0.21679701  1.2661288 ]\n",
            "[ 0.153571    1.1436496  -0.23313192 -1.8341624 ]\n",
            "[ 0.17615321  1.0111139  -0.223581   -1.7300377 ]\n",
            "[-0.02819265 -0.03241859  0.2113428   0.708733  ]\n",
            "[ 0.17775087  1.2067062  -0.21211174 -2.049627  ]\n",
            "[-0.08109096 -0.5884178   0.21238197  1.5904372 ]\n",
            "[-0.13125147 -1.0148844   0.23165378  1.8016124 ]\n",
            "[ 0.09819034  1.1636231  -0.241624   -2.018207  ]\n",
            "[-0.22000666 -0.77121305  0.20978397  1.3619281 ]\n",
            "[ 0.02670329  0.23040065 -0.22484593 -0.89619946]\n",
            "[ 0.06946006 -0.17390457 -0.21043333 -0.4321507 ]\n",
            "[ 0.09949186  1.4220332  -0.22724509 -2.382307  ]\n",
            "[-0.11801719 -0.77474165  0.21511358  1.4383097 ]\n",
            "[ 0.21883155  1.3466414  -0.24501932 -1.9008595 ]\n",
            "[-0.07719609 -0.4077673   0.22860877  0.97954065]\n",
            "[ 0.29137433  2.0910387  -0.22762379 -2.8358934 ]\n",
            "[-0.09009559 -0.62628293  0.22391501  1.3049927 ]\n",
            "[ 0.1986615   1.0261875  -0.22706026 -1.7140224 ]\n",
            "[-0.08882098  0.22242782  0.2157298   0.15180776]\n",
            "[ 0.15580723  1.222576   -0.23307975 -2.028147  ]\n",
            "[-0.17628759 -0.74594754  0.22925004  1.4414696 ]\n",
            "[ 0.04582115 -0.27860114  0.21419801  1.3179195 ]\n",
            "[ 0.14662851  1.5304414  -0.21002688 -2.5115635 ]\n",
            "[-0.16328582 -1.1647124   0.23569971  2.0284057 ]\n",
            "[-0.10015289 -0.583235    0.23521705  1.2412283 ]\n",
            "[-1.5123637  -1.696783    0.2211927   0.99331313]\n",
            "[ 0.11370311  1.5216153  -0.24796079 -2.5884795 ]\n",
            "[ 0.21541901  0.43507352 -0.23133922 -0.9052645 ]\n",
            "[-0.18932493 -0.99073696  0.22932939  1.6505593 ]\n",
            "[ 0.1069829   1.2204828  -0.21009836 -1.8885927 ]\n",
            "[ 0.06114228  0.6420178  -0.22116324 -1.264173  ]\n",
            "[-0.09712931 -0.5893198   0.23531598  1.4291291 ]\n",
            "[ 0.2016119   1.0341094  -0.22593231 -1.8647264 ]\n",
            "[ 0.12421776  1.5627322  -0.21446878 -2.5149348 ]\n",
            "[-0.15947498 -0.3684503   0.21589431  1.1412176 ]\n",
            "[-0.15118015 -0.83551323  0.23678195  1.4475136 ]\n",
            "[ 0.07108078  0.25983992 -0.21949896 -1.0125761 ]\n",
            "[ 0.06591523  0.24477196 -0.21730995 -0.78979933]\n",
            "[ 0.13950466  1.7302653  -0.25610596 -2.8484468 ]\n",
            "[-0.16445911 -0.4292011   0.22498383  0.9978698 ]\n",
            "[ 0.26080158  1.7245625  -0.2295218  -2.4546335 ]\n",
            "[ 0.06478866  0.561897   -0.20978728 -1.269901  ]\n",
            "[ 0.2060554   0.5498514  -0.20957415 -1.1426243 ]\n",
            "[-0.22904481 -1.1396163   0.24324723  1.5601996 ]\n",
            "[-0.04765554 -0.60803366  0.22492361  1.5014545 ]\n",
            "[ 0.15775512  0.6342135  -0.21027698 -1.1975598 ]\n",
            "[ 0.21111317  1.7446909  -0.25335753 -2.7319593 ]\n",
            "[ 0.21153001  1.0206836  -0.23268218 -1.7692286 ]\n",
            "[-0.12416109 -0.81481475  0.21470027  1.4261441 ]\n",
            "[-0.16137597 -1.2001597   0.22168022  2.2451653 ]\n",
            "[ 0.2763629   1.0105922  -0.24384338 -1.6813745 ]\n",
            "[ 0.2035995   0.95668393 -0.22615187 -1.6886938 ]\n",
            "[ 0.13513015  0.95707256 -0.21308959 -1.653549  ]\n",
            "[ 0.0590911   0.1730841  -0.21112867 -0.7843433 ]\n",
            "[-0.12421248 -0.1968018   0.22228213  0.82979447]\n",
            "[-0.13939753 -0.78854626  0.23047332  1.4886559 ]\n",
            "[ 0.13602237  1.141702   -0.23860657 -1.8738457 ]\n",
            "[-0.12665427 -0.6337568   0.20965745  1.2650496 ]\n",
            "[-0.12289823 -1.0374404   0.21631424  1.9032719 ]\n",
            "[-0.04739148 -0.18781315  0.21292086  0.79209405]\n",
            "[-0.19070126 -1.1734911   0.21944128  1.9836366 ]\n",
            "[ 0.06190689  1.1565146  -0.230093   -2.1330936 ]\n",
            "[-0.08045538 -0.20477884  0.21478468  0.6736605 ]\n",
            "[-0.07733294 -0.21680681  0.22414282  0.84573156]\n",
            "[-0.0485067   0.00237389  0.21471064  0.6748043 ]\n",
            "[ 0.13943847  0.7636224  -0.21244608 -1.4045995 ]\n",
            "[-0.23567683 -0.6265699   0.21693163  1.1426182 ]\n",
            "[ 0.1305756   0.7652696  -0.23272958 -1.6265403 ]\n",
            "[-0.26116082 -1.5809683   0.23840587  2.346064  ]\n",
            "[-0.05846695 -0.5526853   0.21402396  1.2208204 ]\n",
            "[ 0.16924362  1.7740719  -0.23427835 -2.8042576 ]\n",
            "[-0.11071546 -0.9910552   0.24005593  1.7914265 ]\n",
            "[-0.13171752 -0.5708668   0.21634498  1.2564461 ]\n",
            "[ 0.10523852  0.00687674 -0.21043287 -0.5209056 ]\n",
            "[-0.10166878 -1.3351827   0.22534138  2.3000453 ]\n",
            "[ 0.16146691  1.5268972  -0.22032034 -2.3229885 ]\n",
            "[ 0.11224318  1.1688946  -0.24071445 -2.149012  ]\n",
            "[ 0.24754834  1.1597745  -0.22658873 -1.5818942 ]\n",
            "[-0.07436866 -0.5555476   0.21588282  1.1687536 ]\n",
            "[-0.08552514 -0.2434007   0.21173975  0.7274715 ]\n",
            "[-0.07356281 -0.76054245  0.23507564  1.6593553 ]\n",
            "[ 0.30149996  1.2865971  -0.21073611 -1.2230914 ]\n",
            "[ 0.2183676  0.7970872 -0.2179844 -1.3498844]\n",
            "[ 0.01124259 -0.18039891  0.21826479  1.008452  ]\n",
            "[0.271299   1.0357033  0.20945571 0.21468747]\n",
            "[ 0.14670424  0.41257787 -0.22272164 -0.8750642 ]\n",
            "[-0.09336262 -0.00196814  0.21888483  0.92266214]\n",
            "[-0.17721388 -0.83840436  0.21375038  1.4299719 ]\n",
            "[-0.36678872 -1.2856505   0.21323946  1.226138  ]\n",
            "[-0.08168299 -0.7840884   0.22504756  1.4315069 ]\n",
            "[-0.07892404 -0.02217605  0.21510296  0.75796527]\n",
            "[-0.12136959 -0.36970317  0.21032093  1.1305155 ]\n",
            "[-0.1563079  -0.7755318   0.22456333  1.5218006 ]\n",
            "[-0.08815633 -0.3793784   0.21318948  0.9216529 ]\n",
            "[-0.11824749 -0.5626891   0.22100613  1.247013  ]\n",
            "[-0.15073173 -0.8248746   0.21831031  1.5302837 ]\n",
            "[-0.08957922 -1.7302226   0.22813143  2.7975457 ]\n",
            "[-0.1785402  -0.44400352  0.215076    0.90949523]\n",
            "[-0.18624856 -0.9438059   0.22767812  1.1582341 ]\n",
            "[ 0.0955195   0.36873612 -0.23264699 -0.9984504 ]\n",
            "[ 0.14695585  0.95990425 -0.24004416 -1.6954545 ]\n",
            "[-0.12887678 -0.75143117  0.23033865  1.3727053 ]\n",
            "[0.04587489 0.31554785 0.22193412 0.56538695]\n",
            "[ 0.17732026  0.60769004 -0.22467092 -1.0710791 ]\n",
            "[-0.14588155 -1.1371638   0.21143498  2.046838  ]\n",
            "[-0.02086951  0.01928886  0.22644082  0.6922225 ]\n",
            "[ 0.21687461  1.0255042  -0.22525333 -1.4938141 ]\n",
            "[-0.02802615 -1.029322    0.23429911  2.034969  ]\n",
            "[ 0.13838917  0.6160108  -0.21525198 -1.2649267 ]\n",
            "[ 0.17740794  0.61282027 -0.2297894  -1.114215  ]\n",
            "[ 0.1433185   0.55581564 -0.21521872 -1.210152  ]\n",
            "[ 0.1111043   1.159512   -0.21247464 -1.9433391 ]\n",
            "[-0.21999684 -1.5204606   0.23606664  2.2856593 ]\n",
            "[ 0.6387798   1.4845538  -0.21012087 -1.1707718 ]\n",
            "[-0.14427195 -0.96971494  0.22322069  1.6182425 ]\n",
            "[-0.15772577 -0.20187001  0.21874774  0.6825667 ]\n",
            "[-0.09810295 -0.61160296  0.23812278  1.3725543 ]\n",
            "[-0.16366799 -0.96893096  0.2181145   1.5477335 ]\n",
            "[ 0.13692676  1.1680502  -0.21486945 -1.8353577 ]\n",
            "[-0.08036633  0.02677151  0.21292855  0.42721894]\n",
            "[ 0.06169332  0.41230002 -0.21305892 -1.0549637 ]\n",
            "[-0.19190134 -0.9361151   0.22248615  1.5872319 ]\n",
            "[-0.1316683  -0.23281585  0.21418734  0.7818087 ]\n",
            "[ 0.14106666  0.22882769 -0.2166063  -0.6989484 ]\n",
            "[ 0.1103731   0.02244258 -0.21818848 -0.41800043]\n",
            "[ 0.09521934  0.5714938  -0.21185207 -1.1881357 ]\n",
            "[ 0.13346934  0.81705993 -0.22950436 -1.5345347 ]\n",
            "[-0.22698204 -1.1530845   0.21247622  1.7244776 ]\n",
            "[ 0.3004258   2.4672568  -0.23595828 -2.986179  ]\n",
            "[ 0.177273    0.6025904  -0.22595866 -1.2381303 ]\n",
            "[ 0.11425269  0.9546971  -0.21977185 -1.7607169 ]\n",
            "[-0.20448871 -1.1798284   0.21010986  1.9029119 ]\n",
            "[ 0.14391056  1.0135915  -0.22250834 -1.6430042 ]\n",
            "[-0.11149465 -0.23048826  0.21533416  0.80770004]\n",
            "[-0.0891907  -0.6390372   0.22138157  1.3330683 ]\n",
            "[ 0.1485914   0.5721249  -0.21084541 -1.2491549 ]\n",
            "[ 0.02008652 -0.22757907  0.21852772  1.3574833 ]\n",
            "[ 0.03568894 -0.46373978  0.2351189   1.6703203 ]\n",
            "[ 0.13772282  0.7896826  -0.2223779  -1.5534285 ]\n",
            "[-0.20487534 -0.2420155   0.2136383   0.5795024 ]\n",
            "[-0.09416966 -1.1538081   0.23481916  2.0194213 ]\n",
            "[ 0.136048    0.58493656 -0.21125238 -1.1811188 ]\n",
            "[ 0.25802872  1.7833163  -0.25084263 -2.7197227 ]\n",
            "[ 0.14065547  1.0249968  -0.2168104  -1.7165364 ]\n",
            "[-0.06370834 -0.978771    0.21928714  1.8591524 ]\n",
            "[-0.19769773 -0.40610453  0.22905216  0.8147434 ]\n",
            "[ 0.1185559   0.58536375 -0.20982318 -1.0267932 ]\n",
            "[ 0.05267249  1.1350886  -0.21092087 -2.029062  ]\n",
            "[-0.09298722 -1.0331875   0.22486734  1.7579113 ]\n",
            "[ 0.12505235  0.3944415  -0.21601164 -0.9280466 ]\n",
            "[-0.11457177 -0.80730754  0.23837315  1.5709076 ]\n",
            "[-0.15479532 -1.4056274   0.21698633  2.1742146 ]\n",
            "[-0.01594603 -0.58020437  0.22701424  1.4298979 ]\n",
            "[-0.05192943 -0.17951663  0.2120175   0.61553425]\n",
            "[ 0.17530335  0.21944958 -0.22626394 -0.7230886 ]\n",
            "[ 0.12644017  1.4123058  -0.22402836 -2.2473884 ]\n",
            "[-0.11113222 -1.5281475   0.23892951  2.5115256 ]\n",
            "[ 0.24263616  1.1770406  -0.24156326 -1.7565763 ]\n",
            "[ 0.08352112  0.5572801  -0.21822403 -1.1841227 ]\n",
            "[ 0.47013494  1.112747   -0.2096644  -0.97891974]\n",
            "[-0.09554982 -0.6137987   0.21108966  1.3276273 ]\n",
            "[-0.1017649  -0.596527    0.22072676  1.3371491 ]\n",
            "[-0.19565563 -0.99200916  0.21279569  1.630717  ]\n",
            "[ 0.09290869  1.0231376  -0.2143703  -1.9629791 ]\n",
            "[ 0.08268348  0.82727766 -0.23498847 -1.5864029 ]\n",
            "[ 0.11867044  0.03545569 -0.21210872 -0.5373207 ]\n",
            "[ 0.1008646   0.43899012 -0.21353005 -0.9390966 ]\n",
            "[-0.07193038 -0.5818571   0.22649902  1.2651998 ]\n",
            "[-0.12368692  0.1797558   0.21571314  0.16475753]\n",
            "[-0.10761809 -1.0151969   0.20990801  1.9261607 ]\n",
            "[ 0.4451503  1.7006137 -0.2294923 -1.9676733]\n",
            "[ 0.17714572  1.2264427  -0.21284404 -1.942696  ]\n",
            "[-0.12712161 -0.83285564  0.21809888  1.3953799 ]\n",
            "[ 0.12852125  0.37707776 -0.22483513 -1.0096898 ]\n",
            "[ 0.10870212  0.22497168 -0.22213231 -0.92224634]\n",
            "[-0.11314964 -1.1399485   0.2298382   1.957583  ]\n",
            "[-0.10436435 -0.7840596   0.22870137  1.637659  ]\n",
            "[ 0.03245044  0.44690922 -0.21413085 -1.1455882 ]\n",
            "[ 0.18709996  0.6243597  -0.21614061 -1.1005261 ]\n",
            "[ 0.08855513  0.19969219 -0.21444388 -0.8026968 ]\n",
            "[-0.1766896  -1.1428267   0.22529145  1.9348141 ]\n",
            "[ 0.16941692  1.0417452  -0.23791336 -1.85815   ]\n",
            "[-0.04165293 -0.98594373  0.2112124   1.9435022 ]\n",
            "[-0.1331076  -0.6134652   0.23664348  1.1406704 ]\n",
            "[-0.12809595 -0.45456037  0.21173982  1.0236752 ]\n",
            "[-0.12197441 -0.55241376  0.21251768  1.2238078 ]\n",
            "[-0.23722707 -1.7204382   0.2362154   2.489085  ]\n",
            "[ 0.14350656  0.58160824 -0.23430973 -1.1694977 ]\n",
            "[ 0.11381996  0.9721293  -0.21608827 -1.6596863 ]\n",
            "[-0.16006908 -0.583185    0.22812387  1.0353513 ]\n",
            "[ 0.23509613  0.6304847  -0.22627664 -1.4153676 ]\n",
            "[ 0.14128858  0.94114286 -0.22431009 -1.5793235 ]\n",
            "[-0.18265119 -0.8387795   0.2391105   1.5387874 ]\n",
            "[-0.08112373  0.4134279  -0.2346813  -1.849918  ]\n",
            "[ 0.29229105  0.91373247 -0.21651204 -1.1610047 ]\n",
            "[ 0.04317426  0.62873924 -0.21094663 -1.3949555 ]\n",
            "[-0.18482436 -0.5529165   0.20960258  1.1319256 ]\n",
            "[-0.12980576 -1.1673969   0.24673983  1.9685878 ]\n",
            "[-0.23166944 -1.2163743   0.22679658  1.9347557 ]\n",
            "[-0.12085178 -0.79666066  0.20987995  1.3649342 ]\n",
            "[ 0.0661724  1.206988  -0.2389925 -2.2761586]\n",
            "[ 0.12414738  0.42409137 -0.2227933  -0.9958833 ]\n",
            "[-0.23486206 -1.1228846   0.22084811  1.4323575 ]\n",
            "[-0.08708262 -0.5566988   0.22333334  1.2936016 ]\n",
            "[ 0.08783253  0.75136    -0.23003744 -1.4358277 ]\n",
            "[-0.11927797 -0.8184502   0.21184763  1.6345406 ]\n",
            "[-0.21919098 -0.42220134  0.22283955  0.8542571 ]\n",
            "[-0.15921538 -0.452816    0.22305362  0.97466797]\n",
            "[-0.07023939 -0.27229106  0.22145599  1.1822028 ]\n",
            "[ 0.14260069  1.3480583  -0.22779481 -2.3582532 ]\n",
            "[-0.1381054 -0.9643925  0.210264   1.7198266]\n",
            "[ 0.13657285  0.26162043 -0.2140614  -0.8251496 ]\n",
            "[ 0.05298869  0.24217312 -0.21562044 -0.8844433 ]\n",
            "[-0.19490746 -1.1776525   0.22720708  1.8520932 ]\n",
            "[ 0.14332993  0.96845686 -0.21076111 -1.6914057 ]\n",
            "[ 0.17842893  0.44248396 -0.21080256 -0.9434266 ]\n",
            "[-0.7781909  -1.3111391   0.22791149  1.440766  ]\n",
            "[-0.27054703  1.6018342  -0.26396498 -3.1737862 ]\n",
            "[-0.09553878 -0.45519885  0.23220725  1.0069151 ]\n",
            "[-0.03243596 -0.0022922   0.22190452  0.6944841 ]\n",
            "[-0.11018195 -1.2006013   0.22851916  2.0019855 ]\n",
            "[ 0.15762672  1.2063518  -0.23754857 -2.024828  ]\n",
            "[-0.1559045  -1.201795    0.25208697  1.976568  ]\n",
            "[ 0.1244497   0.7457107  -0.23144557 -1.4851379 ]\n",
            "[ 0.09553619  1.140773   -0.22631699 -1.9570816 ]\n",
            "[-0.14502153 -1.5234705   0.22972766  2.4123247 ]\n",
            "[-0.04138579 -0.5153349  -0.21044089 -0.20916277]\n",
            "[-0.04752232 -0.57108766  0.22429058  1.247453  ]\n",
            "[-0.20836473 -0.9724232   0.20989046  1.3253382 ]\n",
            "[ 0.49583802  2.1483865  -0.24529138 -2.3834355 ]\n",
            "[-0.13906732 -0.9830305   0.22624417  1.8069667 ]\n",
            "[ 0.00310082  0.3676529  -0.20989192 -1.2138679 ]\n",
            "[ 0.11703233  0.7986744  -0.22775698 -1.5444101 ]\n",
            "[-0.03956024 -0.35993603  0.21723391  0.9415618 ]\n",
            "[ 0.13965312  0.228947   -0.21157078 -0.80206203]\n",
            "[ 0.12468816  0.24556349 -0.21849485 -0.6062346 ]\n",
            "[ 0.04580129 -0.1838096  -0.21339037 -0.29097858]\n",
            "[-0.17697605 -0.766508    0.22097224  1.4604439 ]\n",
            "[-0.1472627 -1.5626293  0.2424524  2.5090172]\n",
            "[-0.16312271 -1.5716213   0.24387822  2.5277438 ]\n",
            "[ 0.09548015  0.45804784 -0.21072404 -1.392347  ]\n",
            "[-0.18681304 -0.7664314   0.23680098  1.4561918 ]\n",
            "[ 0.12918498  1.035989   -0.24013457 -2.0015688 ]\n",
            "[-0.27012625 -1.1028358   0.21829534  1.2484694 ]\n",
            "[-0.12497265 -1.5241779   0.21294288  2.5755777 ]\n",
            "[ 0.08835122  0.36376455 -0.21027476 -0.96446204]\n",
            "[ 0.05560466  1.1963558  -0.21319939 -2.0245733 ]\n",
            "[-0.10444687 -1.023174    0.21305923  1.8745403 ]\n",
            "[ 0.1411061   1.3310751  -0.24400362 -2.318183  ]\n",
            "[-0.11725043 -0.83182126  0.23256041  1.6350337 ]\n",
            "[-0.08769365 -1.5882276   0.24087426  2.5863314 ]\n",
            "[ 0.20896518  1.5232321  -0.24214035 -2.0765865 ]\n",
            "[-0.02671223 -0.5995392   0.22612476  1.4752682 ]\n",
            "[ 0.16703412  0.5993145  -0.23329021 -1.1104841 ]\n",
            "[-0.13946179 -0.24441507  0.22943321  0.8117665 ]\n",
            "[ 0.19466609  1.4056553  -0.21911967 -2.121565  ]\n",
            "[-0.18285531 -0.40326396  0.21651654  1.0612619 ]\n",
            "[ 0.1006837   1.1720003  -0.22118136 -2.011436  ]\n",
            "[-0.1633633 -0.5645104  0.2328181  1.1717967]\n",
            "[ 0.16704436  1.1275566  -0.21783972 -1.9324242 ]\n",
            "[ 0.07509985  0.8092201  -0.23502    -1.6733341 ]\n",
            "[-0.07612725 -0.6261846   0.22623459  1.212183  ]\n",
            "[-0.06833419 -1.1684369   0.24445197  2.2020237 ]\n",
            "[-0.08624565 -0.6291848   0.24079658  1.400326  ]\n",
            "[-0.13859206 -1.1652827   0.2357827   1.7156128 ]\n",
            "[ 0.07299471 -0.34458303 -0.21511748 -0.10273148]\n",
            "[-0.15313767 -0.7622795   0.21203814  1.4526321 ]\n",
            "[ 0.11778244  1.1840334  -0.23512879 -2.2075431 ]\n",
            "[ 0.1235728   0.7421913  -0.21980058 -1.3432124 ]\n",
            "[ 0.21584734  0.43217427 -0.23323375 -1.0013759 ]\n",
            "[-0.06711928 -0.9519475   0.21069232  1.9486288 ]\n",
            "[-0.38875714 -0.5772756   0.22187118  0.7241648 ]\n",
            "[ 0.10382432  1.0280278  -0.21555836 -1.8336637 ]\n",
            "[-0.03616003  0.17617099 -0.21471374 -0.92149824]\n",
            "[-0.11835762 -0.44663608  0.22085154  1.0156085 ]\n",
            "[-0.02270482  0.15290551  0.21814504  0.32260603]\n",
            "[-0.13861395 -0.6160044   0.21207535  1.3245982 ]\n",
            "[-0.15853006 -1.2269794   0.21947229  1.9909835 ]\n",
            "[-0.03504068 -0.6583548   0.23133159  1.643851  ]\n",
            "[-0.41071692 -1.9158292   0.2194314   2.1276448 ]\n",
            "[-0.05558152 -0.6586041   0.2096223   1.5680692 ]\n",
            "[-0.14385357 -0.18212408  0.2178042   0.64805764]\n",
            "[-0.18243405 -0.98635197  0.21014558  1.6762434 ]\n",
            "[ 0.08811522  0.83231735 -0.21451896 -1.4169482 ]\n",
            "[ 0.07520001  0.56698453 -0.21743202 -1.224613  ]\n",
            "[-0.07396798 -0.60739064  0.22846234  1.1418213 ]\n",
            "[-0.3582014  -0.61099344  0.2121896   0.5569364 ]\n",
            "[ 0.00368123  0.7526153  -0.2112611  -1.6804937 ]\n",
            "[-0.10582886 -0.24075915  0.2166452   0.62675065]\n",
            "[-0.15227602  0.05074565 -0.21594311 -1.5526309 ]\n",
            "[ 0.11158605  0.5549628  -0.23224168 -1.2079917 ]\n",
            "[-0.1025413  -1.5821717   0.24687923  2.6469307 ]\n",
            "[-0.6494994  -0.32717204 -0.23027928 -0.9810783 ]\n",
            "[ 0.0957933   0.9455502  -0.20949307 -1.6513181 ]\n",
            "[-0.14559814 -1.1998044   0.23841289  1.8185123 ]\n",
            "[-0.09823634 -0.1806247   0.220681    0.8134791 ]\n",
            "[ 0.02528812  0.07173222 -0.23191367 -1.1488163 ]\n",
            "[ 0.13815808  0.01854599 -0.21505061 -0.62175995]\n",
            "[ 0.14753689  0.79923666 -0.2178961  -1.5790544 ]\n",
            "[ 0.20069972  1.6003798  -0.2442714  -2.5032043 ]\n",
            "[ 0.03181212  0.0371465  -0.21761763 -0.61781853]\n",
            "[-0.12079077 -0.56111646  0.22306187  1.3137984 ]\n",
            "[ 0.15145938  0.6320684  -0.20946722 -1.1442013 ]\n",
            "[-0.03979881 -0.6191314   0.23224889  1.5448943 ]\n",
            "[ 0.12858458  0.94604003 -0.22989102 -1.784878  ]\n",
            "[-0.15065375 -1.407597    0.23156342  2.3767014 ]\n",
            "[-0.24501784 -0.7382607   0.21464765  1.1751152 ]\n",
            "[ 0.05738951  0.57946694 -0.22173697 -1.6276249 ]\n",
            "[ 0.26929086  0.9999972  -0.24261886 -1.5110741 ]\n",
            "[-0.08910228 -1.158213    0.21060756  2.0088205 ]\n",
            "[-0.1532946  -0.5978674   0.21073636  1.0792344 ]\n",
            "[ 0.14019057  1.0094353  -0.23410593 -1.7683376 ]\n",
            "[ 0.17486121  0.8347257  -0.23072664 -1.4297801 ]\n",
            "[ 0.12056319 -0.39393854 -0.21192475 -0.17274705]\n",
            "[-0.06399928 -0.7951398   0.21424879  1.4608281 ]\n",
            "[-0.14735606 -0.24980976  0.21371196  0.8417125 ]\n",
            "[ 0.02330797 -0.3893968  -0.21692276 -0.30249727]\n",
            "[ 0.09731678  0.6363233  -0.22133097 -1.356121  ]\n",
            "[ 0.05066852 -0.18324594  0.22019011  1.1767937 ]\n",
            "[ 0.2048824   1.3812928  -0.23739018 -2.2135348 ]\n",
            "[ 0.14170092  1.5091763  -0.24397123 -2.3790333 ]\n",
            "[ 0.14334509  0.98939145 -0.24253896 -1.7963338 ]\n",
            "[-0.20032328 -0.5694909   0.21888837  1.1305757 ]\n",
            "[ 0.19519494  1.765027   -0.23377581 -2.547241  ]\n",
            "[ 0.12246011  0.9960678  -0.21073608 -1.8004676 ]\n",
            "[-0.11126432 -0.801138    0.23340249  1.6208444 ]\n",
            "[-0.09561562 -0.42468673  0.22597857  1.0576702 ]\n",
            "[ 0.20689946  0.269856   -0.22910713 -0.918229  ]\n",
            "[-0.09418931 -0.6305493   0.21465436  1.4340135 ]\n",
            "[-0.01161338  0.01115855  0.21160951  0.63901377]\n",
            "[-0.19187501 -1.2163955   0.22653928  1.9108151 ]\n",
            "[ 0.12052746  0.8114198  -0.21745522 -1.5143942 ]\n",
            "[ 5.8490559e-02  2.1774368e-04 -2.1924041e-01 -5.9278578e-01]\n",
            "[-0.16466641 -0.76260376  0.21763575  1.3924812 ]\n",
            "[-0.12728864 -0.76567364  0.23189752  1.4909143 ]\n",
            "[ 0.15026373  0.27230895 -0.22018039 -1.1285318 ]\n",
            "[-0.09514337  0.0078343   0.2136222   0.5755041 ]\n",
            "[ 0.12148333  0.55544096 -0.23628014 -1.2162186 ]\n",
            "[ 0.12106849  1.406449   -0.21645287 -2.2761185 ]\n",
            "[ 0.16258337  0.82762975 -0.23091711 -1.5198886 ]\n",
            "[-0.14533067 -0.96774226  0.22633182  1.689219  ]\n",
            "[-0.0891232  -1.0149173   0.23936352  1.9340786 ]\n",
            "[ 0.20762359  0.73376286 -0.22090825 -1.1926153 ]\n",
            "[ 0.12932007  0.2332747  -0.22658986 -0.7879518 ]\n",
            "[-0.12988302 -0.5738636   0.21907058  1.266384  ]\n",
            "[ 0.11188817  0.42900774 -0.2249357  -0.93328744]\n",
            "[ 0.13123974  0.36256096 -0.22638655 -0.9765667 ]\n",
            "[ 0.10839432  0.56427675 -0.21389295 -1.2553483 ]\n",
            "[-0.15224303 -1.3449144   0.23509316  2.194397  ]\n",
            "[-0.20884353 -0.99345905  0.20965959  1.5352727 ]\n",
            "[ 0.16979848  0.6399491  -0.22087382 -1.2407187 ]\n",
            "[-0.12446374 -0.7843417   0.24216957  1.4413421 ]\n",
            "[-0.12228332 -1.0009805   0.21222782  1.8746015 ]\n",
            "[ 0.21653649  1.3771065  -0.22680534 -1.9452243 ]\n",
            "[ 0.15552363  1.9472123  -0.21095058 -2.7672493 ]\n",
            "[ 0.19782497  0.8128538  -0.21148437 -1.4185328 ]\n",
            "[-0.15195851 -0.43401957  0.23424071  1.0673263 ]\n",
            "[-0.10827366 -0.39919877  0.20962873  1.0270836 ]\n",
            "[ 0.1077764   0.3835614  -0.21612291 -1.075916  ]\n",
            "[-0.10473509 -0.27545583  0.21579823  1.0473609 ]\n",
            "[ 0.1414592   0.5981989  -0.21094769 -1.2576433 ]\n",
            "[ 0.1680086  0.779097  -0.2378711 -1.4808775]\n",
            "[ 0.12756965 -0.34989777 -0.20957577  0.12347708]\n",
            "[-0.131413   -0.04189738  0.2097866   0.48206285]\n",
            "[ 0.09930481  1.2025969  -0.21214816 -2.1049    ]\n",
            "[-0.07173384  0.14305548  0.21682225  0.33652785]\n",
            "[-0.12342793 -0.59332824  0.2368623   1.2370582 ]\n",
            "[ 0.1812037  1.1557468 -0.2140877 -1.9517592]\n",
            "[ 0.13000175  0.8213459  -0.22246681 -1.5163443 ]\n",
            "[-0.24085212 -1.1739894   0.22961931  1.866566  ]\n",
            "[-0.0631633  -0.46365997  0.21534829  1.2525551 ]\n",
            "[-0.07228167 -0.57602346  0.21876061  1.4051526 ]\n",
            "[-0.21540317 -1.9097528   0.24094142  2.8262203 ]\n",
            "[ 0.14978307  0.9873627  -0.22989213 -1.752172  ]\n",
            "[ 0.14638671  1.0331185  -0.21158123 -1.7844826 ]\n",
            "[ 0.15280865  0.59144187 -0.22784555 -1.2808245 ]\n",
            "[-0.1611691  -0.81955636  0.2187613   1.5514138 ]\n",
            "[0.13978083 0.2825042  0.21462119 0.88945514]\n",
            "[0.23785575 1.14213    0.21199611 0.01549599]\n",
            "[ 0.10424972  0.5967428  -0.23424602 -1.4224945 ]\n",
            "[-0.1259922  -1.2319567   0.22454391  2.056637  ]\n",
            "[-0.48894134 -0.7550462   0.22661977  1.1299415 ]\n",
            "[ 0.13109235  0.99410933 -0.22945224 -1.694783  ]\n",
            "[ 0.07270034  0.77890015 -0.24100685 -1.5475906 ]\n",
            "[-0.10724364 -0.01357122  0.22545978  0.63299775]\n",
            "[-0.21257293 -0.6027682   0.22382751  1.1232904 ]\n",
            "[ 0.18020244  1.227702   -0.22597423 -1.9644858 ]\n",
            "[-0.10629255 -0.75662553  0.23492032  1.4061141 ]\n",
            "[ 0.15461977  1.3834177  -0.23721495 -2.23259   ]\n",
            "[-0.15729015 -1.7159206   0.21821219  2.659524  ]\n",
            "[-0.11052316 -1.1920162   0.23569432  2.0721514 ]\n",
            "[ 0.09977161  1.0099094  -0.23281032 -1.8282146 ]\n",
            "[ 0.07333992  1.154664   -0.2223132  -2.1657085 ]\n",
            "[ 0.10049018  0.24880369 -0.20980357 -0.7926273 ]\n",
            "[ 0.06466965 -0.30944145 -0.2118159  -0.25203592]\n",
            "[-0.15942837 -0.40727818  0.23119369  0.90585876]\n",
            "[-0.11155571  0.3297577   0.21559688  0.12341961]\n",
            "[-0.01457771 -0.3943094   0.24139851  1.4499247 ]\n",
            "[-0.18798283 -0.765682    0.21605562  1.4266381 ]\n",
            "[ 0.00963602 -0.01197123 -0.21662472 -0.8014858 ]\n",
            "[ 0.2267814   1.1456953  -0.23918025 -1.9019965 ]\n",
            "[ 0.07073411  0.60394114 -0.23245765 -1.6222061 ]\n",
            "[ 0.026977    0.25741068 -0.22211488 -0.9538072 ]\n",
            "[-0.15280147 -1.6148608   0.2309346   2.630971  ]\n",
            "[-0.09595523 -0.62741816  0.21457945  1.2660435 ]\n",
            "[-0.11953303 -1.3601934   0.2484548   2.3123696 ]\n",
            "[-0.16122109 -0.3540367   0.21488181  0.7857945 ]\n",
            "[-0.17463407 -0.06176674  0.21331905  0.6690007 ]\n",
            "[-0.08259646 -0.3832027   0.21414706  1.2295102 ]\n",
            "[ 0.17684919  1.1517833  -0.21763177 -1.865434  ]\n",
            "[ 0.16240351  0.74832577 -0.22860953 -1.349852  ]\n",
            "[-0.11115822 -1.2152092   0.22047925  2.0401444 ]\n",
            "[ 0.15927756  0.4319719  -0.22401126 -0.8491999 ]\n",
            "[-0.10010363 -0.45117292  0.21155299  1.1212444 ]\n",
            "[ 0.3668119   1.1343     -0.23335382 -1.3964809 ]\n",
            "[-0.06269314 -0.9328574   0.21218964  1.6220618 ]\n",
            "[ 0.24123922  1.4040135  -0.23715895 -2.179552  ]\n",
            "[ 0.17995383  0.6442364  -0.2097662  -1.1264166 ]\n",
            "[-0.21243097 -0.78330624  0.23696363  1.4155453 ]\n",
            "[ 0.0084832   0.19649568 -0.21563943 -0.93225676]\n",
            "[-0.16538617 -1.1324241   0.25080556  2.0652895 ]\n",
            "[-0.17464678 -0.39431947  0.2134545   0.8425764 ]\n",
            "[-0.42959502 -1.008241    0.23607194  1.1500214 ]\n",
            "[-0.07465107 -0.7703479   0.22230701  1.4958712 ]\n",
            "[-0.12405818 -1.3927956   0.23350446  2.3252988 ]\n",
            "[ 0.07068608  0.60963464 -0.21023035 -1.2071831 ]\n",
            "[-0.12277636 -0.7435692   0.21553966  1.4206166 ]\n",
            "[ 0.10882821  1.5987048  -0.22813533 -2.5749886 ]\n",
            "[ 0.08085307  0.44026297 -0.23138589 -1.0848422 ]\n",
            "[-0.12554535 -1.4183364   0.24686879  2.275348  ]\n",
            "[-0.07792985 -0.42613435  0.21206817  1.127407  ]\n",
            "[-0.12171639 -1.6159414   0.25024965  2.6205802 ]\n",
            "[-0.09645989 -0.647374    0.21227716  1.4576639 ]\n",
            "[ 0.1216469   0.42801565 -0.22548027 -1.1655698 ]\n",
            "[-0.09407534 -0.17935148  0.23005669  0.8989396 ]\n",
            "[-0.06803532  0.01909727  0.21562499  0.4649339 ]\n",
            "[ 0.08437958  0.37658247 -0.23516126 -1.1507558 ]\n",
            "[ 0.06308797  0.3979806  -0.23163882 -1.0222995 ]\n",
            "[ 0.18048564  0.26134568 -0.21638142 -0.77892494]\n",
            "[-0.13898747 -0.59925     0.22654985  1.2566073 ]\n",
            "[ 0.08785123  1.016109   -0.21350476 -2.0374136 ]\n",
            "[ 0.1776374   1.5790274  -0.25196174 -2.4510336 ]\n",
            "[ 0.12246381  1.1368501  -0.23892148 -1.867797  ]\n",
            "[ 0.15007861  0.63094085 -0.21681754 -1.3912824 ]\n",
            "[-0.12148874 -1.164686    0.24742576  2.0047085 ]\n",
            "[-0.15990087 -1.1676836   0.22075525  1.9719222 ]\n",
            "[ 0.16952781  0.9923012  -0.22570246 -1.7028522 ]\n",
            "[-0.10532089 -1.2162516   0.23852229  2.0219429 ]\n",
            "[-0.04607094 -0.22618195  0.22619133  0.97219026]\n",
            "[ 0.16122827  1.6167575  -0.22488748 -2.5586724 ]\n",
            "[ 0.18696034  0.63739395 -0.22995816 -1.1138383 ]\n",
            "[-0.12474176 -0.37995437  0.23087665  0.989967  ]\n",
            "[-0.16984561 -1.5568502   0.25021636  2.5542212 ]\n",
            "[-0.11919232 -0.8270303   0.23030044  1.6951896 ]\n",
            "[ 0.08647048  0.41154394 -0.22136797 -0.9073533 ]\n",
            "[-0.05390058 -0.8338644   0.21590815  1.6500722 ]\n",
            "[-0.14547631 -0.82214886  0.21934949  1.4476975 ]\n",
            "[-0.12882563 -1.0274796   0.233475    1.7525876 ]\n",
            "[ 0.06714521  0.95044833 -0.21098964 -1.883956  ]\n",
            "[-0.17189695 -0.7970937   0.21339105  1.4551269 ]\n",
            "[ 0.15497088  0.5837567  -0.22380099 -1.2549155 ]\n",
            "[ 0.18052544  1.1998849  -0.24458969 -1.9778967 ]\n",
            "[-0.19138108 -0.9444079   0.22943716  1.6792194 ]\n",
            "[-0.09307035  0.12261505  0.21794757  0.24786435]\n",
            "[-0.10550281 -0.56177515  0.22461905  1.2985746 ]\n",
            "[-0.22106549 -0.43102184  0.21486923  0.9680263 ]\n",
            "[-0.09515248 -0.83069134  0.23049378  1.6599933 ]\n",
            "[-0.09931394 -0.60416627  0.23590833  1.2646524 ]\n",
            "[ 0.1306377   0.4172313  -0.21177016 -0.95703727]\n",
            "[-0.15980668 -0.80311525  0.22336645  1.6091411 ]\n",
            "[-0.12489042 -0.5607901   0.21510477  1.0288671 ]\n",
            "[-0.23219036 -0.15111841 -0.21148218 -0.8816553 ]\n",
            "[ 0.12686774  0.00664261 -0.21908903 -0.5115164 ]\n",
            "[-0.22735067 -0.6255466   0.21576007  0.94015294]\n",
            "[-0.15693122 -1.5640066   0.23816526  2.5446918 ]\n",
            "[-0.18076327 -1.218266    0.22674794  1.9450549 ]\n",
            "[ 0.00665497 -0.3874067   0.21415624  1.2920812 ]\n",
            "[ 0.3625495   2.0556257  -0.24271433 -2.3085022 ]\n",
            "[ 0.0417725   0.5808943  -0.22292176 -1.3548621 ]\n",
            "[-0.1492553  -1.5339651   0.21104126  2.5318058 ]\n",
            "[ 0.13731419  0.8004101  -0.22065514 -1.4300016 ]\n",
            "[-0.08716894 -0.26860216  0.21991006  1.0741673 ]\n",
            "[-0.12477789 -0.8166312   0.23450224  1.9114088 ]\n",
            "[-0.0966222  -0.9417338   0.22197907  1.6258541 ]\n",
            "[ 0.21206228  1.5464462  -0.22110288 -2.4588184 ]\n",
            "[-0.063768   -0.5883066   0.21828884  1.2455964 ]\n",
            "[ 0.06259085  0.5621326  -0.21413915 -1.2990588 ]\n",
            "[-0.16975768 -1.2129192   0.23223655  2.0521657 ]\n",
            "[-0.00834536 -1.1683192   0.23472208  2.3294003 ]\n",
            "[ 0.16217972  0.26748225 -0.22190796 -0.8804156 ]\n",
            "[ 0.20653087  1.0292236  -0.23338774 -1.612225  ]\n",
            "[ 0.12493614  0.19368137 -0.22872932 -0.89126223]\n",
            "[ 0.16895765  0.43338874 -0.2129511  -0.7972316 ]\n",
            "[ 0.12725623  1.0099158  -0.22959569 -1.851462  ]\n",
            "[ 0.13474965  0.583071   -0.2114926  -1.0048059 ]\n",
            "[-0.07397404 -0.6094597   0.20954056  1.2344277 ]\n",
            "[-0.20090234 -0.99426496  0.2295317   1.7278461 ]\n",
            "[ 0.1160702   0.00157815 -0.21817073 -0.42052606]\n",
            "[-0.10763694 -0.5723519  -0.21326871 -0.15741299]\n",
            "[ 0.13736941  1.3657627  -0.2370764  -2.235502  ]\n",
            "[-0.09367191 -1.6088634   0.23630318  2.633386  ]\n",
            "[ 0.16479276  1.1635128  -0.22176813 -2.021481  ]\n",
            "[ 0.13058443  0.4111104  -0.21724646 -0.85367274]\n",
            "[-0.14399755 -0.27629912  0.23532817  1.0964268 ]\n",
            "[-0.18772607 -1.3937584   0.22910844  1.9215273 ]\n",
            "[ 0.1752043   1.3843955  -0.25302464 -2.262168  ]\n",
            "[-0.2000712  -1.570138    0.21183904  2.356339  ]\n",
            "[ 0.24353392 -0.14723964 -0.21311598 -0.29525235]\n",
            "[-0.1370669  -0.24062851  0.22072582  0.67629254]\n",
            "[ 0.16390608  0.38271296 -0.21595336 -0.8040601 ]\n",
            "[-0.05057512 -1.1554246   0.22491878  2.1581748 ]\n",
            "[ 0.15592082  0.6065     -0.2211062  -1.0450916 ]\n",
            "[-0.08538738  0.57301766 -0.21074736 -1.4013838 ]\n",
            "[-0.18144295 -1.0105246   0.23789662  1.8166821 ]\n",
            "[-0.02473134 -0.60187143  0.22362764  1.3601629 ]\n",
            "[ 0.11602344  1.3743984  -0.24648052 -2.3438516 ]\n",
            "[-0.17366405 -1.3528996   0.24288218  2.4059298 ]\n",
            "[-0.03165387 -0.6039856   0.24142237  1.4921197 ]\n",
            "[-0.10861044 -0.9548089   0.24856573  1.7565731 ]\n",
            "[-0.11558888 -0.6394518   0.21835828  1.2402756 ]\n",
            "[ 0.12989269  1.1422184  -0.23658139 -2.0031683 ]\n",
            "[ 0.16673483  1.2207032  -0.21121022 -1.8365151 ]\n",
            "[ 0.14380604  1.1675142  -0.21792814 -1.9706959 ]\n",
            "[-0.19568484 -1.1686385   0.24582838  1.8737729 ]\n",
            "[-0.06479141 -0.7719267   0.22138509  1.4413383 ]\n",
            "[ 0.16966675  1.1597818  -0.24133943 -2.040105  ]\n",
            "[ 0.07863097  1.5380452  -0.21641266 -2.5854895 ]\n",
            "[ 0.17428796  0.4579417  -0.21492578 -1.0897846 ]\n",
            "[-0.07991196 -0.55135983  0.22352628  1.1553324 ]\n",
            "[ 0.12322189  1.0062401  -0.23074497 -1.8221287 ]\n",
            "[-0.21775118 -1.3847072   0.22446007  2.091965  ]\n",
            "[-0.12353445 -0.9622178   0.22675368  1.7741805 ]\n",
            "[-0.09980434  0.18109965  0.21402778  0.28075984]\n",
            "[ 0.09089379  0.2030465  -0.21956535 -0.9932704 ]\n",
            "[-0.11876629 -1.3710912   0.22693814  2.2436144 ]\n",
            "[ 0.09924623  1.0280681  -0.23355186 -1.8258566 ]\n",
            "[ 0.12167284  0.95034516 -0.2503463  -1.8317472 ]\n",
            "[ 0.08101897  1.1648827  -0.22017422 -2.1885247 ]\n",
            "[-0.05215325 -0.9499104   0.23267615  1.8390439 ]\n",
            "[-0.07791147 -0.8159936   0.21778025  1.6089312 ]\n",
            "[ 0.10293868  0.17697264 -0.22563893 -0.9665586 ]\n",
            "[ 0.2761611   1.0112625  -0.22469644 -1.4124559 ]\n",
            "[ 0.16431564  0.95510495 -0.21285404 -1.7302982 ]\n",
            "[-0.15719756 -0.79571944  0.23185924  1.5424132 ]\n",
            "[ 0.15814199  0.2447195  -0.21244943 -0.6176268 ]\n",
            "[-0.13834007 -1.5189404   0.22051238  2.6059937 ]\n",
            "[ 0.12013303  1.5906621  -0.24637327 -2.549445  ]\n",
            "[ 0.13653405  1.7794273  -0.2281979  -2.813928  ]\n",
            "[ 0.14682056  1.035122   -0.22650714 -1.7759746 ]\n",
            "[-0.09230827  0.61964816 -0.23164773 -1.7717073 ]\n",
            "[ 0.09755585  0.9517744  -0.2280551  -1.7969725 ]\n",
            "[ 0.25550804  1.1976286  -0.2428549  -2.0220203 ]\n",
            "[ 0.03837448  0.40888473 -0.23390329 -1.2106549 ]\n",
            "[-0.19081946 -1.3899142   0.24158059  2.0812201 ]\n",
            "[-0.18686539 -0.2573051   0.2196712   0.6072371 ]\n",
            "[ 0.10756129 -0.01221772 -0.21771392 -0.39119977]\n",
            "[ 0.10829222  1.195986   -0.22427104 -1.968061  ]\n",
            "[ 0.19767572  0.24727316 -0.22392178 -0.62552947]\n",
            "[-0.13261522 -0.4220716   0.21136351  1.0692663 ]\n",
            "[-0.09002219  0.14548002  0.21239763  0.52795666]\n",
            "[-0.2575437  -1.7215877   0.23512608  2.630081  ]\n",
            "[ 0.24133997  1.5473627  -0.22386158 -2.3959148 ]\n",
            "[ 0.02417615  0.56480354 -0.22406335 -1.5272292 ]\n",
            "[ 0.12549214  0.57296157 -0.22400346 -1.0801102 ]\n",
            "[-0.10993353 -0.9972563   0.2101813   1.7458652 ]\n",
            "[ 0.20533577  1.1406711  -0.22423357 -1.7693399 ]\n",
            "[-0.09314713 -0.6469948   0.22036704  1.4697998 ]\n",
            "[ 0.01791419 -0.20039651  0.21923381  1.2067063 ]\n",
            "[-0.11236966 -0.36231017  0.21145289  0.986638  ]\n",
            "[ 0.14465174  1.3944578  -0.23943281 -2.4419982 ]\n",
            "[-1.0004172  -1.5966212  -0.21908839 -0.5963011 ]\n",
            "[-0.1404833 -0.3580135  0.2304679  1.0013298]\n",
            "[-0.08614114 -0.21381843  0.21716422  0.93872035]\n",
            "[-0.06892432 -0.39270818  0.22635287  1.247322  ]\n",
            "[ 0.1812365   1.7440501  -0.21578795 -2.7733617 ]\n",
            "[ 0.13011676  1.2040882  -0.21318908 -2.088029  ]\n",
            "[ 0.09210178  1.1787386  -0.24087243 -2.0171604 ]\n",
            "[-0.09197222 -0.56649745  0.22349513  1.2906076 ]\n",
            "[ 0.20261337  1.5455589  -0.24775839 -2.5445285 ]\n",
            "[-0.15037875 -1.1595039   0.2166332   2.051524  ]\n",
            "[ 0.13913554  0.38764703 -0.21497904 -0.938819  ]\n",
            "[ 0.14198585  0.6030601  -0.21930887 -1.2111692 ]\n",
            "[ 0.04817613  0.7663511  -0.22112738 -1.601405  ]\n",
            "[-0.13031067 -0.05065682  0.21062858  0.504725  ]\n",
            "[ 0.06197009  0.8006318  -0.23327687 -1.9186107 ]\n",
            "[-0.15834248 -1.9384809   0.22101334  2.9543824 ]\n",
            "[ 0.1982593   1.4135537  -0.23799783 -2.3192973 ]\n",
            "[-0.2521346 -1.382602   0.2369226  2.1562681]\n",
            "[ 0.17180935  1.0133348  -0.21765757 -1.4872743 ]\n",
            "[-0.0777266  -0.9548458   0.23823656  1.8133572 ]\n",
            "[ 0.09794599  0.44932127 -0.2238061  -1.171989  ]\n",
            "[ 0.06831384  0.2578147  -0.2147164  -0.9274553 ]\n",
            "[-0.13056538 -0.45078683  0.23095843  1.0857283 ]\n",
            "[-0.12085271 -0.76072186  0.23204684  1.6130438 ]\n",
            "[ 0.06918076  0.5540478  -0.21687433 -1.187119  ]\n",
            "[-0.13118222 -0.45299503  0.2326717   1.1224602 ]\n",
            "[ 0.20831822  1.7444518  -0.25674036 -2.8090303 ]\n",
            "[-0.11811576 -0.95170873  0.22887243  1.8886006 ]\n",
            "[-0.31899863 -1.709792    0.23566628  2.043762  ]\n",
            "[-0.01818221  0.7674987  -0.23843384 -2.0170252 ]\n",
            "[ 0.12990567  0.6398209  -0.21093227 -1.1504369 ]\n",
            "[ 0.2189382   0.7795656  -0.22380152 -1.2547983 ]\n",
            "[-0.06484758 -0.7839562   0.23481895  1.6684185 ]\n",
            "[-0.01836655  0.39435065 -0.22665218 -1.5978065 ]\n",
            "[-0.19580717 -1.0293052   0.24149019  1.7253898 ]\n",
            "[-0.10277125 -0.25202218  0.21255325  0.73471993]\n",
            "[ 0.1719008   0.7649505  -0.21768467 -1.4344403 ]\n",
            "[ 0.09603158  0.6072015  -0.23087609 -1.3384002 ]\n",
            "[-0.19072148 -0.7886501   0.21893914  1.5606633 ]\n",
            "[-0.20502806 -1.2010174   0.2264229   1.9518088 ]\n",
            "[ 0.13663664  0.40199482 -0.2229651  -0.83586484]\n",
            "[ 0.04286863  0.36120266 -0.22015777 -1.0451759 ]\n",
            "[-0.13050184 -0.7664235   0.21938789  1.5315915 ]\n",
            "[ 0.04866251  0.57700574 -0.21294765 -1.3277828 ]\n",
            "[ 0.03419058 -0.38740087  0.22170515  1.387271  ]\n",
            "[-0.13162945 -0.95411193  0.22472388  1.7736677 ]\n",
            "[-0.14944369 -0.6264883   0.21910669  1.0235362 ]\n",
            "[ 0.11035639  1.180542   -0.21574879 -1.9385872 ]\n",
            "[ 0.11572371  0.99289495 -0.2373566  -1.8415927 ]\n",
            "[-0.10393546 -0.9506727   0.22326732  1.8578961 ]\n",
            "[-0.953413   -1.1245699   0.21813828  0.24811491]\n",
            "[-0.36462817 -1.0077292   0.21637763  1.304087  ]\n",
            "[ 0.09727869  0.19897391 -0.21083605 -1.0251777 ]\n",
            "[ 0.13766542  0.6374216  -0.22481792 -1.1001407 ]\n",
            "[ 0.18020482 -0.01299314 -0.22003722 -0.48057118]\n",
            "[-0.23470446 -1.5782903   0.24860024  2.326267  ]\n",
            "[ 0.18960378  0.99838907 -0.23314151 -1.8014258 ]\n",
            "[0.08390371 0.47656184 0.22454326 0.6842208 ]\n",
            "[-0.15068214 -0.806652    0.23097822  1.5669744 ]\n",
            "[-0.09858031 -1.0083364   0.23220608  1.8703034 ]\n",
            "[-0.15017085 -0.4045037   0.22697361  0.96754044]\n",
            "[ 0.14595392  0.7592153  -0.2401519  -1.5126642 ]\n",
            "[ 0.17335212  0.6298163  -0.22314629 -1.1662922 ]\n",
            "[-0.16473274 -0.79289204  0.21555106  1.2390252 ]\n",
            "[-0.09227195 -0.3796448   0.21730608  0.8565826 ]\n",
            "[ 0.18148239  0.79944396 -0.23500928 -1.4695244 ]\n",
            "[ 0.1337115   0.36392942 -0.23091584 -0.88992727]\n",
            "[-0.15608299 -0.74490124  0.2424943   1.452909  ]\n",
            "[ 0.07923095 -0.33566618 -0.21319821 -0.16094811]\n",
            "[ 0.17831725  0.17775661 -0.22590381 -0.62598777]\n",
            "[-0.07415716 -0.44837967  0.21025528  1.063627  ]\n",
            "[-0.11056305 -0.8260782   0.21917973  1.6300849 ]\n",
            "[-0.16991366 -0.6451651   0.21088591  1.2600635 ]\n",
            "[ 0.2291566  1.3998293 -0.2444505 -2.2445648]\n",
            "[ 0.20263575  0.96771777 -0.22792332 -1.677954  ]\n",
            "[ 0.0638864   0.78317994 -0.22742766 -1.5727938 ]\n",
            "[ 0.11957917  0.6243301  -0.22320075 -1.3793625 ]\n",
            "[ 0.06148887 -0.0308666   0.21326394  1.0783889 ]\n",
            "[-0.03534266 -0.12097143 -0.22388478 -0.84993297]\n",
            "[-0.10749821  1.3665872  -0.24249229 -2.261488  ]\n",
            "[-0.11374884 -0.6123859   0.22810219  1.2344148 ]\n",
            "[-0.07857867 -0.19383056  0.21366346  0.81439173]\n",
            "[-0.1115097  -1.1536205   0.20944989  1.9489375 ]\n",
            "[-0.14606121 -0.9934914   0.21911219  1.7617391 ]\n",
            "[ 0.14382935  0.6383209  -0.22247311 -1.2370076 ]\n",
            "[-0.03633361 -0.5633048   0.22674671  1.3277364 ]\n",
            "[ 0.17260289  1.0223492  -0.21316667 -1.7576095 ]\n",
            "[ 0.15413764  0.63590664 -0.21106601 -1.2435058 ]\n",
            "[-0.716836   -1.4860392   0.21226408  1.5862857 ]\n",
            "[ 0.11021993  0.22983548 -0.21397185 -0.91658294]\n",
            "[ 0.17875738  0.6315192  -0.21663949 -1.2615432 ]\n",
            "[ 0.06017493  1.1435184  -0.22250427 -2.0251637 ]\n",
            "[ 0.03045455  0.00344289 -0.20958294 -0.70602864]\n",
            "[ 0.17921728  0.7731986  -0.23294927 -1.5544225 ]\n",
            "[ 0.16197494  1.4065778  -0.23309506 -2.334546  ]\n",
            "[ 0.08207066 -0.00554039 -0.21625112 -0.66632754]\n",
            "[ 0.17970408  0.2511389  -0.2206041  -0.57349706]\n",
            "[ 0.00986327  0.26436725 -0.21442932 -1.0297436 ]\n",
            "[-0.40968007 -2.2900047   0.23740293  2.673307  ]\n",
            "[-0.09554202 -0.5684384   0.23731953  1.2905179 ]\n",
            "[-0.05550878 -0.41867396  0.22153302  1.1166171 ]\n",
            "[-0.11566211 -0.9835535   0.23177834  1.9545915 ]\n",
            "[ 0.02448057  0.59856254 -0.21757211 -1.5024472 ]\n",
            "[ 0.02737729 -0.7814118   0.22596075  1.627132  ]\n",
            "[-0.3678133  -1.9394965   0.21373713  2.5651894 ]\n",
            "[ 0.07704426  0.19319871 -0.21084586 -0.7898865 ]\n",
            "[-0.12132379 -0.8059839   0.22261684  1.5729953 ]\n",
            "[ 0.19546562  0.04794149 -0.21874018 -0.48498073]\n",
            "[ 0.07139252  1.0029447  -0.24062648 -1.9745077 ]\n",
            "[-0.09766649 -0.5575778   0.22411585  1.1784823 ]\n",
            "[ 0.1343435   0.56021863 -0.21863917 -1.2448678 ]\n",
            "[ 0.12151135  1.1653031  -0.23106113 -2.0081518 ]\n",
            "[ 0.12808461  1.374101   -0.2206944  -2.210649  ]\n",
            "[-0.14900026 -0.1744979   0.21127254  0.6184931 ]\n",
            "[-0.24245204 -0.6459684   0.21742761  1.2082694 ]\n",
            "[ 0.12473924  1.000119   -0.2149205  -1.7626159 ]\n",
            "[ 0.18109213  1.0070431  -0.23702428 -1.8733767 ]\n",
            "[ 0.12676279  1.1986146  -0.23104703 -2.0025299 ]\n",
            "[-0.14298141 -1.5884053   0.25849476  2.5325599 ]\n",
            "[ 0.27211115  0.99467623 -0.21965545 -1.6013657 ]\n",
            "[ 0.12640637  1.1422929  -0.2120848  -2.005098  ]\n",
            "[-0.14344504 -0.76145345  0.21971187  1.4017473 ]\n",
            "[ 0.11748837  0.5897757  -0.23368919 -1.1991724 ]\n",
            "[-0.11745746 -0.77561635  0.22360787  1.4213343 ]\n",
            "[-0.11868949 -0.20096545  0.21455315  0.7408747 ]\n",
            "[ 0.14681749  1.1687303  -0.22651863 -1.7583201 ]\n",
            "[-0.10896856 -0.42197564  0.21618663  0.9354338 ]\n",
            "[-0.14193983 -1.021354    0.24779849  1.805732  ]\n",
            "[ 0.10332023  0.97283614 -0.23557496 -1.8738825 ]\n",
            "[-0.17006136 -0.55924064  0.2301143   1.2139109 ]\n",
            "[-0.00988437  0.23984718 -0.23016633 -1.3905323 ]\n",
            "[-0.12347177  0.12920702  0.21395992  0.2620629 ]\n",
            "[-0.27379587 -1.571538    0.2592881   2.389426  ]\n",
            "[-0.17936319 -0.7490409   0.22475491  1.4832039 ]\n",
            "[ 0.17823935  0.0362236  -0.21375336 -0.38291174]\n",
            "[-0.10724486 -0.8237216   0.22323173  1.5743741 ]\n",
            "[-0.15552092  0.01717295  0.21734548  0.39441264]\n",
            "[-0.12190849 -0.9975335   0.21368572  1.8969076 ]\n",
            "[ 0.12675361  1.0345287  -0.23103243 -1.809515  ]\n",
            "[-0.09843168 -0.12170611 -0.2186586  -1.0056627 ]\n",
            "[-0.20400922 -1.1573508   0.24934663  1.9401832 ]\n",
            "[-0.08659411 -0.95514244  0.21685407  1.8867499 ]\n",
            "[ 0.14110373  1.1943413  -0.21687254 -1.9212818 ]\n",
            "[-0.2219762  -1.0159383   0.24512723  1.6573398 ]\n",
            "[ 0.1482273   1.0241318  -0.21629812 -1.6912068 ]\n",
            "[-0.2036876  -0.9776588   0.21273194  1.6365707 ]\n",
            "[ 0.12326072  0.9383002  -0.21013594 -1.6972249 ]\n",
            "[ 0.12584247  0.01382823 -0.21073534 -0.37636566]\n",
            "[-0.16552508 -0.05850027  0.21884388  0.28015444]\n",
            "[-0.10787572 -0.647912    0.21811302  1.2166324 ]\n",
            "[-0.13548915 -0.06212177  0.21891488  0.2767443 ]\n",
            "[ 0.11487938  1.3620785  -0.24451186 -2.368447  ]\n",
            "[-0.09655755 -0.27151808  0.23206574  0.9259697 ]\n",
            "[ 0.14498836 -0.10749267  0.21585743  1.4491888 ]\n",
            "[-0.07547205 -0.26023713  0.21855801  0.7726953 ]\n",
            "[-0.0219094  -0.23282346  0.2131291   0.969229  ]\n",
            "[ 0.05675883  0.03636358 -0.21285965 -0.66900086]\n",
            "[ 0.10222446  1.3438308  -0.20949693 -2.2644417 ]\n",
            "[ 0.12646176  0.386574   -0.23286347 -1.0565932 ]\n",
            "[-0.07088318 -0.06772731  0.22190408  0.5839157 ]\n",
            "[-0.17048833 -0.7411168   0.2300336   1.2730451 ]\n",
            "[-0.15937716 -0.8127168   0.24029423  1.6485009 ]\n",
            "[-0.25395167 -1.7607585   0.24101688  2.3559332 ]\n",
            "[ 0.23097248  0.39824426 -0.2246148  -0.7363672 ]\n",
            "[-0.15172142 -0.9605956   0.2168977   1.5503818 ]\n",
            "[-1.6359217  -1.0561675  -0.21535493 -1.621749  ]\n",
            "[-0.1626411  -1.2285352   0.23077667  2.0160105 ]\n",
            "[ 0.13566318  1.0302618  -0.23530057 -1.890486  ]\n",
            "[-0.19341552 -0.7423782   0.23094526  1.4664243 ]\n",
            "[-0.04968606 -0.742953    0.21292964  1.4557697 ]\n",
            "[-0.05949714 -0.59655595  0.23107868  1.2965702 ]\n",
            "[ 0.15388925  0.59325564 -0.21694843 -1.0471501 ]\n",
            "[ 0.08152295  0.3675277  -0.2254316  -0.9405439 ]\n",
            "[ 0.23644456  1.2179615  -0.22741947 -1.8936522 ]\n",
            "[ 0.1320245   0.8173504  -0.21208288 -1.4537816 ]\n",
            "[-0.10028234 -0.45240116  0.21183252  0.98589635]\n",
            "[-0.05581596 -0.20129216  0.22094825  0.81220067]\n",
            "[-0.06792097 -1.7995404   0.23511843  2.6779985 ]\n",
            "[-0.14432107 -0.8366007   0.23163508  1.4555595 ]\n",
            "[-0.18436596 -0.7717127   0.24088423  1.4201145 ]\n",
            "[-0.07884268 -0.95698893  0.23633704  1.7544643 ]\n",
            "[ 0.18815958  0.61179274 -0.23358184 -1.2226086 ]\n",
            "[ 0.0553638  -0.35637158 -0.21230012  0.00354172]\n",
            "[ 0.0608057   0.48067707 -0.2335573  -1.5079938 ]\n",
            "[-0.09214524 -0.5718473   0.2107502   1.2858717 ]\n",
            "[ 0.07044781  0.03773694 -0.21014372 -0.68129706]\n",
            "[-0.13973737 -0.7890312   0.21005973  1.3649305 ]\n",
            "[ 0.08414043  0.25258562 -0.2148488  -0.7743002 ]\n",
            "[ 0.06487765  0.60043633 -0.22831483 -1.6413413 ]\n",
            "[-0.02090127 -0.78290105  0.21383984  1.7976245 ]\n",
            "[ 0.09124044  1.5223849  -0.25023896 -2.6669395 ]\n",
            "[ 0.15983284  1.0330937  -0.21009356 -1.6586325 ]\n",
            "[-0.17877682 -1.1759905   0.2377172   1.9533515 ]\n",
            "[-0.1277617  -0.8062208   0.23155203  1.3404714 ]\n",
            "[ 0.14538364  0.7851235  -0.2253945  -1.4495045 ]\n",
            "[-0.07551657 -1.208655    0.24162598  2.242884  ]\n",
            "[ 0.09541377  0.98017895 -0.24569212 -1.7769704 ]\n",
            "[ 0.14748333  0.0447258  -0.21122198 -0.41909817]\n",
            "[ 0.07880491  1.3729775  -0.23598656 -2.2703106 ]\n",
            "[-0.16637929 -0.6376031   0.23174441  1.2679582 ]\n",
            "[-0.12677206 -1.039279    0.22289687  1.8523588 ]\n",
            "[-0.10227178 -0.9334499   0.2226511   1.6268497 ]\n",
            "[-0.14955606 -1.3821315   0.2472155   2.315017  ]\n",
            "[ 0.11545073  0.64065903 -0.23965126 -1.6118364 ]\n",
            "[ 0.09211032 -0.10696754  0.22893931  1.6390778 ]\n",
            "[-0.27942684 -0.1678449   0.21518195  0.24749744]\n",
            "[ 0.16958435  0.21810368 -0.2148409  -0.63782257]\n",
            "[ 0.14673308  0.39648312 -0.22028536 -0.92721254]\n",
            "[-0.19010948 -0.6260821   0.21821672  1.1307727 ]\n",
            "[ 0.3296082  1.3951839 -0.2420402 -1.7745022]\n",
            "[-0.12975727 -1.3903297   0.23219396  2.318542  ]\n",
            "[-0.13288765 -0.44609445  0.21802293  0.95913184]\n",
            "[ 0.25461128  1.1542367  -0.2267762  -1.5938059 ]\n",
            "[ 0.18057933  0.40886366 -0.21882889 -1.0390615 ]\n",
            "[-0.17474817 -0.78891414  0.22499464  1.5541055 ]\n",
            "[-0.12468007 -0.8155719   0.23085253  1.609517  ]\n",
            "[ 0.14712696  0.79081094 -0.21173713 -1.4013925 ]\n",
            "[-0.20237803 -0.89502263 -0.21965675 -0.30710077]\n",
            "[ 0.14999634  1.1940953  -0.22323981 -2.0990944 ]\n",
            "[-0.24439773 -0.43322626  0.22632483  0.8056527 ]\n",
            "[-0.14685579 -0.23071484  0.2098609   0.69306225]\n",
            "[ 0.15910372  1.2284383  -0.24016736 -2.1917636 ]\n",
            "[-0.12493819 -0.21384944  0.21093741  0.63008267]\n",
            "[ 0.17202668  0.75621396 -0.22893995 -1.4424773 ]\n",
            "[ 0.10850374  0.7807312  -0.21277663 -1.3958079 ]\n",
            "[ 0.30277804 -0.82116526  0.21782337  2.2644465 ]\n",
            "[-0.03371128 -0.575626    0.22863808  1.4178818 ]\n",
            "[-0.03565321 -0.03079787  0.2131082   0.5266932 ]\n",
            "[ 0.07445802 -0.14398861 -0.21323125 -0.3021599 ]\n",
            "[ 0.12067796  0.40831915 -0.2178728  -1.0074419 ]\n",
            "[-0.16715069 -1.1841705   0.2245404   1.9462458 ]\n",
            "[ 0.17429584  0.7912117  -0.2168731  -1.5022144 ]\n",
            "[0.01516348 0.00489649 0.2174462  0.9568556 ]\n",
            "[-0.09669898 -0.4122337   0.23000051  1.0001792 ]\n",
            "[-0.168872   -1.3541728   0.24105223  2.2584608 ]\n",
            "[ 0.15454596  0.95248616 -0.21734583 -1.7212553 ]\n",
            "[ 0.18892373  0.94214225 -0.21532145 -1.5426041 ]\n",
            "[-0.05880016 -1.1956534   0.25229642  2.2051098 ]\n",
            "[ 0.29454854  0.83221346 -0.23330112 -1.2392634 ]\n",
            "[ 0.10124941  0.37208018 -0.22861432 -1.0307176 ]\n",
            "[-0.04119973 -0.79439116  0.2184136   1.9104244 ]\n",
            "[ 0.1363226  -0.16732298 -0.21615551 -0.19848458]\n",
            "[ 0.09659342  0.22101282 -0.22683416 -0.79926807]\n",
            "[-0.06499623 -0.39435953  0.21715248  1.0183383 ]\n",
            "[ 0.15283139  0.82232857 -0.21817242 -1.472764  ]\n",
            "[ 0.241287    1.3576062  -0.24196811 -1.9149094 ]\n",
            "[-0.11141729 -0.04177706  0.2232783   0.6406071 ]\n",
            "[ 0.07757321 -0.19135031 -0.21480823 -0.25518033]\n",
            "[-0.08683872 -1.0039893   0.24295926  1.821468  ]\n",
            "[ 0.08757335  0.06029776 -0.22130777 -0.4971096 ]\n",
            "[-0.1586589  -1.3418622   0.22162081  2.3887293 ]\n",
            "[-0.2116067 -1.3397474  0.2247521  2.1988337]\n",
            "[-0.13071917 -1.3761663   0.2143881   2.2331781 ]\n",
            "[-0.1391751 -1.0368418  0.2159072  1.7807161]\n",
            "[ 0.18366131  0.83710283 -0.21038814 -1.3794712 ]\n",
            "22447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJaLKHvpwsUv",
        "outputId": "48867491-6776-40db-975b-37be799fd2d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([-0.00487464, -0.02781332, -0.02078416, -0.00240914], dtype=float32), {})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the neural network for the dynamics model\n",
        "class DynamicsModel(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        super(DynamicsModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim + action_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, state_dim)  # Predict next state\n",
        "        self.reward = nn.Linear(128, 1)       # Predict reward\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        x = torch.cat([state, action], dim=-1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        next_state = self.fc3(x)\n",
        "        reward = self.reward(x)\n",
        "        return next_state, reward\n"
      ],
      "metadata": {
        "id": "3fVjGrdzuJ4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model and optimizer\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "model = DynamicsModel(state_dim, action_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Convert collected data to tensors for training\n",
        "states = torch.tensor([d[0] for d in data], dtype=torch.float32)\n",
        "actions = torch.tensor([d[1] for d in data], dtype=torch.float32).unsqueeze(1)\n",
        "next_states = torch.tensor([d[3] for d in data], dtype=torch.float32)\n",
        "rewards = torch.tensor([d[2] for d in data], dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Train the dynamics model\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    predicted_next_states, predicted_rewards = model(states, actions)\n",
        "    loss = criterion(predicted_next_states, next_states) + criterion(predicted_rewards, rewards)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"Model training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "ja_lVS2RuhL0",
        "outputId": "46c0031a-3db8-4d52-aa50-14a6cafb93fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "expected sequence of length 4 at dim 2 (got 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b6c7bc4865b4>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Convert collected data to tensors for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 4 at dim 2 (got 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[d[0] for d in data]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k33oyoqkw62R",
        "outputId": "755298e2-9775-41ec-83d9-a0d5dbf0925a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([ 0.00603946,  0.03967333,  0.00213784, -0.01986235], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.00683293, -0.15547922,  0.00174059,  0.27349433], dtype=float32),\n",
              " array([ 0.00372334, -0.35062596,  0.00721048,  0.56672573], dtype=float32),\n",
              " array([-0.00328917, -0.5458483 ,  0.018545  ,  0.8616715 ], dtype=float32),\n",
              " array([-0.01420614, -0.35098374,  0.03577843,  0.57487684], dtype=float32),\n",
              " array([-0.02122582, -0.15638115,  0.04727596,  0.29367638], dtype=float32),\n",
              " array([-0.02435344, -0.35214412,  0.05314949,  0.6008867 ], dtype=float32),\n",
              " array([-0.03139632, -0.54796773,  0.06516723,  0.9098259 ], dtype=float32),\n",
              " array([-0.04235568, -0.3537854 ,  0.08336374,  0.6383163 ], dtype=float32),\n",
              " array([-0.04943138, -0.5499647 ,  0.09613007,  0.95604396], dtype=float32),\n",
              " array([-0.06043068, -0.74623895,  0.11525095,  1.2773148 ], dtype=float32),\n",
              " array([-0.07535546, -0.9426261 ,  0.14079724,  1.60375   ], dtype=float32),\n",
              " array([-0.09420798, -1.1391054 ,  0.17287225,  1.9368104 ], dtype=float32),\n",
              " (array([ 0.01093751, -0.04095897, -0.04498712,  0.03105763], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.01011833,  0.15477827, -0.04436597, -0.27547294], dtype=float32),\n",
              " array([ 0.0132139 , -0.03968353, -0.04987543,  0.00289342], dtype=float32),\n",
              " array([ 0.01242023, -0.23405603, -0.04981756,  0.27943233], dtype=float32),\n",
              " array([ 0.00773911, -0.42843324, -0.04422892,  0.55599606], dtype=float32),\n",
              " array([-0.00082956, -0.23271912, -0.03310899,  0.24971296], dtype=float32),\n",
              " array([-0.00548394, -0.03714039, -0.02811473, -0.05322663], dtype=float32),\n",
              " array([-0.00622675, -0.23184817, -0.02917927,  0.23045497], dtype=float32),\n",
              " array([-0.01086371, -0.03632167, -0.02457017, -0.07128742], dtype=float32),\n",
              " array([-0.01159015, -0.23108292, -0.02599591,  0.21354337], dtype=float32),\n",
              " array([-0.0162118 , -0.03559913, -0.02172505, -0.08722517], dtype=float32),\n",
              " array([-0.01692379,  0.15982738, -0.02346955, -0.38668242], dtype=float32),\n",
              " array([-0.01372724,  0.3552745 , -0.0312032 , -0.6866718 ], dtype=float32),\n",
              " array([-0.00662175,  0.16059928, -0.04493663, -0.40397334], dtype=float32),\n",
              " array([-0.00340976,  0.35632876, -0.0530161 , -0.7104781 ], dtype=float32),\n",
              " array([ 0.00371681,  0.16197956, -0.06722566, -0.43494332], dtype=float32),\n",
              " array([ 0.0069564 ,  0.3579856 , -0.07592453, -0.74803776], dtype=float32),\n",
              " array([ 0.01411611,  0.1639886 , -0.09088529, -0.48018095], dtype=float32),\n",
              " array([ 0.01739589, -0.02974074, -0.1004889 , -0.2174698 ], dtype=float32),\n",
              " array([ 0.01680107,  0.16666342, -0.1048383 , -0.5400839 ], dtype=float32),\n",
              " array([ 0.02013434,  0.36309075, -0.11563998, -0.8638731 ], dtype=float32),\n",
              " array([ 0.02739616,  0.16971686, -0.13291743, -0.609672  ], dtype=float32),\n",
              " array([ 0.03079049, -0.02332121, -0.14511088, -0.36163172], dtype=float32),\n",
              " array([ 0.03032407, -0.21611464, -0.15234351, -0.11799405], dtype=float32),\n",
              " array([ 0.02600178, -0.40876284, -0.1547034 ,  0.12301548], dtype=float32),\n",
              " array([ 0.01782652, -0.601369  , -0.1522431 ,  0.36317277], dtype=float32),\n",
              " array([ 0.00579914, -0.40444815, -0.14497963,  0.02662131], dtype=float32),\n",
              " array([-0.00228982, -0.5972256 , -0.14444721,  0.27027893], dtype=float32),\n",
              " array([-0.01423434, -0.40036947, -0.13904163, -0.06425002], dtype=float32),\n",
              " array([-0.02224172, -0.20355622, -0.14032663, -0.39736745], dtype=float32),\n",
              " array([-0.02631285, -0.39643747, -0.14827397, -0.15201028], dtype=float32),\n",
              " array([-0.0342416 , -0.58915955, -0.15131418,  0.0904679 ], dtype=float32),\n",
              " array([-0.04602479, -0.7818253 , -0.14950483,  0.33184755], dtype=float32),\n",
              " array([-0.0616613 , -0.9745381 , -0.14286788,  0.57390136], dtype=float32),\n",
              " array([-0.08115206, -0.7777327 , -0.13138984,  0.23984043], dtype=float32),\n",
              " array([-0.09670671, -0.5810024 , -0.12659304, -0.09122899], dtype=float32),\n",
              " array([-0.10832676, -0.38431472, -0.12841761, -0.4210187 ], dtype=float32),\n",
              " array([-0.11601305, -0.5774056 , -0.13683799, -0.1714184 ], dtype=float32),\n",
              " array([-0.12756117, -0.38061744, -0.14026636, -0.5039463 ], dtype=float32),\n",
              " array([-0.13517351, -0.18382622, -0.15034528, -0.8373372 ], dtype=float32),\n",
              " array([-0.13885003, -0.37661034, -0.16709203, -0.59545827], dtype=float32),\n",
              " array([-0.14638224, -0.1795927 , -0.1790012 , -0.9357656 ], dtype=float32),\n",
              " array([-0.1499741 , -0.371908  , -0.1977165 , -0.70424765], dtype=float32),\n",
              " (array([ 0.01338784, -0.04234957, -0.02825495, -0.02831193], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.01254085, -0.23705517, -0.02882119,  0.25532407], dtype=float32),\n",
              " array([ 0.00779975, -0.04153382, -0.02371471, -0.04630842], dtype=float32),\n",
              " array([ 0.00696907, -0.23630783, -0.02464087,  0.23879898], dtype=float32),\n",
              " array([ 0.00224292, -0.04084269, -0.01986489, -0.06155341], dtype=float32),\n",
              " array([ 0.00142606,  0.15455836, -0.02109596, -0.36043707], dtype=float32),\n",
              " array([ 0.00451723, -0.04025746, -0.0283047 , -0.0744801 ], dtype=float32),\n",
              " array([ 0.00371208,  0.1552586 , -0.02979431, -0.3759572 ], dtype=float32),\n",
              " array([ 0.00681725,  0.35079077, -0.03731345, -0.6778835 ], dtype=float32),\n",
              " array([ 0.01383307,  0.15620655, -0.05087112, -0.39717796], dtype=float32),\n",
              " array([ 0.0169572 ,  0.35201195, -0.05881468, -0.7054557 ], dtype=float32),\n",
              " array([ 0.02399744,  0.5478974 , -0.07292379, -1.0160574 ], dtype=float32),\n",
              " array([ 0.03495538,  0.7439119 , -0.09324494, -1.3307184 ], dtype=float32),\n",
              " array([ 0.04983362,  0.94007814, -0.11985931, -1.6510637 ], dtype=float32),\n",
              " array([ 0.06863519,  1.1363792 , -0.15288058, -1.9785571 ], dtype=float32),\n",
              " array([ 0.09136277,  0.9431621 , -0.19245173, -1.7368838 ], dtype=float32),\n",
              " (array([-0.01596896, -0.01268894,  0.00115657,  0.01733264], dtype=float32),\n",
              "  {}),\n",
              " array([-0.01622274,  0.18241641,  0.00150322, -0.27498516], dtype=float32),\n",
              " array([-0.01257441, -0.01272696, -0.00399648,  0.01817152], dtype=float32),\n",
              " array([-0.01282895,  0.18245207, -0.00363305, -0.27576965], dtype=float32),\n",
              " array([-0.00917991,  0.37762567, -0.00914844, -0.56959623], dtype=float32),\n",
              " array([-0.0016274 ,  0.1826332 , -0.02054037, -0.2798094 ], dtype=float32),\n",
              " array([ 0.00202527, -0.0121898 , -0.02613655,  0.00632503], dtype=float32),\n",
              " array([ 0.00178147, -0.20692736, -0.02601005,  0.29064834], dtype=float32),\n",
              " array([-0.00235708, -0.40166897, -0.02019709,  0.57501584], dtype=float32),\n",
              " array([-0.01039045, -0.596502  , -0.00869677,  0.8612683 ], dtype=float32),\n",
              " array([-0.0223205 , -0.40126273,  0.0085286 ,  0.5658636 ], dtype=float32),\n",
              " array([-0.03034575, -0.20626147,  0.01984587,  0.2758797 ], dtype=float32),\n",
              " array([-0.03447098, -0.40166086,  0.02536346,  0.5747554 ], dtype=float32),\n",
              " array([-0.0425042 , -0.59712905,  0.03685857,  0.8753194 ], dtype=float32),\n",
              " array([-0.05444678, -0.402527  ,  0.05436496,  0.59444857], dtype=float32),\n",
              " array([-0.06249732, -0.598366  ,  0.06625393,  0.9037486 ], dtype=float32),\n",
              " array([-0.07446463, -0.7943198 ,  0.0843289 ,  1.2164987 ], dtype=float32),\n",
              " array([-0.09035103, -0.6003806 ,  0.10865888,  0.951387  ], dtype=float32),\n",
              " array([-0.10235865, -0.79678386,  0.12768662,  1.2761374 ], dtype=float32),\n",
              " array([-0.11829432, -0.6035003 ,  0.15320936,  1.0260102 ], dtype=float32),\n",
              " array([-0.13036433, -0.41071317,  0.17372957,  0.78508437], dtype=float32),\n",
              " array([-0.1385786 , -0.60774213,  0.18943125,  1.1269989 ], dtype=float32),\n",
              " (array([ 0.00349465, -0.03505467, -0.03337127, -0.01061309], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.00279356, -0.22968253, -0.03358354,  0.27135682], dtype=float32),\n",
              " array([-0.00180009, -0.03409786, -0.0281564 , -0.03172647], dtype=float32),\n",
              " array([-0.00248205,  0.16141632, -0.02879093, -0.33315837], dtype=float32),\n",
              " array([ 0.00074628,  0.35693598, -0.0354541 , -0.6347797 ], dtype=float32),\n",
              " array([ 0.007885  ,  0.16232602, -0.04814969, -0.35346952], dtype=float32),\n",
              " array([ 0.01113152,  0.3580984 , -0.05521908, -0.66093826], dtype=float32),\n",
              " array([ 0.01829349,  0.55394346, -0.06843784, -0.9704843 ], dtype=float32),\n",
              " array([ 0.02937235,  0.749914  , -0.08784753, -1.283857  ], dtype=float32),\n",
              " array([ 0.04437063,  0.5560135 , -0.11352468, -1.0199218 ], dtype=float32),\n",
              " array([ 0.0554909 ,  0.3625724 , -0.13392311, -0.7649325 ], dtype=float32),\n",
              " array([ 0.06274235,  0.55925936, -0.14922176, -1.0965769 ], dtype=float32),\n",
              " array([ 0.07392754,  0.7559971 , -0.17115329, -1.4321127 ], dtype=float32),\n",
              " array([ 0.08904748,  0.5633502 , -0.19979554, -1.1974382 ], dtype=float32),\n",
              " (array([-0.03378486, -0.00821117, -0.00159062,  0.04565681], dtype=float32),\n",
              "  {}),\n",
              " array([-0.03394909,  0.18693355, -0.00067748, -0.24752755], dtype=float32),\n",
              " array([-0.03021042, -0.00817872, -0.00562803,  0.04494161], dtype=float32),\n",
              " array([-0.03037399,  0.18702349, -0.0047292 , -0.24951169], dtype=float32),\n",
              " array([-0.02663352, -0.00803061, -0.00971944,  0.04167581], dtype=float32),\n",
              " array([-0.02679413,  0.18722935, -0.00888592, -0.2540578 ], dtype=float32),\n",
              " array([-0.02304955, -0.0077646 , -0.01396708,  0.03580918], dtype=float32),\n",
              " array([-0.02320484,  0.18755482, -0.01325089, -0.26124758], dtype=float32),\n",
              " array([-0.01945374, -0.00737549, -0.01847584,  0.02722658], dtype=float32),\n",
              " array([-0.01960125,  0.18800649, -0.01793131, -0.27122796], dtype=float32),\n",
              " array([-0.01584112,  0.38337967, -0.02335587, -0.5695121 ], dtype=float32),\n",
              " array([-0.00817353,  0.57882124, -0.03474611, -0.8694606 ], dtype=float32),\n",
              " array([ 0.0034029 ,  0.7743982 , -0.05213532, -1.1728623 ], dtype=float32),\n",
              " array([ 0.01889086,  0.9701577 , -0.07559257, -1.4814233 ], dtype=float32),\n",
              " array([ 0.03829401,  0.776035  , -0.10522103, -1.2132739 ], dtype=float32),\n",
              " array([ 0.05381472,  0.5824164 , -0.12948652, -0.9553302 ], dtype=float32),\n",
              " array([ 0.06546304,  0.7790199 , -0.14859311, -1.2857293 ], dtype=float32),\n",
              " array([ 0.08104344,  0.9756875 , -0.1743077 , -1.6210057 ], dtype=float32),\n",
              " array([ 0.10055719,  0.7829945 , -0.20672782, -1.3873334 ], dtype=float32),\n",
              " (array([ 0.01592897,  0.02479029,  0.02951646, -0.01722212], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.01642478,  0.21947677,  0.02917201, -0.3004481 ], dtype=float32),\n",
              " array([0.02081431, 0.02395144, 0.02316305, 0.00129051], dtype=float32),\n",
              " array([ 0.02129334,  0.21873367,  0.02318886, -0.28399515], dtype=float32),\n",
              " array([0.02566802, 0.02328879, 0.01750896, 0.01591028], dtype=float32),\n",
              " array([ 0.02613379, -0.17207983,  0.01782716,  0.31406567], dtype=float32),\n",
              " array([0.02269219, 0.02278369, 0.02410848, 0.02705773], dtype=float32),\n",
              " array([ 0.02314787, -0.17267555,  0.02464963,  0.3272486 ], dtype=float32),\n",
              " array([0.01969436, 0.02208695, 0.0311946 , 0.04243986], dtype=float32),\n",
              " array([ 0.0201361 , -0.17346811,  0.0320434 ,  0.34479946], dtype=float32),\n",
              " array([ 0.01666673, -0.3690309 ,  0.03893939,  0.6474122 ], dtype=float32),\n",
              " array([ 0.00928612, -0.17447248,  0.05188764,  0.36724108], dtype=float32),\n",
              " array([0.00579667, 0.01987523, 0.05923246, 0.09136   ], dtype=float32),\n",
              " array([ 0.00619417,  0.21410036,  0.06105966, -0.18206263], dtype=float32),\n",
              " array([ 0.01047618,  0.40829787,  0.05741841, -0.45487565], dtype=float32),\n",
              " array([ 0.01864214,  0.60256296,  0.04832089, -0.7289213 ], dtype=float32),\n",
              " array([ 0.0306934 ,  0.79698485,  0.03374247, -1.0060129 ], dtype=float32),\n",
              " array([ 0.04663309,  0.9916403 ,  0.01362221, -1.2879115 ], dtype=float32),\n",
              " array([ 0.0664659 ,  0.79634774, -0.01213602, -0.99099505], dtype=float32),\n",
              " array([ 0.08239286,  0.6013903 , -0.03195592, -0.7021483 ], dtype=float32),\n",
              " array([ 0.09442066,  0.4067255 , -0.04599889, -0.41969362], dtype=float32),\n",
              " array([ 0.10255517,  0.21228448, -0.05439276, -0.14185952], dtype=float32),\n",
              " array([ 0.10680086,  0.01798202, -0.05722995,  0.13317955], dtype=float32),\n",
              " array([ 0.1071605 ,  0.21387506, -0.05456636, -0.17699535], dtype=float32),\n",
              " array([ 0.111438  ,  0.01957473, -0.05810627,  0.09798679], dtype=float32),\n",
              " array([ 0.1118295 ,  0.21547925, -0.05614653, -0.21244769], dtype=float32),\n",
              " array([ 0.11613908,  0.02120313, -0.06039549,  0.06200888], dtype=float32),\n",
              " array([ 0.11656314, -0.17300323, -0.05915531,  0.3350418 ], dtype=float32),\n",
              " array([ 0.11310308, -0.36723557, -0.05245447,  0.60849917], dtype=float32),\n",
              " array([ 0.10575837, -0.5615865 , -0.04028449,  0.88421005], dtype=float32),\n",
              " array([ 0.09452663, -0.756139  , -0.02260029,  1.1639615 ], dtype=float32),\n",
              " array([ 7.9403855e-02, -5.6073016e-01,  6.7894347e-04,  8.6427927e-01],\n",
              "       dtype=float32),\n",
              " array([ 0.06818926, -0.75586134,  0.01796453,  1.1571757 ], dtype=float32),\n",
              " array([ 0.05307203, -0.5609781 ,  0.04110804,  0.87017924], dtype=float32),\n",
              " array([ 0.04185246, -0.36643872,  0.05851163,  0.590699  ], dtype=float32),\n",
              " array([ 0.03452369, -0.562329  ,  0.07032561,  0.9012242 ], dtype=float32),\n",
              " array([ 0.02327711, -0.36822674,  0.08835009,  0.63144916], dtype=float32),\n",
              " array([ 0.01591258, -0.5644631 ,  0.10097907,  0.9505967 ], dtype=float32),\n",
              " array([ 0.00462331, -0.37083456,  0.119991  ,  0.69127095], dtype=float32),\n",
              " array([-0.00279338, -0.567399  ,  0.13381642,  1.0191903 ], dtype=float32),\n",
              " array([-0.01414136, -0.7640259 ,  0.15420023,  1.3507186 ], dtype=float32),\n",
              " array([-0.02942188, -0.9607116 ,  0.1812146 ,  1.6874019 ], dtype=float32),\n",
              " (array([-0.01601098, -0.02475636, -0.00347149, -0.0071812 ], dtype=float32),\n",
              "  {}),\n",
              " array([-0.01650611,  0.17041521, -0.00361511, -0.3009574 ], dtype=float32),\n",
              " array([-0.01309781,  0.3655885 , -0.00963426, -0.59477824], dtype=float32),\n",
              " array([-0.00578604,  0.17060271, -0.02152983, -0.3051456 ], dtype=float32),\n",
              " array([-0.00237398,  0.36602476, -0.02763274, -0.60454   ], dtype=float32),\n",
              " array([ 0.00494651,  0.561522  , -0.03972354, -0.90579695], dtype=float32),\n",
              " array([ 0.01617695,  0.7571587 , -0.05783948, -1.2106961 ], dtype=float32),\n",
              " array([ 0.03132012,  0.56282926, -0.0820534 , -0.9366847 ], dtype=float32),\n",
              " array([ 0.04257671,  0.75895613, -0.1007871 , -1.2539818 ], dtype=float32),\n",
              " array([ 0.05775584,  0.565259  , -0.12586673, -0.9944918 ], dtype=float32),\n",
              " array([ 0.06906101,  0.37202483, -0.14575657, -0.74384075], dtype=float32),\n",
              " array([ 0.07650151,  0.179183  , -0.16063339, -0.5003461 ], dtype=float32),\n",
              " array([ 0.08008517, -0.01335331, -0.1706403 , -0.26228303], dtype=float32),\n",
              " array([ 0.07981811,  0.18374138, -0.17588596, -0.6035564 ], dtype=float32),\n",
              " array([ 0.08349293,  0.38083035, -0.1879571 , -0.94607306], dtype=float32),\n",
              " array([ 0.09110954,  0.18866868, -0.20687856, -0.7178416 ], dtype=float32),\n",
              " (array([-0.02041473,  0.04989837, -0.04869616,  0.0479341 ], dtype=float32),\n",
              "  {}),\n",
              " array([-0.01941676, -0.14449272, -0.04773748,  0.32486406], dtype=float32),\n",
              " array([-0.02230662, -0.3389036 , -0.0412402 ,  0.6021187 ], dtype=float32),\n",
              " array([-0.02908469, -0.53342515, -0.02919783,  0.8815318 ], dtype=float32),\n",
              " array([-0.03975319, -0.33791903, -0.01156719,  0.5798146 ], dtype=float32),\n",
              " array([-4.6511576e-02, -5.3287703e-01,  2.9103516e-05,  8.6883134e-01],\n",
              "       dtype=float32),\n",
              " array([-0.05716912, -0.33775544,  0.01740573,  0.57615757], dtype=float32),\n",
              " array([-0.06392422, -0.14288175,  0.02892888,  0.28900832], dtype=float32),\n",
              " array([-0.06678186,  0.05181599,  0.03470905,  0.0055878 ], dtype=float32),\n",
              " array([-0.06574554,  0.24642341,  0.0348208 , -0.2759451 ], dtype=float32),\n",
              " array([-0.06081707,  0.05082241,  0.0293019 ,  0.02751378], dtype=float32),\n",
              " array([-0.05980062,  0.24551217,  0.02985218, -0.25578195], dtype=float32),\n",
              " array([-0.05489038,  0.44019547,  0.02473654, -0.53890157], dtype=float32),\n",
              " array([-0.04608647,  0.24473466,  0.01395851, -0.23852825], dtype=float32),\n",
              " array([-0.04119178,  0.04941611,  0.00918794,  0.05852471], dtype=float32),\n",
              " array([-0.04020346,  0.24440512,  0.01035844, -0.23124525], dtype=float32),\n",
              " array([-0.03531535,  0.0491367 ,  0.00573353,  0.06468699], dtype=float32),\n",
              " array([-0.03433262, -0.14606698,  0.00702727,  0.35917336], dtype=float32),\n",
              " array([-0.03725396,  0.04895437,  0.01421074,  0.06871454], dtype=float32),\n",
              " array([-0.03627487, -0.1463684 ,  0.01558503,  0.36584693], dtype=float32),\n",
              " array([-0.03920224,  0.04852864,  0.02290197,  0.07811869], dtype=float32),\n",
              " array([-0.03823167, -0.146914  ,  0.02446434,  0.37793836], dtype=float32),\n",
              " array([-0.04116995, -0.3423747 ,  0.03202311,  0.6782335 ], dtype=float32),\n",
              " array([-0.04801744, -0.14771193,  0.04558778,  0.3958022 ], dtype=float32),\n",
              " array([-0.05097168,  0.04673455,  0.05350382,  0.11783369], dtype=float32),\n",
              " array([-0.05003699,  0.2410507 ,  0.0558605 , -0.15750082], dtype=float32),\n",
              " array([-0.04521598,  0.04517532,  0.05271048,  0.15226841], dtype=float32),\n",
              " array([-0.04431247,  0.23950444,  0.05575585, -0.12333073], dtype=float32),\n",
              " array([-0.03952238,  0.4337851 ,  0.05328923, -0.39791515], dtype=float32),\n",
              " array([-0.03084668,  0.23794925,  0.04533093, -0.08891872], dtype=float32),\n",
              " array([-0.02608769,  0.4323931 ,  0.04355256, -0.36696216], dtype=float32),\n",
              " array([-0.01743983,  0.23668021,  0.03621331, -0.06087079], dtype=float32),\n",
              " array([-0.01270623,  0.43126473,  0.03499589, -0.34191182], dtype=float32),\n",
              " array([-0.00408093,  0.2356628 ,  0.02815766, -0.03840189], dtype=float32),\n",
              " array([0.00063233, 0.04014862, 0.02738962, 0.26303038], dtype=float32),\n",
              " array([ 0.0014353 , -0.15535337,  0.03265023,  0.5642249 ], dtype=float32),\n",
              " array([-0.00167177,  0.03929563,  0.04393473,  0.2820045 ], dtype=float32),\n",
              " array([-0.00088586, -0.15642457,  0.04957482,  0.58821416], dtype=float32),\n",
              " array([-0.00401435,  0.03796937,  0.0613391 ,  0.3115505 ], dtype=float32),\n",
              " array([-0.00325496, -0.15797038,  0.06757011,  0.6229298 ], dtype=float32),\n",
              " array([-0.00641437,  0.03614627,  0.08002871,  0.35226977], dtype=float32),\n",
              " array([-0.00569144,  0.2300444 ,  0.0870741 ,  0.0858568 ], dtype=float32),\n",
              " array([-0.00109056,  0.0337892 ,  0.08879124,  0.40469176], dtype=float32),\n",
              " array([-0.00041477,  0.22754712,  0.09688507,  0.14127013], dtype=float32),\n",
              " array([0.00413617, 0.03118072, 0.09971048, 0.46287808], dtype=float32),\n",
              " array([0.00475979, 0.22476257, 0.10896803, 0.20321387], dtype=float32),\n",
              " array([0.00925504, 0.02826464, 0.11303232, 0.52818584], dtype=float32),\n",
              " array([ 0.00982033, -0.16825096,  0.12359603,  0.854239  ], dtype=float32),\n",
              " array([ 0.00645531, -0.3648211 ,  0.1406808 ,  1.1830897 ], dtype=float32),\n",
              " array([-8.4111094e-04, -1.7177643e-01,  1.6434261e-01,  9.3760729e-01],\n",
              "       dtype=float32),\n",
              " array([-0.00427664, -0.36868712,  0.18309475,  1.2770932 ], dtype=float32),\n",
              " array([-0.01165038, -0.17630966,  0.20863661,  1.0468799 ], dtype=float32),\n",
              " (array([ 0.04462428, -0.01533295,  0.01856678, -0.0098398 ], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.04431763, -0.21071619,  0.01836999,  0.28864285], dtype=float32),\n",
              " array([ 0.0401033 , -0.4060952 ,  0.02414284,  0.5870624 ], dtype=float32),\n",
              " array([ 0.0319814 , -0.6015468 ,  0.03588409,  0.88725173], dtype=float32),\n",
              " array([ 0.01995046, -0.40692982,  0.05362913,  0.6060618 ], dtype=float32),\n",
              " array([ 0.01181186, -0.21259718,  0.06575036,  0.33074132], dtype=float32),\n",
              " array([ 0.00755992, -0.40859044,  0.07236519,  0.64341265], dtype=float32),\n",
              " array([-6.1188766e-04, -6.0464239e-01,  8.5233442e-02,  9.5797777e-01],\n",
              "       dtype=float32),\n",
              " array([-0.01270474, -0.4107635 ,  0.104393  ,  0.69324344], dtype=float32),\n",
              " array([-0.02092001, -0.21723276,  0.11825787,  0.4351635 ], dtype=float32),\n",
              " array([-0.02526466, -0.02396608,  0.12696114,  0.18197507], dtype=float32),\n",
              " array([-0.02574398, -0.2206545 ,  0.13060063,  0.5118594 ], dtype=float32),\n",
              " array([-0.03015707, -0.41735086,  0.14083782,  0.84267884], dtype=float32),\n",
              " array([-0.03850409, -0.22440307,  0.1576914 ,  0.5973924 ], dtype=float32),\n",
              " array([-0.04299215, -0.42133918,  0.16963924,  0.9353007 ], dtype=float32),\n",
              " array([-0.05141893, -0.22886105,  0.18834527,  0.70036286], dtype=float32),\n",
              " array([-0.05599616, -0.42602536,  0.20235252,  1.0459259 ], dtype=float32),\n",
              " (array([-0.01949738,  0.03023877,  0.0278571 ,  0.01118268], dtype=float32),\n",
              "  {}),\n",
              " array([-0.01889261, -0.16527139,  0.02808075,  0.31252307], dtype=float32),\n",
              " array([-0.02219803,  0.0294395 ,  0.03433121,  0.02882652], dtype=float32),\n",
              " array([-0.02160924, -0.16615753,  0.03490774,  0.3321406 ], dtype=float32),\n",
              " array([-0.0249324 ,  0.02845061,  0.04155056,  0.050667  ], dtype=float32),\n",
              " array([-0.02436338,  0.2229529 ,  0.0425639 , -0.22862227], dtype=float32),\n",
              " array([-0.01990432,  0.02724935,  0.03799145,  0.07717718], dtype=float32),\n",
              " array([-0.01935934, -0.16839606,  0.03953499,  0.38160032], dtype=float32),\n",
              " array([-0.02272726,  0.02614287,  0.047167  ,  0.10164022], dtype=float32),\n",
              " array([-0.0222044 ,  0.22055824,  0.0491998 , -0.17579654], dtype=float32),\n",
              " array([-0.01779324,  0.4149428 ,  0.04568388, -0.45256168], dtype=float32),\n",
              " array([-0.00949438,  0.60938996,  0.03663264, -0.73050165], dtype=float32),\n",
              " array([ 0.00269342,  0.41378137,  0.02202261, -0.42651808], dtype=float32),\n",
              " array([ 0.01096905,  0.6085846 ,  0.01349225, -0.71217793], dtype=float32),\n",
              " array([ 2.3140738e-02,  8.0351716e-01, -7.5131160e-04, -1.0005835e+00],\n",
              "       dtype=float32),\n",
              " array([ 0.03921108,  0.60840523, -0.02076298, -0.7081366 ], dtype=float32),\n",
              " array([ 0.05137919,  0.41357696, -0.03492571, -0.4220611 ], dtype=float32),\n",
              " array([ 0.05965072,  0.60917586, -0.04336694, -0.7255466 ], dtype=float32),\n",
              " array([ 0.07183424,  0.41467956, -0.05787787, -0.44682235], dtype=float32),\n",
              " array([ 0.08012784,  0.2204221 , -0.06681432, -0.17293066], dtype=float32),\n",
              " array([ 0.08453628,  0.41643354, -0.07027293, -0.48592058], dtype=float32),\n",
              " array([ 0.09286495,  0.61247313, -0.07999134, -0.7998974 ], dtype=float32),\n",
              " array([ 0.10511441,  0.80859584, -0.09598929, -1.1166332 ], dtype=float32),\n",
              " array([ 0.12128633,  0.6148557 , -0.11832196, -0.85553837], dtype=float32),\n",
              " array([ 0.13358344,  0.8113741 , -0.13543272, -1.1829604 ], dtype=float32),\n",
              " array([ 0.14981093,  1.0079682 , -0.15909193, -1.5148468 ], dtype=float32),\n",
              " array([ 0.16997029,  1.2046176 , -0.18938887, -1.8526719 ], dtype=float32),\n",
              " (array([-0.02934377,  0.03919176,  0.04466549, -0.00191145], dtype=float32),\n",
              "  {}),\n",
              " array([-0.02855994, -0.15654136,  0.04462726,  0.3045227 ], dtype=float32),\n",
              " array([-0.03169077,  0.03791714,  0.05071771,  0.02624142], dtype=float32),\n",
              " array([-0.03093242,  0.23227645,  0.05124254, -0.25001806], dtype=float32),\n",
              " array([-0.02628689,  0.03646161,  0.04624218,  0.05837738], dtype=float32),\n",
              " array([-0.02555766, -0.15929182,  0.04740972,  0.365284  ], dtype=float32),\n",
              " array([-0.0287435 ,  0.03512545,  0.05471541,  0.08791902], dtype=float32),\n",
              " array([-0.02804099,  0.22942215,  0.05647378, -0.1870116 ], dtype=float32),\n",
              " array([-0.02345254,  0.0335396 ,  0.05273355,  0.12293829], dtype=float32),\n",
              " array([-0.02278175, -0.16229664,  0.05519232,  0.4317808 ], dtype=float32),\n",
              " array([-0.02602769, -0.3581549 ,  0.06382793,  0.7413391 ], dtype=float32),\n",
              " array([-0.03319078, -0.5540972 ,  0.07865471,  1.0534067 ], dtype=float32),\n",
              " array([-0.04427272, -0.3601012 ,  0.09972285,  0.7864131 ], dtype=float32),\n",
              " array([-0.05147475, -0.55644137,  0.11545111,  1.1087301 ], dtype=float32),\n",
              " array([-0.06260358, -0.36301017,  0.13762571,  0.8543821 ], dtype=float32),\n",
              " array([-0.06986378, -0.55971247,  0.15471336,  1.18698   ], dtype=float32),\n",
              " array([-0.08105803, -0.36689728,  0.17845295,  0.9465163 ], dtype=float32),\n",
              " array([-0.08839598, -0.17456888,  0.19738328,  0.71479225], dtype=float32),\n",
              " (array([-0.04987548,  0.01927129,  0.01728549,  0.03811076], dtype=float32),\n",
              "  {}),\n",
              " array([-0.04949006, -0.17609422,  0.01804771,  0.33619693], dtype=float32),\n",
              " array([-0.05301194, -0.3714683 ,  0.02477165,  0.63451606], dtype=float32),\n",
              " array([-0.06044131, -0.17670047,  0.03746197,  0.34973606], dtype=float32),\n",
              " array([-0.06397532,  0.01786922,  0.04445669,  0.06909754], dtype=float32),\n",
              " array([-0.06361793,  0.21232654,  0.04583864, -0.20923428], dtype=float32),\n",
              " array([-0.0593714 ,  0.4067641 ,  0.04165396, -0.48711243], dtype=float32),\n",
              " array([-0.05123612,  0.21107993,  0.03191171, -0.18159805], dtype=float32),\n",
              " array([-0.04701452,  0.40573105,  0.02827975, -0.46404564], dtype=float32),\n",
              " array([-0.0388999 ,  0.21022113,  0.01899883, -0.16258487], dtype=float32),\n",
              " array([-0.03469548,  0.405066  ,  0.01574714, -0.44921413], dtype=float32),\n",
              " array([-0.02659416,  0.59996176,  0.00676285, -0.736892  ], dtype=float32),\n",
              " array([-0.01459492,  0.40474704, -0.00797499, -0.44208837], dtype=float32),\n",
              " array([-0.00649998,  0.59998095, -0.01681675, -0.7372745 ], dtype=float32),\n",
              " array([ 0.00549964,  0.40509522, -0.03156225, -0.4499312 ], dtype=float32),\n",
              " array([ 0.01360154,  0.60064906, -0.04056087, -0.7523936 ], dtype=float32),\n",
              " array([ 0.02561452,  0.40610915, -0.05560874, -0.4727454 ], dtype=float32),\n",
              " array([ 0.0337367 ,  0.6019706 , -0.06506365, -0.782424  ], dtype=float32),\n",
              " array([ 0.04577611,  0.79792356, -0.08071212, -1.0948467 ], dtype=float32),\n",
              " array([ 0.06173459,  0.6039521 , -0.10260906, -0.8285403 ], dtype=float32),\n",
              " array([ 0.07381363,  0.800316  , -0.11917987, -1.151651  ], dtype=float32),\n",
              " array([ 0.08981995,  0.9967739 , -0.14221288, -1.4792036 ], dtype=float32),\n",
              " array([ 0.10975543,  1.1933166 , -0.17179696, -1.8127112 ], dtype=float32),\n",
              " array([ 0.13362175,  1.0004746 , -0.20805119, -1.5779666 ], dtype=float32),\n",
              " (array([ 0.03794099,  0.02218536, -0.04878299,  0.01811487], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.0383847 ,  0.21797174, -0.04842069, -0.28955185], dtype=float32),\n",
              " array([ 0.04274413,  0.0235725 , -0.05421173, -0.01252486], dtype=float32),\n",
              " array([ 0.04321558,  0.21942832, -0.05446223, -0.32180744], dtype=float32),\n",
              " array([ 0.04760415,  0.41528183, -0.06089838, -0.6311561 ], dtype=float32),\n",
              " array([ 0.05590979,  0.22106008, -0.0735215 , -0.35825658], dtype=float32),\n",
              " array([ 0.06033099,  0.02705613, -0.08068663, -0.08963267], dtype=float32),\n",
              " array([ 0.06087211, -0.16682215, -0.08247928,  0.17654246], dtype=float32),\n",
              " array([ 0.05753567, -0.3606728 , -0.07894844,  0.44210854], dtype=float32),\n",
              " array([ 0.05032221, -0.554594  , -0.07010627,  0.7088976 ], dtype=float32),\n",
              " array([ 0.03923033, -0.7486785 , -0.05592831,  0.97871476], dtype=float32),\n",
              " array([ 0.02425676, -0.9430078 , -0.03635402,  1.2533187 ], dtype=float32),\n",
              " array([ 0.00539661, -0.74743956, -0.01128764,  0.9494744 ], dtype=float32),\n",
              " array([-0.00955218, -0.9424077 ,  0.00770184,  1.2385895 ], dtype=float32),\n",
              " array([-0.02840034, -0.74738556,  0.03247363,  0.94832927], dtype=float32),\n",
              " array([-0.04334805, -0.9429293 ,  0.05144022,  1.2510358 ], dtype=float32),\n",
              " array([-0.06220664, -0.7485029 ,  0.07646094,  0.97489876], dtype=float32),\n",
              " array([-0.0771767 , -0.9445626 ,  0.09595891,  1.2905867 ], dtype=float32),\n",
              " array([-0.09606795, -0.7507829 ,  0.12177064,  1.029423  ], dtype=float32),\n",
              " array([-0.1110836 , -0.94729626,  0.14235911,  1.3577224 ], dtype=float32),\n",
              " array([-0.13002953, -0.7542177 ,  0.16951355,  1.1127467 ], dtype=float32),\n",
              " array([-0.14511389, -0.9511106 ,  0.19176848,  1.4534516 ], dtype=float32),\n",
              " (array([-0.02620979,  0.00301837, -0.00418579, -0.0053456 ], dtype=float32),\n",
              "  {}),\n",
              " array([-0.02614942,  0.1982001 , -0.0042927 , -0.29934624], dtype=float32),\n",
              " array([-0.02218542,  0.39338297, -0.01027963, -0.5933799 ], dtype=float32),\n",
              " array([-0.01431776,  0.5886473 , -0.02214723, -0.88928306], dtype=float32),\n",
              " array([-0.00254481,  0.39383277, -0.03993289, -0.6036437 ], dtype=float32),\n",
              " array([ 0.00533184,  0.5894898 , -0.05200576, -0.90863246], dtype=float32),\n",
              " array([ 0.01712164,  0.3951089 , -0.07017841, -0.6327381 ], dtype=float32),\n",
              " array([ 0.02502382,  0.5911361 , -0.08283317, -0.94667065], dtype=float32),\n",
              " array([ 0.03684654,  0.39722148, -0.10176659, -0.6811211 ], dtype=float32),\n",
              " array([ 0.04479097,  0.59359854, -0.115389  , -1.0040305 ], dtype=float32),\n",
              " array([ 0.05666294,  0.79005694, -0.13546962, -1.3306075 ], dtype=float32),\n",
              " array([ 0.07246408,  0.9866024 , -0.16208176, -1.662431  ], dtype=float32),\n",
              " array([ 0.09219613,  0.79369694, -0.1953304 , -1.4243089 ], dtype=float32),\n",
              " (array([ 0.01973823, -0.04255613,  0.02963009,  0.0462463 ], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.01888711, -0.23809016,  0.03055502,  0.34812856], dtype=float32),\n",
              " array([ 0.0141253 , -0.43363306,  0.03751758,  0.6502878 ], dtype=float32),\n",
              " array([ 0.00545264, -0.62925696,  0.05052334,  0.9545447 ], dtype=float32),\n",
              " array([-0.0071325 , -0.43484974,  0.06961424,  0.6781536 ], dtype=float32),\n",
              " array([-0.01582949, -0.6308662 ,  0.08317731,  0.9919162 ], dtype=float32),\n",
              " array([-0.02844682, -0.43694988,  0.10301563,  0.7264732 ], dtype=float32),\n",
              " array([-0.03718581, -0.63333386,  0.1175451 ,  1.0497206 ], dtype=float32),\n",
              " array([-0.04985249, -0.43995073,  0.13853951,  0.7961263 ], dtype=float32),\n",
              " array([-0.05865151, -0.24697421,  0.15446204,  0.5500354 ], dtype=float32),\n",
              " array([-0.06359099, -0.05432066,  0.16546275,  0.309727  ], dtype=float32),\n",
              " array([-0.0646774 , -0.25136596,  0.17165728,  0.6496825 ], dtype=float32),\n",
              " array([-0.06970472, -0.44841063,  0.18465093,  0.99112535], dtype=float32),\n",
              " array([-0.07867294, -0.64545894,  0.20447344,  1.3356526 ], dtype=float32),\n",
              " (array([ 0.00217706,  0.03551329,  0.03433509, -0.00231056], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.00288733, -0.16008382,  0.03428888,  0.3010047 ], dtype=float32),\n",
              " array([-0.00031435,  0.03453306,  0.04030897,  0.01932995], dtype=float32),\n",
              " array([ 0.00037631,  0.22905445,  0.04069557, -0.26036748], dtype=float32),\n",
              " array([0.0049574 , 0.03337589, 0.03548823, 0.04486852], dtype=float32),\n",
              " array([ 0.00562492, -0.1622365 ,  0.0363856 ,  0.3485337 ], dtype=float32),\n",
              " array([0.00238019, 0.03234956, 0.04335627, 0.06754281], dtype=float32),\n",
              " array([ 0.00302718,  0.22682396,  0.04470713, -0.21115191], dtype=float32),\n",
              " array([0.00756366, 0.03109225, 0.04048409, 0.09529182], dtype=float32),\n",
              " array([ 0.0081855 , -0.16458586,  0.04238992,  0.40046754], dtype=float32),\n",
              " array([0.00489379, 0.02990996, 0.05039927, 0.12144481], dtype=float32),\n",
              " array([ 0.00549199,  0.22427496,  0.05282817, -0.1549214 ], dtype=float32),\n",
              " array([0.00997749, 0.02843798, 0.04972974, 0.15394853], dtype=float32),\n",
              " array([ 0.01054625, -0.16735944,  0.05280871,  0.4618961 ], dtype=float32),\n",
              " array([0.00719906, 0.02697793, 0.06204664, 0.18631496], dtype=float32),\n",
              " array([ 0.00773862,  0.2211598 ,  0.06577294, -0.08616734], dtype=float32),\n",
              " array([ 0.01216181,  0.4152803 ,  0.06404959, -0.35739517], dtype=float32),\n",
              " array([ 0.02046742,  0.609436  ,  0.05690168, -0.6292138 ], dtype=float32),\n",
              " array([ 0.03265614,  0.41356805,  0.04431741, -0.31916738], dtype=float32),\n",
              " array([ 0.0409275 ,  0.21784388,  0.03793406, -0.0128443 ], dtype=float32),\n",
              " array([0.04528438, 0.022199  , 0.03767717, 0.2915618 ], dtype=float32),\n",
              " array([ 0.04572836, -0.17343934,  0.04350841,  0.5958855 ], dtype=float32),\n",
              " array([ 0.04225957, -0.36914232,  0.05542612,  0.90194964], dtype=float32),\n",
              " array([ 0.03487672, -0.5649696 ,  0.07346512,  1.2115264 ], dtype=float32),\n",
              " array([ 0.02357733, -0.76095897,  0.09769564,  1.5262969 ], dtype=float32),\n",
              " array([ 0.00835815, -0.5671425 ,  0.12822157,  1.2656353 ], dtype=float32),\n",
              " array([-0.0029847 , -0.37387073,  0.15353428,  1.0157014 ], dtype=float32),\n",
              " array([-0.01046211, -0.5706694 ,  0.17384832,  1.352389  ], dtype=float32),\n",
              " array([-0.0218755 , -0.76749516,  0.20089608,  1.6940315 ], dtype=float32),\n",
              " (array([ 0.02641726,  0.0441802 , -0.02841583,  0.00552868], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.02730086,  0.2396979 , -0.02830525, -0.29598263], dtype=float32),\n",
              " array([ 0.03209482,  0.04499067, -0.03422491, -0.01235939], dtype=float32),\n",
              " array([ 0.03299463,  0.24058631, -0.03447209, -0.3156412 ], dtype=float32),\n",
              " array([ 0.03780636,  0.4361819 , -0.04078492, -0.61899304], dtype=float32),\n",
              " array([ 0.04652999,  0.24165264, -0.05316478, -0.33942926], dtype=float32),\n",
              " array([ 0.05136305,  0.43748918, -0.05995336, -0.6483921 ], dtype=float32),\n",
              " array([ 0.06011283,  0.6333929 , -0.0729212 , -0.9593354 ], dtype=float32),\n",
              " array([ 0.07278069,  0.8294153 , -0.09210791, -1.2740076 ], dtype=float32),\n",
              " array([ 0.08936899,  1.0255837 , -0.11758807, -1.5940542 ], dtype=float32),\n",
              " array([ 0.10988067,  1.2218881 , -0.14946915, -1.9209687 ], dtype=float32),\n",
              " array([ 0.13431843,  1.0286553 , -0.18788852, -1.6781318 ], dtype=float32),\n",
              " (array([0.03439867, 0.03375632, 0.02758047, 0.04146378], dtype=float32), {}),\n",
              " array([ 0.0350738 ,  0.22847213,  0.02840975, -0.24239124], dtype=float32),\n",
              " array([0.03964324, 0.03295614, 0.02356192, 0.05911575], dtype=float32),\n",
              " array([ 0.04030237, -0.16249558,  0.02474424,  0.35913852], dtype=float32),\n",
              " array([0.03705246, 0.03226604, 0.03192701, 0.07435959], dtype=float32),\n",
              " array([ 0.03769778,  0.22691607,  0.0334142 , -0.20808174], dtype=float32),\n",
              " array([ 0.0422361 ,  0.4215447 ,  0.02925256, -0.49003974], dtype=float32),\n",
              " array([ 0.05066699,  0.22602254,  0.01945177, -0.18828297], dtype=float32),\n",
              " array([ 0.05518744,  0.4208609 ,  0.01568611, -0.47476673], dtype=float32),\n",
              " array([ 0.06360466,  0.22552097,  0.00619078, -0.17718138], dtype=float32),\n",
              " array([ 0.06811508,  0.42055377,  0.00264715, -0.46790493], dtype=float32),\n",
              " array([ 0.07652616,  0.61563826, -0.00671095, -0.75975233], dtype=float32),\n",
              " array([ 0.08883892,  0.810852  , -0.021906  , -1.0545393 ], dtype=float32),\n",
              " array([ 0.10505596,  0.6160272 , -0.04299678, -0.7688121 ], dtype=float32),\n",
              " array([ 0.11737651,  0.81171376, -0.05837303, -1.0747079 ], dtype=float32),\n",
              " array([ 0.13361079,  1.0075564 , -0.07986718, -1.3851235 ], dtype=float32),\n",
              " array([ 0.15376191,  1.2035784 , -0.10756966, -1.701675  ], dtype=float32),\n",
              " array([ 0.17783347,  1.3997624 , -0.14160316, -2.0258145 ], dtype=float32),\n",
              " array([ 0.20582873,  1.2063609 , -0.18211944, -1.7801085 ], dtype=float32),\n",
              " (array([-0.00158297, -0.03750164, -0.00612882, -0.00376948], dtype=float32),\n",
              "  {}),\n",
              " array([-0.00233301, -0.23253517, -0.00620421,  0.28697345], dtype=float32),\n",
              " array([-0.00698371, -0.03732529, -0.00046474, -0.00765977], dtype=float32),\n",
              " array([-0.00773021, -0.23244056, -0.00061794,  0.2848765 ], dtype=float32),\n",
              " array([-0.01237903, -0.4275537 ,  0.00507959,  0.57736444], dtype=float32),\n",
              " array([-0.0209301 , -0.23250331,  0.01662688,  0.28628606], dtype=float32),\n",
              " array([-0.02558017, -0.42785838,  0.0223526 ,  0.5841662 ], dtype=float32),\n",
              " array([-0.03413733, -0.62328625,  0.03403592,  0.8838059 ], dtype=float32),\n",
              " array([-0.04660306, -0.81885344,  0.05171204,  1.1869915 ], dtype=float32),\n",
              " array([-0.06298013, -0.6244387 ,  0.07545187,  0.9109557 ], dtype=float32),\n",
              " array([-0.07546891, -0.82049614,  0.09367099,  1.226367  ], dtype=float32),\n",
              " array([-0.09187882, -1.0166907 ,  0.11819833,  1.5468677 ], dtype=float32),\n",
              " array([-0.11221264, -1.2130171 ,  0.14913568,  1.8739719 ], dtype=float32),\n",
              " array([-0.13647299, -1.4094199 ,  0.18661512,  2.2089896 ], dtype=float32),\n",
              " (array([-0.01689429, -0.03464741,  0.00153719,  0.02740062], dtype=float32),\n",
              "  {}),\n",
              " array([-0.01758723, -0.22979137,  0.0020852 ,  0.32056814], dtype=float32),\n",
              " array([-0.02218306, -0.03469918,  0.00849656,  0.02854354], dtype=float32),\n",
              " array([-0.02287704,  0.16029991,  0.00906744, -0.26144657], dtype=float32),\n",
              " array([-0.01967105,  0.35529125,  0.0038385 , -0.55125576], dtype=float32),\n",
              " array([-0.01256522,  0.5503591 , -0.00718661, -0.8427268 ], dtype=float32),\n",
              " array([-0.00155804,  0.35533595, -0.02404115, -0.55231255], dtype=float32),\n",
              " array([ 0.00554868,  0.16055973, -0.0350874 , -0.26730007], dtype=float32),\n",
              " array([ 0.00875987,  0.35616443, -0.0404334 , -0.57084006], dtype=float32),\n",
              " array([ 0.01588316,  0.16163212, -0.0518502 , -0.2911643 ], dtype=float32),\n",
              " array([ 0.0191158 ,  0.35745358, -0.05767349, -0.59973884], dtype=float32),\n",
              " array([ 0.02626488,  0.553333  , -0.06966826, -0.91001606], dtype=float32),\n",
              " array([ 0.03733154,  0.35921952, -0.08786859, -0.6400181 ], dtype=float32),\n",
              " array([ 0.04451593,  0.5554495 , -0.10066894, -0.95902765], dtype=float32),\n",
              " array([ 0.05562492,  0.3618145 , -0.1198495 , -0.69959235], dtype=float32),\n",
              " array([ 0.0628612 ,  0.55837613, -0.13384135, -1.0274713 ], dtype=float32),\n",
              " array([ 0.07402873,  0.7550011 , -0.15439077, -1.359003  ], dtype=float32),\n",
              " array([ 0.08912875,  0.562115  , -0.18157083, -1.1183261 ], dtype=float32),\n",
              " array([ 0.10037105,  0.7590938 , -0.20393735, -1.4620261 ], dtype=float32),\n",
              " (array([-0.02358542, -0.04545682, -0.00313577,  0.02332161], dtype=float32),\n",
              "  {}),\n",
              " array([-0.02449456, -0.24053366, -0.00266934,  0.31501353], dtype=float32),\n",
              " array([-0.02930523, -0.04537379,  0.00363093,  0.02148997], dtype=float32),\n",
              " array([-0.0302127 ,  0.1496959 ,  0.00406073, -0.27004516], dtype=float32),\n",
              " array([-0.02721879, -0.04548376, -0.00134017,  0.02391578], dtype=float32),\n",
              " array([-0.02812846, -0.24058646, -0.00086186,  0.31617558], dtype=float32),\n",
              " array([-0.03294019, -0.04545224,  0.00546165,  0.02322097], dtype=float32),\n",
              " array([-0.03384924, -0.2406521 ,  0.00592607,  0.3176221 ], dtype=float32),\n",
              " array([-0.03866228, -0.43585795,  0.01227851,  0.61216795], dtype=float32),\n",
              " array([-0.04737944, -0.24090973,  0.02452187,  0.3233775 ], dtype=float32),\n",
              " array([-0.05219763, -0.43637213,  0.03098942,  0.6236916 ], dtype=float32),\n",
              " array([-0.06092507, -0.6319127 ,  0.04346326,  0.92597115], dtype=float32),\n",
              " array([-0.07356333, -0.43740383,  0.06198268,  0.6472575 ], dtype=float32),\n",
              " array([-0.08231141, -0.24319774,  0.07492783,  0.37471902], dtype=float32),\n",
              " array([-0.08717536, -0.04921563,  0.08242221,  0.10657045], dtype=float32),\n",
              " array([-0.08815967,  0.14463438,  0.08455362, -0.15901275], dtype=float32),\n",
              " array([-0.08526698,  0.33845043,  0.08137336, -0.42386904], dtype=float32),\n",
              " array([-0.07849798,  0.532331  ,  0.07289598, -0.68983024], dtype=float32),\n",
              " array([-0.06785136,  0.72636974,  0.05909938, -0.95870286], dtype=float32),\n",
              " array([-0.05332396,  0.5305051 ,  0.03992532, -0.6480538 ], dtype=float32),\n",
              " array([-0.04271386,  0.7250488 ,  0.02696425, -0.9279018 ], dtype=float32),\n",
              " array([-0.02821288,  0.5295734 ,  0.00840621, -0.6268687 ], dtype=float32),\n",
              " array([-0.01762141,  0.3343351 , -0.00413117, -0.3315503 ], dtype=float32),\n",
              " array([-0.01093471,  0.5295156 , -0.01076217, -0.6255331 ], dtype=float32),\n",
              " array([-3.4440163e-04,  7.2478610e-01, -2.3272835e-02, -9.2158598e-01],\n",
              "       dtype=float32),\n",
              " array([ 0.01415132,  0.9202147 , -0.04170455, -1.221491  ], dtype=float32),\n",
              " array([ 0.03255561,  0.72565424, -0.06613437, -0.9421616 ], dtype=float32),\n",
              " array([ 0.0470687,  0.921602 , -0.0849776, -1.2548702], dtype=float32),\n",
              " array([ 0.06550074,  0.72766477, -0.11007501, -0.9899673 ], dtype=float32),\n",
              " array([ 0.08005404,  0.9240742 , -0.12987435, -1.3150951 ], dtype=float32),\n",
              " array([ 0.09853552,  0.73081255, -0.15617625, -1.06572   ], dtype=float32),\n",
              " array([ 0.11315177,  0.9276173 , -0.17749065, -1.4030637 ], dtype=float32),\n",
              " array([ 0.13170412,  0.7350878 , -0.20555192, -1.170715  ], dtype=float32),\n",
              " (array([ 0.01412532, -0.01979424, -0.00433513,  0.00777739], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.01372944, -0.21485375, -0.00417958,  0.29908937], dtype=float32),\n",
              " array([ 0.00943236, -0.01967247,  0.0018022 ,  0.00509123], dtype=float32),\n",
              " array([ 0.00903891,  0.17542359,  0.00190403, -0.28702253], dtype=float32),\n",
              " array([ 0.01254738,  0.37051833, -0.00383642, -0.57910436], dtype=float32),\n",
              " array([ 0.01995775,  0.17545035, -0.01541851, -0.28763244], dtype=float32),\n",
              " array([ 0.02346676, -0.01944836, -0.02117116,  0.00014803], dtype=float32),\n",
              " array([ 0.02307779, -0.21426038, -0.0211682 ,  0.28607672], dtype=float32),\n",
              " array([ 0.01879258, -0.01884304, -0.01544666, -0.0132066 ], dtype=float32),\n",
              " array([ 0.01841572,  0.176497  , -0.01571079, -0.31072283], dtype=float32),\n",
              " array([ 0.02194566, -0.01839764, -0.02192525, -0.02303575], dtype=float32),\n",
              " array([ 0.02157771, -0.21319841, -0.02238597,  0.2626497 ], dtype=float32),\n",
              " array([ 0.01731374, -0.01776419, -0.01713297, -0.03700913], dtype=float32),\n",
              " array([ 0.01695846, -0.21263632, -0.01787315,  0.25021932], dtype=float32),\n",
              " array([ 0.01270573, -0.40749854, -0.01286877,  0.53721154], dtype=float32),\n",
              " array([ 0.00455576, -0.21219803, -0.00212454,  0.24050172], dtype=float32),\n",
              " array([ 0.0003118 , -0.0170458 ,  0.0026855 , -0.05285059], dtype=float32),\n",
              " array([-2.9117691e-05,  1.7803754e-01,  1.6284847e-03, -3.4468502e-01],\n",
              "       dtype=float32),\n",
              " array([ 0.00353163,  0.37313628, -0.00526522, -0.636854  ], dtype=float32),\n",
              " array([ 0.01099436,  0.17808816, -0.01800229, -0.3458338 ], dtype=float32),\n",
              " array([ 0.01455612, -0.01677315, -0.02491897, -0.05888158], dtype=float32),\n",
              " array([ 0.01422066, -0.2115291 , -0.0260966 ,  0.22583625], dtype=float32),\n",
              " array([ 0.00999008, -0.0160441 , -0.02157988, -0.07496296], dtype=float32),\n",
              " array([ 0.00966919,  0.17938046, -0.02307914, -0.37437555], dtype=float32),\n",
              " array([ 0.0132568 , -0.01540618, -0.03056665, -0.08905805], dtype=float32),\n",
              " array([ 0.01294868, -0.21007697, -0.03234781,  0.19382653], dtype=float32),\n",
              " array([ 0.00874714, -0.01450758, -0.02847128, -0.10888268], dtype=float32),\n",
              " array([ 0.00845699,  0.18101054, -0.03064893, -0.41041043], dtype=float32),\n",
              " array([ 0.0120772 , -0.01366379, -0.03885714, -0.12754546], dtype=float32),\n",
              " array([ 0.01180393, -0.20820816, -0.04140805,  0.15262972], dtype=float32),\n",
              " array([ 0.00763976, -0.01251852, -0.03835545, -0.15282363], dtype=float32),\n",
              " array([ 0.00738939,  0.18313104, -0.04141193, -0.45735586], dtype=float32),\n",
              " array([ 0.01105201, -0.01138173, -0.05055904, -0.17800848], dtype=float32),\n",
              " array([ 0.01082438,  0.18442592, -0.05411921, -0.48620266], dtype=float32),\n",
              " array([ 0.0145129 ,  0.3802681 , -0.06384327, -0.7954391 ], dtype=float32),\n",
              " array([ 0.02211826,  0.18607771, -0.07975205, -0.52350414], dtype=float32),\n",
              " array([ 0.02583981, -0.00783656, -0.09022214, -0.25697953], dtype=float32),\n",
              " array([ 0.02568308, -0.20156233, -0.09536172,  0.00593789], dtype=float32),\n",
              " array([ 0.02165183, -0.3951965 , -0.09524297,  0.26707557], dtype=float32),\n",
              " array([ 0.0137479 , -0.1988534 , -0.08990145, -0.05406337], dtype=float32),\n",
              " array([ 0.00977084, -0.00256509, -0.09098272, -0.37370223], dtype=float32),\n",
              " array([ 0.00971953, -0.19628477, -0.09845677, -0.11103659], dtype=float32),\n",
              " array([ 0.00579384, -0.38986814, -0.1006775 ,  0.14903262], dtype=float32),\n",
              " array([-0.00200352, -0.5834151 , -0.09769685,  0.40833375], dtype=float32),\n",
              " array([-0.01367183, -0.3870535 , -0.08953017,  0.08651868], dtype=float32),\n",
              " array([-0.0214129 , -0.58078563, -0.08779979,  0.34966627], dtype=float32),\n",
              " array([-0.03302861, -0.7745563 , -0.08080647,  0.6134227 ], dtype=float32),\n",
              " array([-0.04851973, -0.57840365, -0.06853802,  0.29642257], dtype=float32),\n",
              " array([-0.06008781, -0.38237497, -0.06260957, -0.01706448], dtype=float32),\n",
              " array([-0.06773531, -0.5765458 , -0.06295086,  0.25522584], dtype=float32),\n",
              " array([-0.07926622, -0.38058412, -0.05784634, -0.05662972], dtype=float32),\n",
              " array([-0.0868779 , -0.574831  , -0.05897893,  0.21725589], dtype=float32),\n",
              " array([-0.09837452, -0.3789177 , -0.05463381, -0.09343287], dtype=float32),\n",
              " array([-0.10595287, -0.18305697, -0.05650247, -0.40283996], dtype=float32),\n",
              " array([-0.10961401, -0.3773339 , -0.06455927, -0.12849246], dtype=float32),\n",
              " array([-0.11716069, -0.5714745 , -0.06712912,  0.14314447], dtype=float32),\n",
              " array([-0.12859018, -0.37545857, -0.06426623, -0.1699383 ], dtype=float32),\n",
              " array([-0.13609935, -0.17947844, -0.067665  , -0.48218292], dtype=float32),\n",
              " array([-0.13968892, -0.37358335, -0.07730865, -0.21157017], dtype=float32),\n",
              " array([-0.14716059, -0.5675197 , -0.08154006,  0.0557594 ], dtype=float32),\n",
              " array([-0.15851098, -0.7613836 , -0.08042488,  0.3216428 ], dtype=float32),\n",
              " array([-0.17373866, -0.5652139 , -0.07399201,  0.00472003], dtype=float32),\n",
              " array([-0.18504293, -0.75920105, -0.07389762,  0.2731707 ], dtype=float32),\n",
              " array([-0.20022696, -0.95319504, -0.0684342 ,  0.5416614 ], dtype=float32),\n",
              " array([-0.21929085, -1.1472918 , -0.05760098,  0.8120211 ], dtype=float32),\n",
              " array([-0.24223669, -0.9514301 , -0.04136055,  0.50179046], dtype=float32),\n",
              " array([-0.2612653 , -0.7557503 , -0.03132474,  0.19636525], dtype=float32),\n",
              " array([-0.2763803 , -0.5601946 , -0.02739744, -0.10603234], dtype=float32),\n",
              " array([-0.2875842 , -0.36469096, -0.02951808, -0.4072316 ], dtype=float32),\n",
              " array([-0.294878  , -0.16916315, -0.03766271, -0.7090726 ], dtype=float32),\n",
              " array([-0.29826128, -0.36374375, -0.05184417, -0.42847887], dtype=float32),\n",
              " array([-0.30553615, -0.16792738, -0.06041374, -0.73704416], dtype=float32),\n",
              " array([-0.3088947 ,  0.02797463, -0.07515462, -1.0481119 ], dtype=float32),\n",
              " array([-0.3083352 , -0.16607398, -0.09611686, -0.7799353 ], dtype=float32),\n",
              " array([-0.31165668,  0.03022872, -0.11171557, -1.1012452 ], dtype=float32),\n",
              " array([-0.3110521 , -0.16326031, -0.13374047, -0.8455969 ], dtype=float32),\n",
              " array([-0.31431732, -0.35632885, -0.15065241, -0.5977828 ], dtype=float32),\n",
              " array([-0.3214439 , -0.15945567, -0.16260807, -0.93387216], dtype=float32),\n",
              " array([-0.324633  ,  0.03744208, -0.18128552, -1.272919  ], dtype=float32),\n",
              " array([-0.32388416,  0.23435397, -0.2067439 , -1.6164532 ], dtype=float32),\n",
              " (array([-0.04182612,  0.0110385 ,  0.01586349, -0.00035488], dtype=float32),\n",
              "  {}),\n",
              " array([-0.04160535,  0.2059294 ,  0.0158564 , -0.28799078], dtype=float32),\n",
              " array([-0.03748677,  0.01058496,  0.01009658,  0.00965064], dtype=float32),\n",
              " array([-0.03727506, -0.18468033,  0.01028959,  0.305502  ], dtype=float32),\n",
              " array([-0.04096867,  0.01029349,  0.01639963,  0.01608182], dtype=float32),\n",
              " array([-0.0407628 , -0.18505976,  0.01672127,  0.3138936 ], dtype=float32),\n",
              " array([-0.044464  , -0.3804159 ,  0.02299914,  0.6118026 ], dtype=float32),\n",
              " array([-0.05207232, -0.57585156,  0.03523519,  0.9116398 ], dtype=float32),\n",
              " array([-0.06358935, -0.7714321 ,  0.05346799,  1.2151855 ], dtype=float32),\n",
              " array([-0.07901799, -0.5770392 ,  0.0777717 ,  0.93972486], dtype=float32),\n",
              " array([-0.09055877, -0.3830468 ,  0.0965662 ,  0.67245775], dtype=float32),\n",
              " array([-0.09821971, -0.579369  ,  0.11001536,  0.99391544], dtype=float32),\n",
              " array([-0.10980709, -0.38587698,  0.12989366,  0.73771137], dtype=float32),\n",
              " array([-0.11752463, -0.58253074,  0.14464788,  1.0682884 ], dtype=float32),\n",
              " array([-0.12917525, -0.77923876,  0.16601366,  1.4026474 ], dtype=float32),\n",
              " array([-0.14476001, -0.9759878 ,  0.1940666 ,  1.7422975 ], dtype=float32),\n",
              " (array([-0.01642722, -0.0326221 , -0.01199012, -0.00078976], dtype=float32),\n",
              "  {}),\n",
              " array([-0.01707967, -0.22757007, -0.01200592,  0.28808615], dtype=float32),\n",
              " array([-0.02163107, -0.42251876, -0.00624419,  0.5769585 ], dtype=float32),\n",
              " array([-0.03008144, -0.61755264,  0.00529498,  0.8676678 ], dtype=float32),\n",
              " array([-0.04243249, -0.8127462 ,  0.02264833,  1.1620108 ], dtype=float32),\n",
              " array([-0.05868742, -0.6179265 ,  0.04588855,  0.87651414], dtype=float32),\n",
              " array([-0.07104595, -0.42345726,  0.06341883,  0.5986039 ], dtype=float32),\n",
              " array([-0.07951509, -0.6194065 ,  0.07539091,  0.9105696 ], dtype=float32),\n",
              " array([-0.09190322, -0.42538133,  0.0936023 ,  0.6425024 ], dtype=float32),\n",
              " array([-0.10041086, -0.6216747 ,  0.10645235,  0.9631325 ], dtype=float32),\n",
              " array([-0.11284435, -0.42813167,  0.125715  ,  0.7056992 ], dtype=float32),\n",
              " array([-0.12140698, -0.23495503,  0.13982898,  0.45508394], dtype=float32),\n",
              " array([-0.12610608, -0.0420584 ,  0.14893067,  0.20953894], dtype=float32),\n",
              " array([-0.12694725,  0.150655  ,  0.15312144, -0.03270733], dtype=float32),\n",
              " array([-0.12393415, -0.04629336,  0.1524673 ,  0.30410072], dtype=float32),\n",
              " array([-0.12486002, -0.2432221 ,  0.15854931,  0.640719  ], dtype=float32),\n",
              " array([-0.12972446, -0.44015753,  0.1713637 ,  0.97883546], dtype=float32),\n",
              " array([-0.1385276 , -0.63711077,  0.1909404 ,  1.3200729 ], dtype=float32),\n",
              " (array([ 0.00590329, -0.00943634, -0.02262541, -0.03771127], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.00571456,  0.18600263, -0.02337964, -0.337446  ], dtype=float32),\n",
              " array([ 0.00943461, -0.00877895, -0.03012856, -0.05222646], dtype=float32),\n",
              " array([ 0.00925903,  0.18676177, -0.03117308, -0.35426086], dtype=float32),\n",
              " array([ 0.01299427, -0.00790339, -0.0382583 , -0.07156841], dtype=float32),\n",
              " array([ 0.0128362 , -0.20245656, -0.03968967,  0.2088026 ], dtype=float32),\n",
              " array([ 0.00878707, -0.00679023, -0.03551362, -0.09613146], dtype=float32),\n",
              " array([ 0.00865127,  0.18882225, -0.03743625, -0.39980397], dtype=float32),\n",
              " array([ 0.01242771,  0.3844547 , -0.04543233, -0.7040507 ], dtype=float32),\n",
              " array([ 0.02011681,  0.5801758 , -0.05951334, -1.010682  ], dtype=float32),\n",
              " array([ 0.03172032,  0.38589638, -0.07972698, -0.73726535], dtype=float32),\n",
              " array([ 0.03943825,  0.5820236 , -0.09447229, -1.0539366 ], dtype=float32),\n",
              " array([ 0.05107872,  0.7782624 , -0.11555102, -1.3747157 ], dtype=float32),\n",
              " array([ 0.06664397,  0.97462326, -0.14304534, -1.7011893 ], dtype=float32),\n",
              " array([ 0.08613644,  0.78140974, -0.17706911, -1.4562411 ], dtype=float32),\n",
              " array([ 0.10176463,  0.5888472 , -0.20619394, -1.2237004 ], dtype=float32),\n",
              " (array([-0.02380175, -0.02552034, -0.03501756,  0.03121573], dtype=float32),\n",
              "  {}),\n",
              " array([-0.02431215, -0.22012308, -0.03439325,  0.31264782], dtype=float32),\n",
              " array([-0.02871461, -0.02452847, -0.02814029,  0.0093198 ], dtype=float32),\n",
              " array([-0.02920518,  0.17098552, -0.02795389, -0.29210722], dtype=float32),\n",
              " array([-0.02578547,  0.36649466, -0.03379604, -0.59347373], dtype=float32),\n",
              " array([-0.01845558,  0.17186166, -0.04566551, -0.3116251 ], dtype=float32),\n",
              " array([-0.01501835, -0.02258096, -0.05189801, -0.03368622], dtype=float32),\n",
              " array([-0.01546996,  0.17324534, -0.05257174, -0.34228134], dtype=float32),\n",
              " array([-0.01200506, -0.02109079, -0.05941737, -0.06662885], dtype=float32),\n",
              " array([-0.01242687, -0.21531276, -0.06074994,  0.20673156], dtype=float32),\n",
              " array([-0.01673313, -0.40951577, -0.05661531,  0.4796492 ], dtype=float32),\n",
              " array([-0.02492344, -0.2136422 , -0.04702233,  0.16967356], dtype=float32),\n",
              " array([-0.02919629, -0.01787983, -0.04362886, -0.13746487], dtype=float32),\n",
              " array([-0.02955388,  0.17783898, -0.04637815, -0.44358653], dtype=float32),\n",
              " array([-0.02599711,  0.37358543, -0.05524988, -0.75052077], dtype=float32),\n",
              " array([-0.0185254,  0.5694241, -0.0702603, -1.0600657], dtype=float32),\n",
              " array([-0.00713691,  0.76540273, -0.09146161, -1.3739479 ], dtype=float32),\n",
              " array([ 0.00817114,  0.9615411 , -0.11894057, -1.693778  ], dtype=float32),\n",
              " array([ 0.02740196,  0.7679762 , -0.15281613, -1.4403682 ], dtype=float32),\n",
              " array([ 0.04276149,  0.5750309 , -0.1816235 , -1.1990763 ], dtype=float32),\n",
              " array([ 0.05426211,  0.7719772 , -0.20560503, -1.5427408 ], dtype=float32),\n",
              " (array([ 0.04285331, -0.02035514, -0.02863592, -0.01651839], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.04244621, -0.21505496, -0.02896629,  0.2669938 ], dtype=float32),\n",
              " array([ 0.03814511, -0.01953184, -0.02362641, -0.03468275], dtype=float32),\n",
              " array([ 0.03775447, -0.21430716, -0.02432006,  0.25045317], dtype=float32),\n",
              " array([ 0.03346833, -0.40907353, -0.019311  ,  0.53536695], dtype=float32),\n",
              " array([ 0.02528686, -0.6039187 , -0.00860366,  0.8219031 ], dtype=float32),\n",
              " array([ 0.01320849, -0.7989219 ,  0.0078344 ,  1.1118675 ], dtype=float32),\n",
              " array([-0.00276995, -0.9941458 ,  0.03007175,  1.4069978 ], dtype=float32),\n",
              " array([-0.02265287, -1.1896278 ,  0.05821171,  1.708928  ], dtype=float32),\n",
              " array([-0.04644542, -1.3853685 ,  0.09239027,  2.0191462 ], dtype=float32),\n",
              " array([-0.07415279, -1.1913179 ,  0.13277319,  1.7564359 ], dtype=float32),\n",
              " array([-0.09797915, -1.3876715 ,  0.1679019 ,  2.0872948 ], dtype=float32),\n",
              " (array([ 0.03384927, -0.04248391, -0.02774385,  0.0281541 ], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.03299959,  0.1530247 , -0.02718077, -0.2731516 ], dtype=float32),\n",
              " array([ 0.03606008,  0.34852374, -0.0326438 , -0.574282  ], dtype=float32),\n",
              " array([ 0.04303056,  0.54408777, -0.04412944, -0.8770673 ], dtype=float32),\n",
              " array([ 0.05391231,  0.34959245, -0.06167079, -0.5985782 ], dtype=float32),\n",
              " array([ 0.06090416,  0.5455206 , -0.07364235, -0.9100315 ], dtype=float32),\n",
              " array([ 0.07181457,  0.7415578 , -0.09184298, -1.2249216 ], dtype=float32),\n",
              " array([ 0.08664573,  0.5477306 , -0.11634141, -0.9623701 ], dtype=float32),\n",
              " array([ 0.09760034,  0.35434797, -0.13558881, -0.7083842 ], dtype=float32),\n",
              " array([ 0.1046873 ,  0.16133869, -0.1497565 , -0.46126857], dtype=float32),\n",
              " array([ 0.10791408,  0.35822475, -0.15898187, -0.7971562 ], dtype=float32),\n",
              " array([ 0.11507857,  0.55512923, -0.174925  , -1.1353322 ], dtype=float32),\n",
              " array([ 0.12618116,  0.75205374, -0.19763164, -1.4773773 ], dtype=float32),\n",
              " (array([-0.04759818, -0.01888063,  0.03748405, -0.02878556], dtype=float32),\n",
              "  {}),\n",
              " array([-0.04797579,  0.17568429,  0.03690834, -0.30941018], dtype=float32),\n",
              " array([-0.04446211, -0.01994357,  0.03072013, -0.00531967], dtype=float32),\n",
              " array([-0.04486098,  0.17472465,  0.03061374, -0.28815392], dtype=float32),\n",
              " array([-0.04136649,  0.36939695,  0.02485066, -0.57102656], dtype=float32),\n",
              " array([-0.03397855,  0.1739355 ,  0.01343013, -0.27061954], dtype=float32),\n",
              " array([-0.03049984,  0.36886325,  0.00801774, -0.55903643], dtype=float32),\n",
              " array([-0.02312257,  0.56387174, -0.00316299, -0.8491826 ], dtype=float32),\n",
              " array([-0.01184514,  0.36879307, -0.02014664, -0.55749595], dtype=float32),\n",
              " array([-0.00446928,  0.564192  , -0.03129656, -0.85645753], dtype=float32),\n",
              " array([ 0.00681456,  0.75972605, -0.04842571, -1.1588148 ], dtype=float32),\n",
              " array([ 0.02200909,  0.56526744, -0.07160201, -0.88170034], dtype=float32),\n",
              " array([ 0.03331443,  0.7612851 , -0.08923601, -1.1960064 ], dtype=float32),\n",
              " array([ 0.04854014,  0.5674244 , -0.11315615, -0.9325731 ], dtype=float32),\n",
              " array([ 0.05988862,  0.7638763 , -0.13180761, -1.2585633 ], dtype=float32),\n",
              " array([ 0.07516615,  0.5706639 , -0.15697888, -1.009898  ], dtype=float32),\n",
              " array([ 0.08657943,  0.76749283, -0.17717683, -1.3474735 ], dtype=float32),\n",
              " array([ 0.10192928,  0.57498443, -0.2041263 , -1.1150492 ], dtype=float32),\n",
              " (array([-0.01661867, -0.02641049, -0.0409108 , -0.0002698 ], dtype=float32),\n",
              "  {}),\n",
              " array([-0.01714688,  0.16927357, -0.0409162 , -0.30557472], dtype=float32),\n",
              " array([-0.0137614 ,  0.364954  , -0.04702769, -0.61087567], dtype=float32),\n",
              " array([-0.00646233,  0.17051981, -0.05924521, -0.3333679 ], dtype=float32),\n",
              " array([-0.00305193, -0.02371106, -0.06591257, -0.05994067], dtype=float32),\n",
              " array([-0.00352615,  0.172291  , -0.06711138, -0.3726696 ], dtype=float32),\n",
              " array([-8.0330508e-05, -2.1816581e-02, -7.4564770e-02, -1.0187962e-01],\n",
              "       dtype=float32),\n",
              " array([-0.00051666, -0.21579511, -0.07660236,  0.16637795], dtype=float32),\n",
              " array([-0.00483256, -0.40974173, -0.07327481,  0.43394566], dtype=float32),\n",
              " array([-0.0130274 , -0.213663  , -0.06459589,  0.11909329], dtype=float32),\n",
              " array([-0.01730066, -0.01767787, -0.06221402, -0.19324927], dtype=float32),\n",
              " array([-0.01765422, -0.21185723, -0.06607901,  0.07917713], dtype=float32),\n",
              " array([-0.02189136, -0.40597275, -0.06449547,  0.35030183], dtype=float32),\n",
              " array([-0.03001082, -0.600121  , -0.05748943,  0.62197024], dtype=float32),\n",
              " array([-0.04201324, -0.794395  , -0.04505002,  0.89600724], dtype=float32),\n",
              " array([-0.05790114, -0.9888782 , -0.02712988,  1.1741958 ], dtype=float32),\n",
              " array([-0.0776787 , -1.1836373 , -0.00364597,  1.4582517 ], dtype=float32),\n",
              " array([-0.10135145, -1.3787143 ,  0.02551907,  1.7497934 ], dtype=float32),\n",
              " array([-0.12892573, -1.5741166 ,  0.06051493,  2.050303  ], dtype=float32),\n",
              " array([-0.16040806, -1.3796643 ,  0.101521  ,  1.7769393 ], dtype=float32),\n",
              " array([-0.18800135, -1.1858219 ,  0.13705978,  1.5174686 ], dtype=float32),\n",
              " array([-0.21171778, -1.3823096 ,  0.16740915,  1.8496057 ], dtype=float32),\n",
              " array([-0.23936398, -1.5788324 ,  0.20440127,  2.1892574 ], dtype=float32),\n",
              " (array([ 0.00039395,  0.00991427, -0.03959865,  0.00013593], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.00059224,  0.2055811 , -0.03959594, -0.30477318], dtype=float32),\n",
              " array([ 0.00470386,  0.40124428, -0.0456914 , -0.6096761 ], dtype=float32),\n",
              " array([ 0.01272874,  0.5969742 , -0.05788492, -0.9163931 ], dtype=float32),\n",
              " array([ 0.02466823,  0.4026807 , -0.07621279, -0.6424497 ], dtype=float32),\n",
              " array([ 0.03272184,  0.20869915, -0.08906177, -0.37470686], dtype=float32),\n",
              " array([ 0.03689583,  0.0149477 , -0.09655592, -0.11138113], dtype=float32),\n",
              " array([ 0.03719478,  0.21131112, -0.09878354, -0.43289763], dtype=float32),\n",
              " array([ 0.041421  ,  0.40768278, -0.10744149, -0.75501424], dtype=float32),\n",
              " array([ 0.04957466,  0.21419303, -0.12254178, -0.4979803 ], dtype=float32),\n",
              " array([ 0.05385852,  0.02099262, -0.13250138, -0.24629001], dtype=float32),\n",
              " array([ 0.05427837,  0.21773359, -0.13742718, -0.5776562 ], dtype=float32),\n",
              " array([ 0.05863304,  0.41448694, -0.1489803 , -0.91028017], dtype=float32),\n",
              " array([ 0.06692278,  0.6112768 , -0.1671859 , -1.2458335 ], dtype=float32),\n",
              " array([ 0.07914831,  0.8081012 , -0.19210258, -1.5858777 ], dtype=float32),\n",
              " (array([-0.04315971,  0.02703363,  0.02978997, -0.00963373], dtype=float32),\n",
              "  {}),\n",
              " array([-0.04261904,  0.22171597,  0.02959729, -0.2927707 ], dtype=float32),\n",
              " array([-0.03818472,  0.0261848 ,  0.02374188,  0.00909791], dtype=float32),\n",
              " array([-0.03766102,  0.22095837,  0.02392383, -0.27600062], dtype=float32),\n",
              " array([-0.03324186,  0.41573095,  0.01840382, -0.56104296], dtype=float32),\n",
              " array([-0.02492724,  0.61058986,  0.00718296, -0.8478714 ], dtype=float32),\n",
              " array([-0.01271544,  0.41537067, -0.00977447, -0.5529384 ], dtype=float32),\n",
              " array([-0.00440803,  0.22038734, -0.02083324, -0.26335102], dtype=float32),\n",
              " array([-2.8002970e-07,  4.1580036e-01, -2.6100256e-02, -5.6253153e-01],\n",
              "       dtype=float32),\n",
              " array([ 0.00831573,  0.61127865, -0.03735089, -0.86332166], dtype=float32),\n",
              " array([ 0.0205413 ,  0.8068887 , -0.05461732, -1.1675106 ], dtype=float32),\n",
              " array([ 0.03667907,  1.0026771 , -0.07796753, -1.4768049 ], dtype=float32),\n",
              " array([ 0.05673262,  0.8085892 , -0.10750363, -1.2094567 ], dtype=float32),\n",
              " array([ 0.0729044 ,  1.0049225 , -0.13169277, -1.5338018 ], dtype=float32),\n",
              " array([ 0.09300285,  0.81161   , -0.1623688 , -1.2849497 ], dtype=float32),\n",
              " array([ 0.10923505,  0.6188841 , -0.1880678 , -1.0471901 ], dtype=float32),\n",
              " array([ 0.12161274,  0.4266877 , -0.2090116 , -0.81894547], dtype=float32),\n",
              " (array([-0.01031106,  0.01905447,  0.02699741,  0.01348536], dtype=float32),\n",
              "  {}),\n",
              " array([-0.00992997,  0.21377905,  0.02726711, -0.2705588 ], dtype=float32),\n",
              " array([-0.00565439,  0.4085015 ,  0.02185594, -0.55451834], dtype=float32),\n",
              " array([ 0.00251564,  0.60330987,  0.01076557, -0.84023595], dtype=float32),\n",
              " array([ 0.01458184,  0.40804258, -0.00603915, -0.544187  ], dtype=float32),\n",
              " array([ 0.02274269,  0.21300603, -0.01692289, -0.25341302], dtype=float32),\n",
              " array([ 0.02700281,  0.4083655 , -0.02199115, -0.55138534], dtype=float32),\n",
              " array([ 0.03517012,  0.60378927, -0.03301886, -0.850915  ], dtype=float32),\n",
              " array([ 0.0472459 ,  0.7993455 , -0.05003716, -1.1537952 ], dtype=float32),\n",
              " array([ 0.06323282,  0.6049106 , -0.07311306, -0.8772127 ], dtype=float32),\n",
              " array([ 0.07533102,  0.4108544 , -0.09065732, -0.60838217], dtype=float32),\n",
              " array([ 0.08354811,  0.60711896, -0.10282496, -0.92818683], dtype=float32),\n",
              " array([ 0.0956905,  0.4135243, -0.1213887, -0.6695059], dtype=float32),\n",
              " array([ 0.10396098,  0.6101062 , -0.13477881, -0.99780965], dtype=float32),\n",
              " array([ 0.1161631 ,  0.80674744, -0.154735  , -1.3296016 ], dtype=float32),\n",
              " array([ 0.13229805,  1.0034456 , -0.18132704, -1.6664345 ], dtype=float32),\n",
              " (array([-0.04279719, -0.02090649, -0.0444557 , -0.01472376], dtype=float32),\n",
              "  {}),\n",
              " array([-0.04321532,  0.17482388, -0.04475018, -0.32109493], dtype=float32),\n",
              " array([-0.03971884, -0.01963316, -0.05117208, -0.04285353], dtype=float32),\n",
              " array([-0.0401115 ,  0.17618382, -0.05202915, -0.35123253], dtype=float32),\n",
              " array([-0.03658783, -0.01816111, -0.0590538 , -0.0753993 ], dtype=float32),\n",
              " array([-0.03695105,  0.17775553, -0.06056178, -0.3861137 ], dtype=float32),\n",
              " array([-0.03339594,  0.3736826 , -0.06828406, -0.6972598 ], dtype=float32),\n",
              " array([-0.02592229,  0.56968164, -0.08222926, -1.0106331 ], dtype=float32),\n",
              " array([-0.01452865,  0.7657989 , -0.10244191, -1.3279632 ], dtype=float32),\n",
              " array([ 7.8732462e-04,  5.7210815e-01, -1.2900119e-01, -1.0690155e+00],\n",
              "       dtype=float32),\n",
              " array([ 0.01222949,  0.76867825, -0.15038149, -1.3992419 ], dtype=float32),\n",
              " array([ 0.02760305,  0.96531546, -0.17836633, -1.7349145 ], dtype=float32),\n",
              " (array([ 0.01978691, -0.03610841, -0.00959862,  0.03796761], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.01906474, -0.23109141, -0.00883927,  0.32760668], dtype=float32),\n",
              " array([ 0.01444291, -0.03584474, -0.00228713,  0.03214942], dtype=float32),\n",
              " array([ 0.01372602, -0.23093382, -0.00164414,  0.32410985], dtype=float32),\n",
              " array([ 0.00910734, -0.4260323 ,  0.00483805,  0.6162738 ], dtype=float32),\n",
              " array([ 5.8669405e-04, -6.2122154e-01,  1.7163530e-02,  9.1047662e-01],\n",
              "       dtype=float32),\n",
              " array([-0.01183774, -0.8165715 ,  0.03537306,  1.2085042 ], dtype=float32),\n",
              " array([-0.02816917, -0.62192386,  0.05954315,  0.9271129 ], dtype=float32),\n",
              " array([-0.04060764, -0.81779706,  0.07808541,  1.2378974 ], dtype=float32),\n",
              " array([-0.05696359, -0.62376016,  0.10284335,  0.9706628 ], dtype=float32),\n",
              " array([-0.06943879, -0.43015772,  0.12225661,  0.7119761 ], dtype=float32),\n",
              " array([-0.07804194, -0.62674135,  0.13649613,  1.0405046 ], dtype=float32),\n",
              " array([-0.09057677, -0.8233865 ,  0.15730622,  1.3727341 ], dtype=float32),\n",
              " array([-0.1070445, -0.6305418,  0.1847609,  1.1330962], dtype=float32),\n",
              " array([-0.11965533, -0.827537  ,  0.20742282,  1.477571  ], dtype=float32),\n",
              " (array([-0.03208663,  0.00148615, -0.04685338,  0.00523903], dtype=float32),\n",
              "  {}),\n",
              " array([-0.03205691,  0.19724764, -0.0467486 , -0.30185083], dtype=float32),\n",
              " array([-0.02811196,  0.3930036 , -0.05278561, -0.60890305], dtype=float32),\n",
              " array([-0.02025188,  0.58882225, -0.06496368, -0.9177336 ], dtype=float32),\n",
              " array([-0.00847544,  0.78475946, -0.08331835, -1.2301054 ], dtype=float32),\n",
              " array([ 0.00721975,  0.5908023 , -0.10792045, -0.9646462 ], dtype=float32),\n",
              " array([ 0.0190358 ,  0.39728263, -0.12721337, -0.7077225 ], dtype=float32),\n",
              " array([ 0.02698145,  0.5939158 , -0.14136782, -1.0375888 ], dtype=float32),\n",
              " array([ 0.03885977,  0.7906046 , -0.1621196 , -1.3711026 ], dtype=float32),\n",
              " array([ 0.05467186,  0.5978386 , -0.18954165, -1.1331997 ], dtype=float32),\n",
              " (array([-0.03587072, -0.02085316, -0.02936663,  0.02386191], dtype=float32),\n",
              "  {}),\n",
              " array([-0.03628778, -0.21554193, -0.0288894 ,  0.3071366 ], dtype=float32),\n",
              " array([-0.04059862, -0.02002048, -0.02274667,  0.00548451], dtype=float32),\n",
              " array([-0.04099903,  0.17542018, -0.02263697, -0.2942876 ], dtype=float32),\n",
              " array([-0.03749063, -0.01937184, -0.02852273, -0.00882911], dtype=float32),\n",
              " array([-0.03787807, -0.21407337, -0.02869931,  0.27471986], dtype=float32),\n",
              " array([-0.04215953, -0.40877435, -0.02320491,  0.5582146 ], dtype=float32),\n",
              " array([-0.05033502, -0.21333447, -0.01204062,  0.25831208], dtype=float32),\n",
              " array([-0.05460171, -0.01804271, -0.00687438, -0.03814417], dtype=float32),\n",
              " array([-0.05496256,  0.17717713, -0.00763726, -0.33298808], dtype=float32),\n",
              " array([-0.05141902, -0.01783528, -0.01429702, -0.04272332], dtype=float32),\n",
              " array([-0.05177573,  0.17748873, -0.01515149, -0.33988258], dtype=float32),\n",
              " array([-0.04822595,  0.37282297, -0.02194914, -0.63730466], dtype=float32),\n",
              " array([-0.0407695 ,  0.568244  , -0.03469523, -0.9368181 ], dtype=float32),\n",
              " array([-0.02940461,  0.76381624, -0.0534316 , -1.2401983 ], dtype=float32),\n",
              " array([-0.01412829,  0.95958203, -0.07823557, -1.5491292 ], dtype=float32),\n",
              " array([ 0.00506335,  0.76548123, -0.10921815, -1.2818465 ], dtype=float32),\n",
              " array([ 0.02037298,  0.9618117 , -0.13485508, -1.6066339 ], dtype=float32),\n",
              " array([ 0.03960921,  1.1582459 , -0.16698776, -1.9381373 ], dtype=float32),\n",
              " array([ 0.06277413,  0.96525556, -0.20575051, -1.7015451 ], dtype=float32),\n",
              " (array([-0.04628768,  0.04713081,  0.03527035, -0.01734914], dtype=float32),\n",
              "  {}),\n",
              " array([-0.04534506, -0.14847875,  0.03492337,  0.28625003], dtype=float32),\n",
              " array([-0.04831464,  0.04612819,  0.04064837,  0.00478301], dtype=float32),\n",
              " array([-0.04739207, -0.14955242,  0.04074403,  0.31000882], dtype=float32),\n",
              " array([-0.05038312, -0.3452305 ,  0.0469442 ,  0.61525774], dtype=float32),\n",
              " array([-0.05728773, -0.15079479,  0.05924936,  0.33772203], dtype=float32),\n",
              " array([-0.06030363, -0.3467076 ,  0.0660038 ,  0.64848477], dtype=float32),\n",
              " array([-0.06723778, -0.15256426,  0.07897349,  0.37729484], dtype=float32),\n",
              " array([-0.07028907, -0.34871382,  0.08651939,  0.6937962 ], dtype=float32),\n",
              " array([-0.07726334, -0.5449226 ,  0.10039531,  1.0124135 ], dtype=float32),\n",
              " array([-0.0881618 , -0.7412302 ,  0.12064359,  1.3348589 ], dtype=float32),\n",
              " array([-0.1029864 , -0.54781747,  0.14734076,  1.0822318 ], dtype=float32),\n",
              " array([-0.11394275, -0.35491464,  0.1689854 ,  0.8391743 ], dtype=float32),\n",
              " array([-0.12104104, -0.55189097,  0.18576889,  1.1798757 ], dtype=float32),\n",
              " array([-0.13207886, -0.3596015 ,  0.2093664 ,  0.95070666], dtype=float32),\n",
              " (array([-0.04325916,  0.02564264,  0.00274125,  0.01141468], dtype=float32),\n",
              "  {}),\n",
              " array([-0.0427463 , -0.16951852,  0.00296954,  0.30496123], dtype=float32),\n",
              " array([-0.04613667,  0.025561  ,  0.00906877,  0.01321632], dtype=float32),\n",
              " array([-0.04562545,  0.22055173,  0.00933309, -0.27659157], dtype=float32),\n",
              " array([-0.04121442,  0.02529787,  0.00380126,  0.01902035], dtype=float32),\n",
              " array([-0.04070846,  0.2203651 ,  0.00418167, -0.27246082], dtype=float32),\n",
              " array([-0.03630116,  0.02518373, -0.00126755,  0.02153808], dtype=float32),\n",
              " array([-0.03579748,  0.22032383, -0.00083679, -0.2715445 ], dtype=float32),\n",
              " array([-0.03139101,  0.02521384, -0.00626768,  0.02087438], dtype=float32),\n",
              " array([-0.03088673, -0.16981767, -0.00585019,  0.3115732 ], dtype=float32),\n",
              " array([-3.4283083e-02, -3.6485580e-01,  3.8127470e-04,  6.0240543e-01],\n",
              "       dtype=float32),\n",
              " array([-0.0415802 , -0.16973917,  0.01242938,  0.30984262], dtype=float32),\n",
              " array([-0.04497498, -0.36503598,  0.01862624,  0.6064194 ], dtype=float32),\n",
              " array([-0.0522757 , -0.56041336,  0.03075462,  0.9049104 ], dtype=float32),\n",
              " array([-0.06348397, -0.3657211 ,  0.04885283,  0.6220505 ], dtype=float32),\n",
              " array([-0.07079839, -0.17131415,  0.06129384,  0.34514505], dtype=float32),\n",
              " array([-0.07422467,  0.02288476,  0.06819674,  0.07240281], dtype=float32),\n",
              " array([-0.07376698, -0.17314525,  0.0696448 ,  0.3857986 ], dtype=float32),\n",
              " array([-0.07722989, -0.3691832 ,  0.07736077,  0.6996017 ], dtype=float32),\n",
              " array([-0.08461355, -0.5652876 ,  0.09135281,  1.0156    ], dtype=float32),\n",
              " array([-0.0959193, -0.3714947,  0.1116648,  0.7529431], dtype=float32),\n",
              " array([-0.10334919, -0.5679647 ,  0.12672366,  1.0785738 ], dtype=float32),\n",
              " array([-0.11470849, -0.37472317,  0.14829515,  0.828193  ], dtype=float32),\n",
              " array([-0.12220296, -0.18190606,  0.164859  ,  0.58558095], dtype=float32),\n",
              " array([-0.12584108, -0.37890658,  0.17657062,  0.9253245 ], dtype=float32),\n",
              " array([-0.1334192 , -0.18655215,  0.1950771 ,  0.6929214 ], dtype=float32),\n",
              " array([-0.13715024, -0.38376832,  0.20893554,  1.0401243 ], dtype=float32),\n",
              " (array([-0.02142735,  0.01476881,  0.02234317, -0.03550925], dtype=float32),\n",
              "  {}),\n",
              " array([-0.02113198,  0.20956334,  0.02163299, -0.3210598 ], dtype=float32),\n",
              " array([-0.01694071,  0.40437064,  0.01521179, -0.60684276], dtype=float32),\n",
              " array([-0.00885329,  0.20903935,  0.00307494, -0.30940762], dtype=float32),\n",
              " array([-0.00467251,  0.01387372, -0.00311321, -0.01575652], dtype=float32),\n",
              " array([-0.00439503,  0.20904018, -0.00342835, -0.30942008], dtype=float32),\n",
              " array([-0.00021423,  0.01396724, -0.00961675, -0.01782032], dtype=float32),\n",
              " array([ 6.5114764e-05, -1.8101548e-01, -9.9731535e-03,  2.7181295e-01],\n",
              "       dtype=float32),\n",
              " array([-0.00355519, -0.37599373, -0.00453689,  0.5613337 ], dtype=float32),\n",
              " array([-0.01107507, -0.5710517 ,  0.00668978,  0.8525838 ], dtype=float32),\n",
              " array([-0.0224961 , -0.3760216 ,  0.02374146,  0.56201196], dtype=float32),\n",
              " array([-0.03001653, -0.18124071,  0.0349817 ,  0.27690235], dtype=float32),\n",
              " array([-0.03364135,  0.01336516,  0.04051974, -0.00454536], dtype=float32),\n",
              " array([-0.03337405,  0.20788328,  0.04042884, -0.2841735 ], dtype=float32),\n",
              " array([-0.02921638,  0.01220873,  0.03474537,  0.02098133], dtype=float32),\n",
              " array([-0.02897221, -0.18339384,  0.03516499,  0.32442117], dtype=float32),\n",
              " array([-0.03264008,  0.01121022,  0.04165342,  0.04303193], dtype=float32),\n",
              " array([-0.03241588,  0.20571089,  0.04251406, -0.23622346], dtype=float32),\n",
              " array([-0.02830166,  0.40020046,  0.03778959, -0.5151988 ], dtype=float32),\n",
              " array([-0.02029765,  0.2045673 ,  0.02748561, -0.21085109], dtype=float32),\n",
              " array([-0.01620631,  0.00906335,  0.02326859,  0.09037381], dtype=float32),\n",
              " array([-0.01602504, -0.18638426,  0.02507606,  0.3903062 ], dtype=float32),\n",
              " array([-0.01975272,  0.00837298,  0.03288219,  0.10563377], dtype=float32),\n",
              " array([-0.01958526,  0.20300867,  0.03499486, -0.1764963 ], dtype=float32),\n",
              " array([-0.01552509,  0.00740383,  0.03146493,  0.1270177 ], dtype=float32),\n",
              " array([-0.01537701,  0.20206122,  0.03400529, -0.1555747 ], dtype=float32),\n",
              " array([-0.01133579,  0.3966802 ,  0.0308938 , -0.43733877], dtype=float32),\n",
              " array([-0.00340219,  0.59135157,  0.02214702, -0.72012514], dtype=float32),\n",
              " array([ 0.00842485,  0.3959303 ,  0.00774452, -0.42055443], dtype=float32),\n",
              " array([ 1.6343452e-02,  5.9094167e-01, -6.6657021e-04, -7.1078587e-01],\n",
              "       dtype=float32),\n",
              " array([ 0.02816229,  0.78607285, -0.01488229, -1.0036786 ], dtype=float32),\n",
              " array([ 0.04388374,  0.9813904 , -0.03495586, -1.3009976 ], dtype=float32),\n",
              " array([ 0.06351155,  1.176938  , -0.06097581, -1.6044149 ], dtype=float32),\n",
              " array([ 0.08705031,  1.3727261 , -0.09306411, -1.9154669 ], dtype=float32),\n",
              " array([ 0.11450484,  1.1787211 , -0.13137345, -1.65304   ], dtype=float32),\n",
              " array([ 0.13807926,  0.9853552 , -0.16443425, -1.4040034 ], dtype=float32),\n",
              " array([ 0.15778635,  1.1820925 , -0.19251432, -1.7432549 ], dtype=float32),\n",
              " (array([ 0.02991766,  0.02179066, -0.03124558,  0.04097376], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.03035347,  0.21734641, -0.0304261 , -0.26140139], dtype=float32),\n",
              " array([ 0.0347004 ,  0.41288918, -0.03565413, -0.5635237 ], dtype=float32),\n",
              " array([ 0.04295819,  0.6084928 , -0.0469246 , -0.8672227 ], dtype=float32),\n",
              " array([ 0.05512804,  0.41403973, -0.06426906, -0.589655  ], dtype=float32),\n",
              " array([ 0.06340884,  0.21987376, -0.07606216, -0.31788942], dtype=float32),\n",
              " array([ 0.06780631,  0.02591291, -0.08241995, -0.05013006], dtype=float32),\n",
              " array([ 0.06832457,  0.22211404, -0.08342255, -0.36763674], dtype=float32),\n",
              " array([ 0.07276685,  0.4183162 , -0.09077528, -0.68541425], dtype=float32),\n",
              " array([ 0.08113317,  0.6145733 , -0.10448357, -1.0052391 ], dtype=float32),\n",
              " array([ 0.09342464,  0.42099014, -0.12458835, -0.7471103 ], dtype=float32),\n",
              " array([ 0.10184444,  0.22778718, -0.13953055, -0.49608645], dtype=float32),\n",
              " array([ 0.10640018,  0.03488006, -0.14945228, -0.25042695], dtype=float32),\n",
              " array([ 0.10709779,  0.23178507, -0.15446082, -0.58626765], dtype=float32),\n",
              " array([ 0.11173349,  0.03912533, -0.16618618, -0.34594968], dtype=float32),\n",
              " array([ 0.11251599,  0.23617312, -0.17310517, -0.6860834 ], dtype=float32),\n",
              " array([ 0.11723946,  0.43322152, -0.18682684, -1.0278777 ], dtype=float32),\n",
              " array([ 0.12590389,  0.63027203, -0.2073844 , -1.3729181 ], dtype=float32),\n",
              " (array([ 0.00877133,  0.04115919,  0.04825992, -0.04646812], dtype=float32),\n",
              "  {}),\n",
              " array([ 0.00959452,  0.2355571 ,  0.04733056, -0.32354257], dtype=float32),\n",
              " array([ 0.01430566,  0.42997426,  0.04085971, -0.60093176], dtype=float32),\n",
              " array([ 0.02290514,  0.6245015 ,  0.02884107, -0.8804697 ], dtype=float32),\n",
              " array([ 0.03539518,  0.42899987,  0.01123168, -0.57886106], dtype=float32),\n",
              " array([ 0.04397517,  0.23372233, -0.00034554, -0.28266117], dtype=float32),\n",
              " array([ 0.04864962,  0.42884922, -0.00599877, -0.57545304], dtype=float32),\n",
              " array([ 0.0572266 ,  0.23381187, -0.01750783, -0.28466594], dtype=float32),\n",
              " array([ 0.06190284,  0.03894394, -0.02320115,  0.00244411], dtype=float32),\n",
              " array([ 0.06268172,  0.23439081, -0.02315226, -0.29746783], dtype=float32),\n",
              " array([ 0.06736954,  0.42983502, -0.02910162, -0.59736174], dtype=float32),\n",
              " array([ 0.07596624,  0.23513213, -0.04104885, -0.3139857 ], dtype=float32),\n",
              " array([ 0.08066888,  0.04061823, -0.04732857, -0.03452563], dtype=float32),\n",
              " array([ 0.08148124,  0.23638582, -0.04801908, -0.34175757], dtype=float32),\n",
              " array([ 0.08620896,  0.4321569 , -0.05485423, -0.64918786], dtype=float32),\n",
              " array([ 0.0948521 ,  0.23784025, -0.06783799, -0.3742704 ], dtype=float32),\n",
              " array([ 0.09960891,  0.04374421, -0.0753234 , -0.10372508], dtype=float32),\n",
              " array([ 0.10048379,  0.23986028, -0.0773979 , -0.41918918], dtype=float32),\n",
              " array([ 0.105281  ,  0.43598875, -0.08578169, -0.7352334 ], dtype=float32),\n",
              " array([ 0.11400077,  0.24214993, -0.10048635, -0.47073323], dtype=float32),\n",
              " array([ 0.11884376,  0.04858027, -0.10990102, -0.21133673], dtype=float32),\n",
              " array([ 0.11981537,  0.24508795, -0.11412776, -0.53656584], dtype=float32),\n",
              " array([ 0.12471713,  0.441614  , -0.12485907, -0.86291796], dtype=float32),\n",
              " array([ 0.1335494 ,  0.24839297, -0.14211743, -0.61195594], dtype=float32),\n",
              " array([ 0.13851728,  0.05551324, -0.15435655, -0.36719516], dtype=float32),\n",
              " array([ 0.13962753, -0.13711706, -0.16170046, -0.1268859 ], dtype=float32),\n",
              " array([ 0.1368852 , -0.32959768, -0.16423817,  0.1107356 ], dtype=float32),\n",
              " array([ 0.13029324, -0.5220319 , -0.16202345,  0.34743336], dtype=float32),\n",
              " array([ 0.1198526 , -0.32502088, -0.15507479,  0.00836048], dtype=float32),\n",
              " array([ 0.11335219, -0.12805423, -0.15490758, -0.32895353], dtype=float32),\n",
              " array([ 0.1107911 , -0.32067072, -0.16148666, -0.08884934], dtype=float32),\n",
              " array([ 0.10437769, -0.12364681, -0.16326363, -0.4278111 ], dtype=float32),\n",
              " array([ 0.10190475, -0.31612566, -0.17181987, -0.19071874], dtype=float32),\n",
              " array([ 0.09558224, -0.11901545, -0.17563424, -0.5322973 ], dtype=float32),\n",
              " array([ 0.09320193,  0.07808525, -0.18628018, -0.8747714 ], dtype=float32),\n",
              " array([ 0.09476363, -0.11408251, -0.20377561, -0.64595675], dtype=float32),\n",
              " (array([-0.04512531,  0.03863895, -0.02779111, -0.03437391], dtype=float32),\n",
              "  {}),\n",
              " array([-0.04435253,  0.23414817, -0.02847858, -0.33569404], dtype=float32),\n",
              " array([-0.03966957,  0.4296636 , -0.03519246, -0.63721985], dtype=float32),\n",
              " array([-0.0310763 ,  0.6252582 , -0.04793686, -0.9407745 ], dtype=float32),\n",
              " array([-0.01857113,  0.43081397, -0.06675235, -0.66353124], dtype=float32),\n",
              " array([-0.00995485,  0.23668104, -0.08002298, -0.39259103], dtype=float32),\n",
              " array([-0.00522123,  0.04278049, -0.0878748 , -0.12617262], dtype=float32),\n",
              " array([-0.00436562, -0.15097985, -0.09039825,  0.13754451], dtype=float32),\n",
              " array([-0.00738522,  0.04531278, -0.08764736, -0.1822331 ], dtype=float32),\n",
              " array([-0.00647896, -0.1484528 , -0.09129202,  0.08156426], dtype=float32),\n",
              " array([-0.00944802, -0.34215555, -0.08966073,  0.34410587], dtype=float32),\n",
              " array([-0.01629113, -0.5358952 , -0.08277862,  0.60722303], dtype=float32),\n",
              " array([-0.02700903, -0.33971938, -0.07063416,  0.2896578 ], dtype=float32),\n",
              " array([-0.03380342, -0.53376675, -0.064841  ,  0.5592539 ], dtype=float32),\n",
              " array([-0.04447876, -0.33779746, -0.05365592,  0.24686779], dtype=float32),\n",
              " array([-0.05123471, -0.5321137 , -0.04871857,  0.5221554 ], dtype=float32),\n",
              " array([-0.06187698, -0.33634108, -0.03827546,  0.2145273 ], dtype=float32),\n",
              " array([-0.0686038 , -0.53089553, -0.03398491,  0.49489495], dtype=float32),\n",
              " array([-0.07922171, -0.33531117, -0.02408701,  0.19169824], dtype=float32),\n",
              " array([-0.08592793, -0.13985308, -0.02025305, -0.10848477], dtype=float32),\n",
              " array([-0.088725  , -0.33467904, -0.02242275,  0.17774025], dtype=float32),\n",
              " array([-0.09541858, -0.52947307, -0.01886794,  0.46326607], dtype=float32),\n",
              " array([-0.10600804, -0.72432333, -0.00960262,  0.74994266], dtype=float32),\n",
              " array([-0.12049451, -0.52907026,  0.00539623,  0.4542534 ], dtype=float32),\n",
              " array([-0.13107592, -0.33402506,  0.0144813 ,  0.16327631], dtype=float32),\n",
              " array([-0.1377564 , -0.5293513 ,  0.01774683,  0.46049228], dtype=float32),\n",
              " array([-0.14834344, -0.7247195 ,  0.02695668,  0.7587158 ], dtype=float32),\n",
              " array([-0.16283783, -0.52997917,  0.04213099,  0.47463575], dtype=float32),\n",
              " array([-0.17343742, -0.33547673,  0.05162371,  0.1955238 ], dtype=float32),\n",
              " array([-0.18014695, -0.14112976,  0.05553418, -0.08043765], dtype=float32),\n",
              " array([-0.18296954,  0.05315394,  0.05392543, -0.35509527], dtype=float32),\n",
              " array([-0.18190646,  0.24746934,  0.04682352, -0.6302983 ], dtype=float32),\n",
              " array([-0.17695707,  0.44190773,  0.03421756, -0.9078751 ], dtype=float32),\n",
              " array([-0.16811892,  0.6365502 ,  0.01606005, -1.1896099 ], dtype=float32),\n",
              " array([-0.15538792,  0.83146036, -0.00773214, -1.477216  ], dtype=float32),\n",
              " array([-0.13875872,  1.0266758 , -0.03727646, -1.7723037 ], dtype=float32),\n",
              " array([-0.11822519,  1.2221979 , -0.07272254, -2.0763397 ], dtype=float32),\n",
              " array([-0.09378124,  1.0278846 , -0.11424933, -1.8070018 ], dtype=float32),\n",
              " array([-0.07322355,  1.2240812 , -0.15038937, -2.1328943 ], dtype=float32),\n",
              " array([-0.04874193,  1.0307362 , -0.19304726, -1.8901983 ], dtype=float32),\n",
              " (array([-0.01744852,  0.03589885,  0.00690643,  0.04834551], dtype=float32),\n",
              "  {}),\n",
              " array([-0.01673054,  0.23092109,  0.00787334, -0.2421504 ], dtype=float32),\n",
              " array([-0.01211212,  0.03568756,  0.00303033,  0.05300555], dtype=float32),\n",
              " array([-0.01139837, -0.15947771,  0.00409044,  0.34664303], dtype=float32),\n",
              " array([-0.01458792,  0.03558582,  0.0110233 ,  0.05525277], dtype=float32),\n",
              " array([-0.01387621, -0.15969244,  0.01212836,  0.35139316], dtype=float32),\n",
              " array([-0.01707006,  0.03525496,  0.01915622,  0.06255922], dtype=float32),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mpc_action_selection(model, current_state, num_simulations=100, horizon=10):\n",
        "    best_action = None\n",
        "    best_reward = -np.inf\n",
        "\n",
        "    for _ in range(num_simulations):\n",
        "        simulated_state = current_state\n",
        "        total_reward = 0\n",
        "        for _ in range(horizon):\n",
        "            action = np.random.choice([0, 1])  # Random action sampling for now\n",
        "            action_tensor = torch.tensor([action], dtype=torch.float32).unsqueeze(0)\n",
        "            state_tensor = torch.tensor(simulated_state, dtype=torch.float32).unsqueeze(0)\n",
        "            next_state, reward = model(state_tensor, action_tensor)\n",
        "            total_reward += reward.item()\n",
        "            simulated_state = next_state.detach().numpy()[0]\n",
        "\n",
        "        if total_reward > best_reward:\n",
        "            best_reward = total_reward\n",
        "            best_action = action\n",
        "\n",
        "    return best_action\n"
      ],
      "metadata": {
        "id": "MSExKxdfui3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_based_agent(env, model, num_episodes=10):\n",
        "    for episode in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        while not done:\n",
        "            action = mpc_action_selection(model, state)\n",
        "            state, reward, done, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "        print(f\"Episode {episode + 1}: Total Reward: {total_reward}\")\n",
        "\n",
        "# Evaluate the agent\n",
        "evaluate_model_based_agent(env, model)\n"
      ],
      "metadata": {
        "id": "thkJAs5LukYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gym\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "\n",
        "from utils import *\n",
        "\n",
        "g_env_model = None\n",
        "def cached_world_model(sess, ob_shape, action_dim, config, path):\n",
        "    global g_env_model\n",
        "    if g_env_model is None:\n",
        "        old_val = config.n_envs\n",
        "        config.n_envs = 1\n",
        "        g_env_model = EnvModel(ob_shape, action_dim, config)\n",
        "        save_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='env_model')\n",
        "        loader = tf.train.Saver(var_list=save_vars)\n",
        "        loader.restore(sess, path)\n",
        "        printstar('World Model Restored')\n",
        "        config.n_envs = old_val\n",
        "\n",
        "    return g_env_model\n",
        "\n",
        "def inject_additional_input(layer, inputs, name, mode=\"multi_additive\"):\n",
        "  \"\"\"Injects the additional input into the layer.\n",
        "\n",
        "  Args:\n",
        "    layer: layer that the input should be injected to.\n",
        "    inputs: inputs to be injected.\n",
        "    name: TF scope name.\n",
        "    mode: how the infor should be added to the layer:\n",
        "      \"concat\" concats as additional channels.\n",
        "      \"multiplicative\" broadcasts inputs and multiply them to the channels.\n",
        "      \"multi_additive\" broadcasts inputs and multiply and add to the channels.\n",
        "\n",
        "  Returns:\n",
        "    updated layer.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: in case of unknown mode.\n",
        "  \"\"\"\n",
        "  layer_shape = shape_list(layer)\n",
        "  input_shape = shape_list(inputs)\n",
        "  zeros_mask = tf.zeros(layer_shape, dtype=tf.float32)\n",
        "  if mode == \"concat\":\n",
        "    emb = common_video.encode_to_shape(inputs, layer_shape, name)\n",
        "    layer = tf.concat(values=[layer, emb], axis=-1)\n",
        "  elif mode == \"multiplicative\":\n",
        "    filters = layer_shape[-1]\n",
        "    input_reshaped = tf.reshape(inputs, [-1, 1, 1, input_shape[-1]])\n",
        "    input_mask = tf.layers.dense(input_reshaped, filters, name=name)\n",
        "    input_broad = input_mask + zeros_mask\n",
        "    layer *= input_broad\n",
        "  elif mode == \"multi_additive\":\n",
        "    filters = layer_shape[-1]\n",
        "    input_reshaped = tf.reshape(inputs, [-1, 1, 1, input_shape[-1]])\n",
        "    input_mul = tf.layers.dense(input_reshaped, filters, name=name + \"_mul\")\n",
        "    layer *= tf.nn.sigmoid(input_mul)\n",
        "    input_add = tf.layers.dense(input_reshaped, filters, name=name + \"_add\")\n",
        "    layer += input_add\n",
        "  else:\n",
        "    raise ValueError(\"Unknown injection mode: %s\" % mode)\n",
        "\n",
        "  return layer\n",
        "\n",
        "class EnvModel(object):\n",
        "    def __init__(self, obs_shape, action_dim, config):\n",
        "\n",
        "        self.obs_shape = obs_shape\n",
        "        self.action_dim = action_dim\n",
        "        self.config = config\n",
        "\n",
        "        self.hidden_size = config.hidden_size\n",
        "        self.layers = config.n_layers\n",
        "        self.dropout_p = config.dropout_p\n",
        "\n",
        "        if(config.activation_fn == 'relu'):\n",
        "            self.activation_fn = tf.nn.relu\n",
        "        elif (config.activation_fn == 'tanh'):\n",
        "            self.activation_fn = tf.nn.tanh\n",
        "\n",
        "        self.l2_clip = config.l2_clip\n",
        "        self.softmax_clip = config.softmax_clip\n",
        "        self.reward_coeff = config.reward_coeff\n",
        "        self.n_envs = config.n_envs\n",
        "        self.max_ep_len = config.max_ep_len\n",
        "        self.log_interval = config.log_interval\n",
        "\n",
        "        self.is_policy = config.is_policy\n",
        "        self.has_rewards = config.has_rewards\n",
        "        self.num_rewards = config.num_rewards\n",
        "\n",
        "        self.width, self.height, self.depth = self.obs_shape\n",
        "\n",
        "        self.states_ph = tf.placeholder(tf.float32, [None, self.width, self.height, self.depth])\n",
        "        self.actions_ph = tf.placeholder(tf.uint8, [None, 1])\n",
        "        self.actions_oph = tf.one_hot(self.actions_ph, depth=action_dim)\n",
        "        self.target_states = tf.placeholder(tf.float32, [None, self.width, self.height, self.depth])\n",
        "        if(self.has_rewards):\n",
        "            self.target_rewards = tf.placeholder(tf.uint8, [None, self.num_rewards])\n",
        "\n",
        "        # NOTE - Implement policy and value parts later\n",
        "        with tf.variable_scope(\"env_model\"):\n",
        "            self.state_pred, self.reward_pred, _, _ = self.network()\n",
        "\n",
        "        # NOTE - Change this maybe to video_l2_loss\n",
        "        self.state_loss = tf.math.maximum(tf.reduce_sum(tf.pow(self.state_pred - self.target_states, 2)), self.l2_clip)\n",
        "        self.loss = self.state_loss\n",
        "\n",
        "        if(self.has_rewards):\n",
        "            self.reward_loss = tf.math.maximum(tf.reduce_mean(tf.losses.softmax_cross_entropy(self.tw_one_hot, self.reward_pred)), self.softmax_clip)\n",
        "            self.loss = self.loss + (self.reward_coeff * self.reward_loss)\n",
        "\n",
        "        self.opt = tf.train.AdamOptimizer().minimize(self.loss)\n",
        "\n",
        "        tf.summary.scalar('loss', self.loss)\n",
        "        if(self.has_rewards):\n",
        "            tf.summary.scalar('image_loss', self.state_loss)\n",
        "            tf.summary.scalar('reward_loss', self.reward_loss)\n",
        "\n",
        "    def generate_data(self, envs):\n",
        "        states = envs.reset()\n",
        "        for frame_idx in range(self.max_ep_len):\n",
        "            states = states.reshape(self.n_envs, self.width, self.height, self.depth)\n",
        "            if(self.n_envs == 1):\n",
        "                actions = envs.action_space.sample()\n",
        "            else:\n",
        "                actions = [envs.action_space.sample() for _ in range(self.n_envs)]\n",
        "            next_states, rewards, dones, _ = envs.step(actions)\n",
        "            next_states = next_states.reshape(self.n_envs, self.width, self.height, self.depth)\n",
        "\n",
        "            yield frame_idx, states, actions, rewards, next_states, dones\n",
        "            states = next_states\n",
        "            if(self.n_envs == 1 and dones == True):\n",
        "                states = envs.reset()\n",
        "\n",
        "    def network(self):\n",
        "        def middle_network(layer):\n",
        "            x = layer\n",
        "            kernel1 = (3, 3)\n",
        "            filters = shape_list(x)[-1]\n",
        "            for i in range(2):\n",
        "              with tf.variable_scope(\"layer%d\" % i):\n",
        "                y = tf.nn.dropout(x, 1.0 - 0.5)\n",
        "                y = tf.layers.conv2d(y, filters, kernel1, activation=self.activation_fn,\n",
        "                                     strides=(1, 1), padding=\"SAME\")\n",
        "                if i == 0:\n",
        "                  x = y\n",
        "                else:\n",
        "                  x = layer_norm(x + y)\n",
        "            return x\n",
        "\n",
        "        batch_size = tf.shape(self.states_ph)[0]\n",
        "\n",
        "        filters = self.hidden_size\n",
        "        kernel2 = (4, 4)\n",
        "        action = self.actions_oph\n",
        "\n",
        "        # Normalize states\n",
        "        if(self.n_envs > 1):\n",
        "            states = [standardize_images(self.states_ph[i, :, :, :]) for i in range(self.n_envs)]\n",
        "            stacked_states = tf.stack(states)\n",
        "        else:\n",
        "            stacked_states = standardize_images(self.states_ph)\n",
        "        inputs_shape = shape_list(stacked_states)\n",
        "\n",
        "        # Using non-zero bias initializer below for edge cases of uniform inputs.\n",
        "        x = tf.layers.dense(\n",
        "            stacked_states, filters, name=\"inputs_embed\",\n",
        "            bias_initializer=tf.random_normal_initializer(stddev=0.01))\n",
        "        x = add_timing_signal_nd(x)\n",
        "\n",
        "        # Down-stride.\n",
        "        layer_inputs = [x]\n",
        "        for i in range(self.layers):\n",
        "          with tf.variable_scope(\"downstride%d\" % i):\n",
        "            layer_inputs.append(x)\n",
        "            x = tf.nn.dropout(x, 1.0 - self.dropout_p)\n",
        "            x = make_even_size(x)\n",
        "            if i < 2:\n",
        "              filters *= 2\n",
        "            x = add_timing_signal_nd(x)\n",
        "            x = tf.layers.conv2d(x, filters, kernel2, activation=self.activation_fn,\n",
        "                                 strides=(2, 2), padding=\"SAME\")\n",
        "            x = layer_norm(x)\n",
        "\n",
        "        if self.is_policy:\n",
        "          with tf.variable_scope(\"policy\"):\n",
        "            x_flat = tf.layers.flatten(x)\n",
        "            policy_pred = tf.layers.dense(x_flat, self.action_dim)\n",
        "            value_pred = tf.layers.dense(x_flat, 1)\n",
        "            value_pred = tf.squeeze(value_pred, axis=-1)\n",
        "        else:\n",
        "          policy_pred, value_pred = None, None\n",
        "\n",
        "        x = inject_additional_input(x, action, \"action_enc\", \"multi_additive\")\n",
        "\n",
        "        # Inject latent if present. Only for stochastic models.\n",
        "        target_states = standardize_images(self.target_states)\n",
        "\n",
        "        x_mid = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
        "        x = middle_network(x)\n",
        "\n",
        "        # Up-convolve.\n",
        "        layer_inputs = list(reversed(layer_inputs))\n",
        "        for i in range(self.layers):\n",
        "          with tf.variable_scope(\"upstride%d\" % i):\n",
        "            x = tf.nn.dropout(x, 1.0 - 0.1)\n",
        "            if i >= self.layers - 2:\n",
        "              filters //= 2\n",
        "            x = tf.layers.conv2d_transpose(\n",
        "                x, filters, kernel2, activation=self.activation_fn,\n",
        "                strides=(2, 2), padding=\"SAME\")\n",
        "            y = layer_inputs[i]\n",
        "            shape = shape_list(y)\n",
        "            x = x[:, :shape[1], :shape[2], :]\n",
        "            x = layer_norm(x + y)\n",
        "            x = add_timing_signal_nd(x)\n",
        "\n",
        "        # Cut down to original size.\n",
        "        x = x[:, :inputs_shape[1], :inputs_shape[2], :]\n",
        "        x_fin = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
        "\n",
        "        x = tf.layers.dense(x, self.depth, name=\"logits\")\n",
        "\n",
        "        reward_pred = None\n",
        "        if self.has_rewards:\n",
        "          # Reward prediction based on middle and final logits.\n",
        "          reward_pred = tf.concat([x_mid, x_fin], axis=-1)\n",
        "          reward_pred = tf.nn.relu(tf.layers.dense(\n",
        "              reward_pred, 128, name=\"reward_pred\"))\n",
        "          reward_pred = tf.squeeze(reward_pred, axis=1)  # Remove extra dims\n",
        "          reward_pred = tf.squeeze(reward_pred, axis=1)  # Remove extra dims\n",
        "\n",
        "        return x, reward_pred, policy_pred, value_pred\n",
        "\n",
        "    def imagine(self, sess, obs, action):\n",
        "        action = np.array(action)\n",
        "        action = np.reshape(action, (1, 1))\n",
        "        obs = obs.reshape(1, self.width, self.height, self.depth)\n",
        "        next_pred_ob = sess.run(self.state_pred, feed_dict={self.states_ph : obs, self.actions_ph : action})\n",
        "        next_pred_ob = next_pred_ob.reshape(self.width, self.height, self.depth)\n",
        "        next_pred_ob = np.rint(next_pred_ob)\n",
        "        return next_pred_ob\n",
        "\n",
        "    def train(self, world_model_path):\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "\n",
        "            losses = []\n",
        "            all_rewards = []\n",
        "            save_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='env_model')\n",
        "            saver = tf.train.Saver(var_list=save_vars)\n",
        "\n",
        "            train_writer = tf.summary.FileWriter('./env_logs/train/', graph=sess.graph)\n",
        "            summary_op = tf.summary.merge_all()\n",
        "\n",
        "            if(self.n_envs == 1):\n",
        "                envs = make_env()()\n",
        "            else:\n",
        "                envs = [make_env() for i in range(self.n_envs)]\n",
        "                envs = SubprocVecEnv(envs)\n",
        "\n",
        "            for idx, states, actions, rewards, next_states, dones in tqdm(\n",
        "                self.generate_data(envs), total=self.max_ep_len):\n",
        "                actions = np.array(actions)\n",
        "                actions = np.reshape(actions, (-1, 1))\n",
        "\n",
        "                if(self.has_rewards):\n",
        "                    target_reward = reward_to_target(rewards)\n",
        "                    loss, reward_loss, state_loss, summary, _ = sess.run([self.loss, self.reward_loss, self.state_loss,\n",
        "                        summary_op, self.opt], feed_dict={\n",
        "                        self.states_ph: states,\n",
        "                        self.actions_ph: actions,\n",
        "                        self.target_states: next_states,\n",
        "                        self.target_rewards: target_reward\n",
        "                    })\n",
        "                else :\n",
        "                    loss, summary, _ = sess.run([self.loss, summary_op, self.opt], feed_dict={\n",
        "                        self.states_ph: states,\n",
        "                        self.actions_ph: actions,\n",
        "                        self.target_states: next_states,\n",
        "                    })\n",
        "\n",
        "                if idx % self.log_interval == 0:\n",
        "                    if(self.has_rewards):\n",
        "                        print('%i => Loss : %.4f, Reward Loss : %.4f, Image Loss : %.4f' % (idx, loss, reward_loss, state_loss))\n",
        "                    else :\n",
        "                        print('%i => Loss : %.4f' % (idx, loss))\n",
        "                    saver.save(sess, '{}/env_model.ckpt'.format(world_model_path))\n",
        "                    print('Environment model saved')\n",
        "\n",
        "                train_writer.add_summary(summary, idx)\n",
        "            envs.close()"
      ],
      "metadata": {
        "id": "UI5fQjGEeMqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from world_model import *\n",
        "from config import argparser\n",
        "from utils import make_env as env_fn, printstar\n",
        "\n",
        "g_env_model = None\n",
        "\n",
        "def main(config):\n",
        "    global env_fn\n",
        "    env = env_fn()()\n",
        "    env.reset()\n",
        "\n",
        "    action_dim = 5\n",
        "    ob_shape = env.observation_space.shape\n",
        "    world_model_path = os.path.expanduser(os.path.join(config.model_dir, config.world_model_type + \"_\" + config.world_model_path))\n",
        "\n",
        "    if(config.train_world_model):\n",
        "        env_model = EnvModel(ob_shape, action_dim, config)\n",
        "        if(not os.path.exists(world_model_path)):\n",
        "            os.mkdir(world_model_path)\n",
        "        printstar(\"Training World Model\")\n",
        "        env_model.train(world_model_path)\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        if(config.eval_world_model):\n",
        "            env_model = cached_world_model(sess, ob_shape, action_dim, config, world_model_path + '/env_model.ckpt')\n",
        "            evaluate_world_model(env, sess, env_model, config)\n",
        "\n",
        "def evaluate_world_model(env, sess, env_model, config, policy=None):\n",
        "    printstar(\"Testing World Model\")\n",
        "    obs = env.reset()\n",
        "    for t in range(config.max_eval_iters):\n",
        "        if(policy is None):\n",
        "                action = env.action_space.sample()\n",
        "        else:\n",
        "            action = policy(obs)\n",
        "\n",
        "        next_pred_ob = env_model.imagine(sess, obs, action)\n",
        "        imgplot = plt.imshow(next_pred_ob)\n",
        "        plt.savefig('./figs/world_model_eval.png')\n",
        "\n",
        "        env.render()\n",
        "        obs, reward, dones, info = env.step(action)\n",
        "        inp = input(\"Press 0 to exit : \")\n",
        "        if(inp == \"0\"):\n",
        "            break\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    config = argparser()\n",
        "    mp.set_start_method('spawn', force=True)\n",
        "    main(config)"
      ],
      "metadata": {
        "id": "NmgPiaZcePVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "\n",
        "def str2bool(v):\n",
        "    return v.lower() == 'true'\n",
        "\n",
        "def str2list(v):\n",
        "    if not v:\n",
        "        return v\n",
        "    else:\n",
        "        return [v_ for v_ in v.split(',')]\n",
        "\n",
        "def argparser():\n",
        "    parser = argparse.ArgumentParser(\"Model-Based Reinforcement Learning for Atari\",\n",
        "                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "\n",
        "    parser.add_argument('--train_world_model', type=str2bool, default=True)\n",
        "    parser.add_argument('--eval_world_model', type=str2bool, default=True)\n",
        "\n",
        "    parser.add_argument('--num_rewards', type=int, default=1)\n",
        "    parser.add_argument('--n_envs', type=int, default=16)\n",
        "    parser.add_argument('--is_policy', type=str2bool, default=False)\n",
        "    parser.add_argument('--has_rewards', type=str2bool, default=False)\n",
        "    parser.add_argument('--hidden_size', type=int, default=64)\n",
        "    parser.add_argument('--n_layers', type=int, default=6)\n",
        "    parser.add_argument('--dropout_p', type=float, default=0.1)\n",
        "    parser.add_argument('--max_ep_len', type=int, default=500000)\n",
        "    parser.add_argument('--l2_clip', type=float, default=0.0)\n",
        "    parser.add_argument('--softmax_clip', type=float, default=0.03)\n",
        "    parser.add_argument('--reward_coeff', type=float, default=0.1)\n",
        "    parser.add_argument('--log_interval', type=int, default=100)\n",
        "    parser.add_argument('--activation_fn', type=str, default='relu', choices=['relu', 'tanh'])\n",
        "\n",
        "    parser.add_argument('--log_dir', type=str, default='./log')\n",
        "    parser.add_argument('--model_dir', type=str, default='./models')\n",
        "    parser.add_argument('--world_model_path', type=str, default=\"CarRacingWorldModel\")\n",
        "\n",
        "    parser.add_argument('--total_timesteps', type=int, default=int(1e6))\n",
        "    parser.add_argument('--max_eval_iters', type=int, default=int(1e3))\n",
        "\n",
        "    parser.add_argument('--render', type=str2bool, default=True, help='Render frames')\n",
        "    parser.add_argument('--debug', type=str2bool, default=False, help='See debugging info')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    return args"
      ],
      "metadata": {
        "id": "EzLqnTLdeSQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code is from OpenAI Baseline and Tensor2Tensor\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "from gym.envs.box2d import CarRacing\n",
        "import multiprocessing as mp\n",
        "\n",
        "def printstar(string, num_stars=50):\n",
        "    print(\"*\" * num_stars)\n",
        "    print(string)\n",
        "    print(\"*\" * num_stars)\n",
        "\n",
        "def make_env():\n",
        "    def _thunk():\n",
        "        env = CarRacing(grayscale=0, show_info_panel=0, discretize_actions=\"hard\", frames_per_state=1, num_lanes=1, num_tracks=1)\n",
        "        return env\n",
        "    return _thunk\n",
        "\n",
        "def worker(remote, parent_remote, env_fn_wrapper):\n",
        "    parent_remote.close()\n",
        "    env = env_fn_wrapper.x()\n",
        "    while True:\n",
        "        cmd, data = remote.recv()\n",
        "        if cmd == 'step':\n",
        "            ob, reward, done, info = env.step(data)\n",
        "            if done:\n",
        "                ob = env.reset()\n",
        "            remote.send((ob, reward, done, info))\n",
        "        elif cmd == 'reset':\n",
        "            ob = env.reset()\n",
        "            remote.send(ob)\n",
        "        elif cmd == 'reset_task':\n",
        "            ob = env.reset_task()\n",
        "            remote.send(ob)\n",
        "        elif cmd == 'close':\n",
        "            remote.close()\n",
        "            break\n",
        "        elif cmd == 'get_spaces':\n",
        "            remote.send((env.observation_space, env.action_space))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "class VecEnv(object):\n",
        "    \"\"\"\n",
        "    An abstract asynchronous, vectorized environment.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_envs, observation_space, action_space):\n",
        "        self.num_envs = num_envs\n",
        "        self.observation_space = observation_space\n",
        "        self.action_space = action_space\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset all the environments and return an array of\n",
        "        observations, or a tuple of observation arrays.\n",
        "        If step_async is still doing work, that work will\n",
        "        be cancelled and step_wait() should not be called\n",
        "        until step_async() is invoked again.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def step_async(self, actions):\n",
        "        \"\"\"\n",
        "        Tell all the environments to start taking a step\n",
        "        with the given actions.\n",
        "        Call step_wait() to get the results of the step.\n",
        "        You should not call this if a step_async run is\n",
        "        already pending.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def step_wait(self):\n",
        "        \"\"\"\n",
        "        Wait for the step taken with step_async().\n",
        "        Returns (obs, rews, dones, infos):\n",
        "         - obs: an array of observations, or a tuple of\n",
        "                arrays of observations.\n",
        "         - rews: an array of rewards\n",
        "         - dones: an array of \"episode done\" booleans\n",
        "         - infos: a sequence of info objects\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"\n",
        "        Clean up the environments' resources.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def step(self, actions):\n",
        "        self.step_async(actions)\n",
        "        return self.step_wait()\n",
        "\n",
        "\n",
        "class CloudpickleWrapper(object):\n",
        "    \"\"\"\n",
        "    Uses cloudpickle to serialize contents (otherwise multiprocessing tries to use pickle)\n",
        "    \"\"\"\n",
        "    def __init__(self, x):\n",
        "        self.x = x\n",
        "    def __getstate__(self):\n",
        "        import cloudpickle\n",
        "        return cloudpickle.dumps(self.x)\n",
        "    def __setstate__(self, ob):\n",
        "        import pickle\n",
        "        self.x = pickle.loads(ob)\n",
        "\n",
        "class SubprocVecEnv(VecEnv):\n",
        "    def __init__(self, env_fns, spaces=None):\n",
        "        \"\"\"\n",
        "        envs: list of gym environments to run in subprocesses\n",
        "        \"\"\"\n",
        "        self.waiting = False\n",
        "        self.closed = False\n",
        "        nenvs = len(env_fns)\n",
        "        self.nenvs = nenvs\n",
        "        self.remotes, self.work_remotes = zip(*[mp.Pipe() for _ in range(nenvs)])\n",
        "        self.ps = [mp.Process(target=worker, args=(work_remote, remote, CloudpickleWrapper(env_fn)))\n",
        "            for (work_remote, remote, env_fn) in zip(self.work_remotes, self.remotes, env_fns)]\n",
        "        for p in self.ps:\n",
        "            p.daemon = True # if the main process crashes, we should not cause things to hang\n",
        "            p.start()\n",
        "        for remote in self.work_remotes:\n",
        "            remote.close()\n",
        "\n",
        "        self.remotes[0].send(('get_spaces', None))\n",
        "        observation_space, action_space = self.remotes[0].recv()\n",
        "        VecEnv.__init__(self, len(env_fns), observation_space, action_space)\n",
        "\n",
        "    def step_async(self, actions):\n",
        "        if(type(actions) == int):\n",
        "            for remote in self.remotes:\n",
        "                remote.send(('step', actions))\n",
        "        else:\n",
        "            for remote, action in zip(self.remotes, actions):\n",
        "                remote.send(('step', action))\n",
        "        self.waiting = True\n",
        "\n",
        "    def step_wait(self):\n",
        "        results = [remote.recv() for remote in self.remotes]\n",
        "        self.waiting = False\n",
        "        obs, rews, dones, infos = zip(*results)\n",
        "        return np.stack(obs), np.stack(rews), np.stack(dones), infos\n",
        "\n",
        "    def reset(self):\n",
        "        for remote in self.remotes:\n",
        "            remote.send(('reset', None))\n",
        "        return np.stack([remote.recv() for remote in self.remotes])\n",
        "\n",
        "    def reset_task(self):\n",
        "        for remote in self.remotes:\n",
        "            remote.send(('reset_task', None))\n",
        "        return np.stack([remote.recv() for remote in self.remotes])\n",
        "\n",
        "    def close(self):\n",
        "        if self.closed:\n",
        "            return\n",
        "        if self.waiting:\n",
        "            for remote in self.remotes:\n",
        "                remote.recv()\n",
        "        for remote in self.remotes:\n",
        "            remote.send(('close', None))\n",
        "        for p in self.ps:\n",
        "            p.join()\n",
        "            self.closed = True\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.nenvs\n",
        "\n",
        "\n",
        "\n",
        "def shape_list(x):\n",
        "  \"\"\"Return list of dims, statically where possible.\"\"\"\n",
        "  x = tf.convert_to_tensor(x)\n",
        "\n",
        "  # If unknown rank, return dynamic shape\n",
        "  if x.get_shape().dims is None:\n",
        "    return tf.shape(x)\n",
        "\n",
        "  static = x.get_shape().as_list()\n",
        "  shape = tf.shape(x)\n",
        "\n",
        "  ret = []\n",
        "  for i, dim in enumerate(static):\n",
        "    if dim is None:\n",
        "      dim = shape[i]\n",
        "    ret.append(dim)\n",
        "  return ret\n",
        "\n",
        "def to_float(x):\n",
        "  \"\"\"Cast x to float; created because tf.to_float is deprecated.\"\"\"\n",
        "  return tf.cast(x, tf.float32)\n",
        "\n",
        "def cast_like(x, y):\n",
        "  \"\"\"Cast x to y's dtype, if necessary.\"\"\"\n",
        "  x = tf.convert_to_tensor(x)\n",
        "  y = tf.convert_to_tensor(y)\n",
        "\n",
        "  if x.dtype.base_dtype == y.dtype.base_dtype:\n",
        "    return x\n",
        "\n",
        "  cast_x = tf.cast(x, y.dtype)\n",
        "  if cast_x.device != x.device:\n",
        "    x_name = \"(eager Tensor)\"\n",
        "    try:\n",
        "      x_name = x.name\n",
        "    except AttributeError:\n",
        "      pass\n",
        "    tf.logging.warning(\"Cast for %s may induce copy from '%s' to '%s'\", x_name,\n",
        "                       x.device, cast_x.device)\n",
        "  return cast_x\n",
        "\n",
        "def layer_norm_vars(filters):\n",
        "  \"\"\"Create Variables for layer norm.\"\"\"\n",
        "  scale = tf.get_variable(\n",
        "      \"layer_norm_scale\", [filters], initializer=tf.ones_initializer())\n",
        "  bias = tf.get_variable(\n",
        "      \"layer_norm_bias\", [filters], initializer=tf.zeros_initializer())\n",
        "  return scale, bias\n",
        "\n",
        "\n",
        "def layer_norm_compute(x, epsilon, scale, bias, layer_collection=None):\n",
        "  \"\"\"Layer norm raw computation.\"\"\"\n",
        "\n",
        "  # Save these before they get converted to tensors by the casting below\n",
        "  params = (scale, bias)\n",
        "\n",
        "  epsilon, scale, bias = [cast_like(t, x) for t in [epsilon, scale, bias]]\n",
        "  mean = tf.reduce_mean(x, axis=[-1], keepdims=True)\n",
        "  variance = tf.reduce_mean(\n",
        "      tf.squared_difference(x, mean), axis=[-1], keepdims=True)\n",
        "  norm_x = (x - mean) * tf.rsqrt(variance + epsilon)\n",
        "\n",
        "  output = norm_x * scale + bias\n",
        "\n",
        "\n",
        "  return output\n",
        "\n",
        "def layer_norm(x,\n",
        "               filters=None,\n",
        "               epsilon=1e-6,\n",
        "               name=None,\n",
        "               reuse=None,\n",
        "               layer_collection=None):\n",
        "  \"\"\"Layer normalize the tensor x, averaging over the last dimension.\"\"\"\n",
        "  if filters is None:\n",
        "    filters = shape_list(x)[-1]\n",
        "  with tf.variable_scope(\n",
        "      name, default_name=\"layer_norm\", values=[x], reuse=reuse):\n",
        "    scale, bias = layer_norm_vars(filters)\n",
        "    return layer_norm_compute(x, epsilon, scale, bias,\n",
        "                              layer_collection=layer_collection)\n",
        "\n",
        "def standardize_images(x):\n",
        "  \"\"\"Image standardization on batches and videos.\"\"\"\n",
        "  with tf.name_scope(\"standardize_images\", values=[x]):\n",
        "    x_shape = shape_list(x)\n",
        "    x = to_float(tf.reshape(x, [-1] + x_shape[-3:]))\n",
        "    x_mean = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
        "    x_variance = tf.reduce_mean(\n",
        "        tf.squared_difference(x, x_mean), axis=[1, 2], keepdims=True)\n",
        "    num_pixels = to_float(x_shape[-2] * x_shape[-3])\n",
        "    x = (x - x_mean) / tf.maximum(tf.sqrt(x_variance), tf.rsqrt(num_pixels))\n",
        "    return tf.reshape(x, x_shape)\n",
        "\n",
        "def pad_to_same_length(x, y, final_length_divisible_by=1, axis=1):\n",
        "  \"\"\"Pad tensors x and y on axis 1 so that they have the same length.\"\"\"\n",
        "  if axis not in [1, 2]:\n",
        "    raise ValueError(\"Only axis=1 and axis=2 supported for now.\")\n",
        "  with tf.name_scope(\"pad_to_same_length\", values=[x, y]):\n",
        "    x_length = shape_list(x)[axis]\n",
        "    y_length = shape_list(y)[axis]\n",
        "    if (isinstance(x_length, int) and isinstance(y_length, int) and\n",
        "        x_length == y_length and final_length_divisible_by == 1):\n",
        "      return x, y\n",
        "    max_length = tf.maximum(x_length, y_length)\n",
        "    if final_length_divisible_by > 1:\n",
        "      # Find the nearest larger-or-equal integer divisible by given number.\n",
        "      max_length += final_length_divisible_by - 1\n",
        "      max_length //= final_length_divisible_by\n",
        "      max_length *= final_length_divisible_by\n",
        "    length_diff1 = max_length - x_length\n",
        "    length_diff2 = max_length - y_length\n",
        "\n",
        "    def padding_list(length_diff, arg):\n",
        "      if axis == 1:\n",
        "        return [[[0, 0], [0, length_diff]],\n",
        "                tf.zeros([tf.rank(arg) - 2, 2], dtype=tf.int32)]\n",
        "      return [[[0, 0], [0, 0], [0, length_diff]],\n",
        "              tf.zeros([tf.rank(arg) - 3, 2], dtype=tf.int32)]\n",
        "\n",
        "    paddings1 = tf.concat(padding_list(length_diff1, x), axis=0)\n",
        "    paddings2 = tf.concat(padding_list(length_diff2, y), axis=0)\n",
        "    res_x = tf.pad(x, paddings1)\n",
        "    res_y = tf.pad(y, paddings2)\n",
        "    # Static shapes are the same except for axis=1.\n",
        "    x_shape = x.shape.as_list()\n",
        "    x_shape[axis] = None\n",
        "    res_x.set_shape(x_shape)\n",
        "    y_shape = y.shape.as_list()\n",
        "    y_shape[axis] = None\n",
        "    res_y.set_shape(y_shape)\n",
        "    return res_x, res_y\n",
        "\n",
        "def make_even_size(x):\n",
        "  \"\"\"Pad x to be even-sized on axis 1 and 2, but only if necessary.\"\"\"\n",
        "  x_shape = x.get_shape().as_list()\n",
        "  assert len(x_shape) > 2, \"Only 3+-dimensional tensors supported.\"\n",
        "  shape = [dim if dim is not None else -1 for dim in x_shape]\n",
        "  new_shape = x_shape  # To make sure constant shapes remain constant.\n",
        "  if x_shape[1] is not None:\n",
        "    new_shape[1] = 2 * int(math.ceil(x_shape[1] * 0.5))\n",
        "  if x_shape[2] is not None:\n",
        "    new_shape[2] = 2 * int(math.ceil(x_shape[2] * 0.5))\n",
        "  if shape[1] % 2 == 0 and shape[2] % 2 == 0:\n",
        "    return x\n",
        "  if shape[1] % 2 == 0:\n",
        "    x, _ = pad_to_same_length(x, x, final_length_divisible_by=2, axis=2)\n",
        "    x.set_shape(new_shape)\n",
        "    return x\n",
        "  if shape[2] % 2 == 0:\n",
        "    x, _ = pad_to_same_length(x, x, final_length_divisible_by=2, axis=1)\n",
        "    x.set_shape(new_shape)\n",
        "    return x\n",
        "  x, _ = pad_to_same_length(x, x, final_length_divisible_by=2, axis=1)\n",
        "  x, _ = pad_to_same_length(x, x, final_length_divisible_by=2, axis=2)\n",
        "  x.set_shape(new_shape)\n",
        "  return x\n",
        "\n",
        "\n",
        "def add_timing_signal_nd(x, min_timescale=1.0, max_timescale=1.0e4):\n",
        "  \"\"\"Adds a bunch of sinusoids of different frequencies to a Tensor.\n",
        "\n",
        "  Each channel of the input Tensor is incremented by a sinusoid of a different\n",
        "  frequency and phase in one of the positional dimensions.\n",
        "\n",
        "  This allows attention to learn to use absolute and relative positions.\n",
        "  Timing signals should be added to some precursors of both the query and the\n",
        "  memory inputs to attention.\n",
        "\n",
        "  The use of relative position is possible because sin(a+b) and cos(a+b) can be\n",
        "  expressed in terms of b, sin(a) and cos(a).\n",
        "\n",
        "  x is a Tensor with n \"positional\" dimensions, e.g. one dimension for a\n",
        "  sequence or two dimensions for an image\n",
        "\n",
        "  We use a geometric sequence of timescales starting with\n",
        "  min_timescale and ending with max_timescale.  The number of different\n",
        "  timescales is equal to channels // (n * 2). For each timescale, we\n",
        "  generate the two sinusoidal signals sin(timestep/timescale) and\n",
        "  cos(timestep/timescale).  All of these sinusoids are concatenated in\n",
        "  the channels dimension.\n",
        "\n",
        "  Args:\n",
        "    x: a Tensor with shape [batch, d1 ... dn, channels]\n",
        "    min_timescale: a float\n",
        "    max_timescale: a float\n",
        "\n",
        "  Returns:\n",
        "    a Tensor the same shape as x.\n",
        "  \"\"\"\n",
        "  num_dims = len(x.get_shape().as_list()) - 2\n",
        "  channels = shape_list(x)[-1]\n",
        "  num_timescales = channels // (num_dims * 2)\n",
        "  log_timescale_increment = (\n",
        "      math.log(float(max_timescale) / float(min_timescale)) /\n",
        "      (tf.to_float(num_timescales) - 1))\n",
        "  inv_timescales = min_timescale * tf.exp(\n",
        "      tf.to_float(tf.range(num_timescales)) * -log_timescale_increment)\n",
        "  for dim in range(num_dims):\n",
        "    length = shape_list(x)[dim + 1]\n",
        "    position = tf.to_float(tf.range(length))\n",
        "    scaled_time = tf.expand_dims(position, 1) * tf.expand_dims(\n",
        "        inv_timescales, 0)\n",
        "    signal = tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=1)\n",
        "    prepad = dim * 2 * num_timescales\n",
        "    postpad = channels - (dim + 1) * 2 * num_timescales\n",
        "    signal = tf.pad(signal, [[0, 0], [prepad, postpad]])\n",
        "    for _ in range(1 + dim):\n",
        "      signal = tf.expand_dims(signal, 0)\n",
        "    for _ in range(num_dims - 1 - dim):\n",
        "      signal = tf.expand_dims(signal, -2)\n",
        "    x += signal\n",
        "  return x\n"
      ],
      "metadata": {
        "id": "554YKfW8eVHK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}